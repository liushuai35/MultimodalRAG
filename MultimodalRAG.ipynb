{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a36b54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\anaconda3\\envs\\mrag\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 15:16:57,003 - INFO - [873340601.py.setup_logging:77] - 全局日志记录器配置完成。日志将输出到控制台，并写入文件: Multimodal_RAG_System_Run_20250512_151657\\run_logs\\system_execution_log.txt\n",
      "2025-05-12 15:16:57,005 - INFO - [873340601.py.<module>:1776] - \n",
      "================================================================================\n",
      "2025-05-12 15:16:57,006 - INFO - [873340601.py.<module>:1777] - ========= Multimodal Retrieval Augmented Generation (RAG) System =========\n",
      "2025-05-12 15:16:57,007 - INFO - [873340601.py.<module>:1778] - =========                     Main Program Execution Start               =========\n",
      "2025-05-12 15:16:57,008 - INFO - [873340601.py.<module>:1779] - ================================================================================\n",
      "\n",
      "2025-05-12 15:16:57,009 - INFO - [873340601.py.<module>:1780] - User Defined Run Identifier (Base): Multimodal_RAG_System_Run\n",
      "2025-05-12 15:16:57,009 - INFO - [873340601.py.<module>:1781] - Sanitized Run Identifier: Multimodal_RAG_System_Run\n",
      "2025-05-12 15:16:57,010 - INFO - [873340601.py.<module>:1782] - All output data will be saved in the directory: d:\\ALL IN AI\\多模态RAG\\IDT_RAG\\MultimodalRAG\\Multimodal_RAG_System_Run_20250512_151657\n",
      "2025-05-12 15:16:57,011 - INFO - [873340601.py.<module>:1787] - Data Source Config: JSON Metadata File='data.json', Image Directory='images'\n",
      "2025-05-12 15:16:57,012 - INFO - [873340601.py.<module>:1802] - Database file will be saved to: Multimodal_RAG_System_Run_20250512_151657\\data_storage\\database\\multimodal_document_library.db\n",
      "2025-05-12 15:16:57,012 - INFO - [873340601.py.<module>:1803] - Faiss index files will be saved to directory: Multimodal_RAG_System_Run_20250512_151657\\data_storage\\vector_indices\n",
      "2025-05-12 15:16:57,013 - INFO - [873340601.py.<module>:1804] - Query session results will be saved to directory: Multimodal_RAG_System_Run_20250512_151657\\query_session_results\n",
      "2025-05-12 15:16:57,013 - INFO - [873340601.py.<module>:1813] - Model Configuration: CLIP Model='openai/clip-vit-base-patch32', Large Language Model (LLM)='glm-4-flash'\n",
      "2025-05-12 15:16:57,014 - INFO - [873340601.py.<module>:1818] - \n",
      "--- [Main Flow] Step 1: Loading document data from JSON and associating image files ---\n",
      "2025-05-12 15:16:57,014 - INFO - [873340601.py.load_data_from_json_and_associate_images:156] - 开始从 JSON 文件 'data.json' 加载数据，并在目录 'images' 中关联图像...\n",
      "2025-05-12 15:16:57,017 - INFO - [873340601.py.load_data_from_json_and_associate_images:188] - 已成功从 'data.json' 加载 219 条原始记录。\n",
      "2025-05-12 15:16:57,054 - INFO - [873340601.py.load_data_from_json_and_associate_images:245] - 成功准备了 219 个文档用于后续处理。\n",
      "2025-05-12 15:16:57,055 - INFO - [873340601.py.load_data_from_json_and_associate_images:248] - 在有效文档中，共有 213 个文档成功关联了图像文件。\n",
      "2025-05-12 15:16:57,055 - INFO - [873340601.py.load_data_from_json_and_associate_images:255] - --- 数据加载与图像关联流程结束 ---\n",
      "2025-05-12 15:16:57,056 - INFO - [873340601.py.<module>:1826] - --- [Main Flow] Step 1 Complete: Successfully loaded and prepared 219 documents for indexing. ---\n",
      "\n",
      "2025-05-12 15:16:57,258 - INFO - [873340601.py.<module>:1832] - --- [Main Flow] Step 2: Initializing Indexer and building indices for loaded documents ---\n",
      "2025-05-12 15:16:57,258 - INFO - [873340601.py.__init__:547] - 开始初始化 Indexer...\n",
      "2025-05-12 15:16:57,259 - INFO - [873340601.py.__init__:554] -   数据库路径: Multimodal_RAG_System_Run_20250512_151657\\data_storage\\database\\multimodal_document_library.db\n",
      "2025-05-12 15:16:57,260 - INFO - [873340601.py.__init__:555] -   文本索引路径: Multimodal_RAG_System_Run_20250512_151657\\data_storage\\vector_indices\\text_vector_index.faiss\n",
      "2025-05-12 15:16:57,260 - INFO - [873340601.py.__init__:556] -   图像索引路径: Multimodal_RAG_System_Run_20250512_151657\\data_storage\\vector_indices\\image_vector_index.faiss\n",
      "2025-05-12 15:16:57,260 - INFO - [873340601.py.__init__:557] -   平均向量索引路径: Multimodal_RAG_System_Run_20250512_151657\\data_storage\\vector_indices\\mean_vector_index.faiss\n",
      "2025-05-12 15:16:57,261 - INFO - [873340601.py.__init__:561] -   - 正在初始化内部 MultimodalEncoder，使用 CLIP 模型: openai/clip-vit-base-patch32...\n",
      "2025-05-12 15:16:57,261 - INFO - [873340601.py.__init__:296] - 开始初始化 MultimodalEncoder，尝试加载 CLIP 模型: openai/clip-vit-base-patch32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 15:17:22,656 - INFO - [873340601.py.__init__:304] - CLIP Processor for 'openai/clip-vit-base-patch32' 加载成功。\n",
      "2025-05-12 15:17:38,646 - INFO - [873340601.py.__init__:308] - CLIP Model 'openai/clip-vit-base-patch32' 加载成功。\n",
      "2025-05-12 15:17:38,646 - INFO - [873340601.py.__init__:315] - CLIP 模型的特征向量维度为: 512\n",
      "2025-05-12 15:17:38,647 - INFO - [873340601.py.__init__:328] - 未检测到 CUDA 支持，模型将运行在 CPU 上 (编码速度可能较慢)。\n",
      "2025-05-12 15:17:38,651 - INFO - [873340601.py.__init__:331] - 模型已成功移动到设备: cpu\n",
      "2025-05-12 15:17:38,651 - INFO - [873340601.py.__init__:332] - MultimodalEncoder 初始化成功完成。\n",
      "2025-05-12 15:17:38,652 - INFO - [873340601.py.__init__:565] -   - MultimodalEncoder 初始化完成。特征向量维度为: 512。\n",
      "2025-05-12 15:17:38,652 - INFO - [873340601.py.__init__:572] -   - 正在初始化 SQLite 数据库，路径: 'Multimodal_RAG_System_Run_20250512_151657\\data_storage\\database\\multimodal_document_library.db'...\n",
      "2025-05-12 15:17:38,653 - INFO - [873340601.py._init_db:605] - 正在连接并初始化数据库表结构于路径: 'Multimodal_RAG_System_Run_20250512_151657\\data_storage\\database\\multimodal_document_library.db'...\n",
      "2025-05-12 15:17:38,679 - INFO - [873340601.py._init_db:643] - 数据库表 'documents' (及索引 'idx_doc_id') 初始化成功，或已存在。\n",
      "2025-05-12 15:17:38,680 - INFO - [873340601.py.__init__:575] -   - SQLite 数据库初始化完成。\n",
      "2025-05-12 15:17:38,680 - INFO - [873340601.py.__init__:584] -   - 正在加载或创建 Faiss 向量索引...\n",
      "2025-05-12 15:17:38,681 - INFO - [873340601.py._load_or_create_faiss_index:667] - 正在为 '文本(Text)' 索引加载或创建 Faiss 文件于路径: 'Multimodal_RAG_System_Run_20250512_151657\\data_storage\\vector_indices\\text_vector_index.faiss'...\n",
      "2025-05-12 15:17:38,682 - INFO - [873340601.py._load_or_create_faiss_index:700] - 未找到 '文本(Text)' Faiss 索引文件: 'Multimodal_RAG_System_Run_20250512_151657\\data_storage\\vector_indices\\text_vector_index.faiss'。将创建一个新的空索引。\n",
      "2025-05-12 15:17:38,682 - INFO - [873340601.py._create_new_faiss_index:725] - 开始为 '文本(Text)' 创建一个新的空 Faiss 索引...\n",
      "2025-05-12 15:17:38,683 - INFO - [873340601.py._create_new_faiss_index:744] - 已成功为 '文本(Text)' 创建一个新的、空的 Faiss 索引 (类型: IndexIDMap2 包裹 IndexFlatIP)。\n",
      "2025-05-12 15:17:38,683 - INFO - [873340601.py._create_new_faiss_index:745] -     索引维度: 512。\n",
      "2025-05-12 15:17:38,684 - INFO - [873340601.py._create_new_faiss_index:746] -     相似度度量: 内积 (Inner Product) - 对于归一化向量，这等同于余弦相似度。\n",
      "2025-05-12 15:17:38,684 - INFO - [873340601.py._load_or_create_faiss_index:667] - 正在为 '图像(Image)' 索引加载或创建 Faiss 文件于路径: 'Multimodal_RAG_System_Run_20250512_151657\\data_storage\\vector_indices\\image_vector_index.faiss'...\n",
      "2025-05-12 15:17:38,685 - INFO - [873340601.py._load_or_create_faiss_index:700] - 未找到 '图像(Image)' Faiss 索引文件: 'Multimodal_RAG_System_Run_20250512_151657\\data_storage\\vector_indices\\image_vector_index.faiss'。将创建一个新的空索引。\n",
      "2025-05-12 15:17:38,686 - INFO - [873340601.py._create_new_faiss_index:725] - 开始为 '图像(Image)' 创建一个新的空 Faiss 索引...\n",
      "2025-05-12 15:17:38,687 - INFO - [873340601.py._create_new_faiss_index:744] - 已成功为 '图像(Image)' 创建一个新的、空的 Faiss 索引 (类型: IndexIDMap2 包裹 IndexFlatIP)。\n",
      "2025-05-12 15:17:38,688 - INFO - [873340601.py._create_new_faiss_index:745] -     索引维度: 512。\n",
      "2025-05-12 15:17:38,688 - INFO - [873340601.py._create_new_faiss_index:746] -     相似度度量: 内积 (Inner Product) - 对于归一化向量，这等同于余弦相似度。\n",
      "2025-05-12 15:17:38,689 - INFO - [873340601.py._load_or_create_faiss_index:667] - 正在为 '平均(Mean)' 索引加载或创建 Faiss 文件于路径: 'Multimodal_RAG_System_Run_20250512_151657\\data_storage\\vector_indices\\mean_vector_index.faiss'...\n",
      "2025-05-12 15:17:38,689 - INFO - [873340601.py._load_or_create_faiss_index:700] - 未找到 '平均(Mean)' Faiss 索引文件: 'Multimodal_RAG_System_Run_20250512_151657\\data_storage\\vector_indices\\mean_vector_index.faiss'。将创建一个新的空索引。\n",
      "2025-05-12 15:17:38,690 - INFO - [873340601.py._create_new_faiss_index:725] - 开始为 '平均(Mean)' 创建一个新的空 Faiss 索引...\n",
      "2025-05-12 15:17:38,690 - INFO - [873340601.py._create_new_faiss_index:744] - 已成功为 '平均(Mean)' 创建一个新的、空的 Faiss 索引 (类型: IndexIDMap2 包裹 IndexFlatIP)。\n",
      "2025-05-12 15:17:38,691 - INFO - [873340601.py._create_new_faiss_index:745] -     索引维度: 512。\n",
      "2025-05-12 15:17:38,692 - INFO - [873340601.py._create_new_faiss_index:746] -     相似度度量: 内积 (Inner Product) - 对于归一化向量，这等同于余弦相似度。\n",
      "2025-05-12 15:17:38,693 - INFO - [873340601.py.__init__:589] -   - 所有 Faiss 索引均已准备就绪。\n",
      "2025-05-12 15:17:38,694 - INFO - [873340601.py.__init__:595] - Indexer 初始化成功完成。\n",
      "2025-05-12 15:17:38,695 - INFO - [873340601.py.index_documents:769] - 开始执行文档索引流程，准备处理 219 个文档...\n",
      "2025-05-12 15:17:38,697 - INFO - [873340601.py.index_documents:797] - 开始遍历 219 个文档进行处理和编码...\n",
      "2025-05-12 15:17:38,903 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本=': Evidence for Bandgap Referen...', 图像='Bandgap1.jpg')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:39,028 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='1. **Evidence 1**: Q1 and Q2 g...', 图像='Bandgap10.jpg')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:39,134 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='1. **PTAT Voltage Generation:*...', 图像='Bandgap11.jpg')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:39,245 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本=': Evidence:\\n1. **Presence of ...', 图像='Bandgap23.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:39,359 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本=': 1. **PTAT Voltage Generation...', 图像='Bandgap26.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:39,530 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\\n\\nThis circuit is identifi...', 图像='Bandgap3.jpg')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:39,675 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\\n\\n**Evidence for Bandgap R...', 图像='Bandgap31.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:39,791 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本=': 1. **Evidence 1: PTAT Curren...', 图像='Bandgap32.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:39,893 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**Evidence:**\\n     - The circ...', 图像='Bandgap33.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:39,993 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**This circuit is a **bandgap ...', 图像='Bandgap34.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:40,098 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本=': 1. **PTAT Current Source**:\\...', 图像='Bandgap35.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:40,204 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\\n\\nBased on the analysis, t...', 图像='Bandgap36.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:40,305 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='Key Evidence of Bandgap Refere...', 图像='Bandgap37.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:40,404 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本=':Key Evidence of Bandgap Refer...', 图像='Bandgap38.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:40,554 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本=': Identification of Bandgap Re...', 图像='Bandgap39.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:40,694 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\\n\\nThis circuit qualifies a...', 图像='Bandgap4.jpg')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:40,801 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本=': Evidence for Bandgap Referen...', 图像='Bandgap40.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:40,902 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本=':\\nBased on the analysis, the ...', 图像='Bandgap41.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:41,004 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本=':**\\nThis circuit is a **bandg...', 图像='Bandgap42.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:41,104 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='The circuit represented by the...', 图像='Bandgap43.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:41,210 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\\n\\nBased on the analysis, t...', 图像='Bandgap44.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:41,316 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\\n\\n#### **Why Is This a Ban...', 图像='Bandgap45.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:41,426 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**Based on the following evide...', 图像='Bandgap46.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:41,534 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='Based on the analysis, the cir...', 图像='Bandgap47.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:41,638 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='#### Evidence for Bandgap Refe...', 图像='Bandgap48.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:41,745 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\\n\\nThis circuit is a **Band...', 图像='Bandgap50.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:41,854 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\\n\\nBased on the provided ci...', 图像='Bandgap52.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:41,963 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='The circuit provided is indeed...', 图像='Bandgap53.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:42,057 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='This circuit qualifies as a ba...', 图像='Bandgap54.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:42,161 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='------------------\\nThis circu...', 图像='Bandgap56.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:42,272 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\\n\\nBased on the circuit's o...', 图像='Bandgap57.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:42,382 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本=': This circuit can be consider...', 图像='Bandgap59.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:42,492 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='The provided circuit is indeed...', 图像='Bandgap60.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:42,593 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本=' **Evidence 1**: Q1 and Q2 wit...', 图像='Bandgap61.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:42,704 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='------\\n\\nBased on the followi...', 图像='Bandgap62.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:42,809 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\\nThis circuit can be defini...', 图像='Bandgap63.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:42,917 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**Evidence for Bandgap Referen...', 图像='Bandgap64.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:43,025 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='1. **PTAT Generation:** Q1, Q2...', 图像='Bandgap65.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:43,122 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='Based on the evidence, the cir...', 图像='Bandgap67.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:43,227 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\\n\\nThis circuit can be conc...', 图像='Bandgap68.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:43,339 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\\nThis circuit is a bandgap ...', 图像='Bandgap69.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:43,441 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\\nThis circuit is a bandgap ...', 图像='Bandgap70.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:43,545 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本=': 1. **PTAT Voltage Generation...', 图像='Bandgap71.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:43,655 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本=': Evidence for Bandgap Referen...', 图像='Bandgap72.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:43,769 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本=' **Evidence for Bandgap Behavi...', 图像='Bandgap73.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:43,861 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='1. **Presence of PTAT and CTAT...', 图像='Bandgap75.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:43,972 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='------\\nBased on the following...', 图像='Bandgap83.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:44,075 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='1. **Evidence 1:** Q1 and Q2 f...', 图像='Bandgap86.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:44,180 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\\n\\nThe provided circuit is ...', 图像='Bandgap87.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:44,277 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='1. **Presence of PTAT and CTAT...', 图像='Bandgap88.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:44,403 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "**Analysis Conclusion:**\n",
      "\n",
      "...', 图像='Comparator1.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:44,504 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='The circuit is confirmed to be...', 图像='Comparator10.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:44,611 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='The circuit is confirmed to be...', 图像='Comparator11.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:44,708 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='Based on the provided circuit ...', 图像='Comparator12.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:44,817 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='#### Evidence Confirming Compa...', 图像='Comparator13.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:44,930 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "#### **Evidence Supporting...', 图像='Comparator14.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:45,048 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "#### **Summary**\n",
      "The circu...', 图像='Comparator15.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:45,151 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='#### Evidence Supporting Compa...', 图像='Comparator16.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:45,265 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='Template\n",
      "\n",
      "**Analysis Conclusio...', 图像='Comparator17.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:45,384 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='This circuit is confirmed to b...', 图像='Comparator18.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:45,488 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='#### **Comparator Confirmation...', 图像='Comparator19.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:45,604 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "**Evidence Supporting Comp...', 图像='Comparator2.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:45,714 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "#### **Evidence Confirming...', 图像='Comparator20.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:45,823 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "Based on the provided circ...', 图像='Comparator21.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:45,934 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "#### **Evidence Supporting...', 图像='Comparator22.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:46,066 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "Based on the provided circ...', 图像='Comparator23.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:46,206 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='#### Evidence and Explanation:...', 图像='Comparator24.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:46,340 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='#### Comparator Confirmation:\n",
      "...', 图像='Comparator25.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:46,447 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "Based on the provided diag...', 图像='Comparator26.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:46,554 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "#### **Comparator Confirma...', 图像='Comparator27.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:46,662 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='#### **Evidence Supporting Com...', 图像='Comparator28.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:46,766 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "#### **Evidence Supporting...', 图像='Comparator29.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:46,865 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "#### **Evidence That This ...', 图像='Comparator3.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:46,979 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='#### Evidence Supporting Compa...', 图像='Comparator30.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:47,083 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='*Analysis Conclusion**\n",
      "\n",
      "Based ...', 图像='Comparator31.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:47,221 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "The circuit is confirmed t...', 图像='Comparator32.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:47,357 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "**Why This Circuit is a Co...', 图像='Comparator33.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:47,487 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "#### **Evidence Supporting...', 图像='Comparator34.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:47,604 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='#### **Evidence Supporting Com...', 图像='Comparator35.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:47,739 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='#### Evidence Supporting Compa...', 图像='Comparator36.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:47,859 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "#### **Evidence Supporting...', 图像='Comparator37.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:47,984 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "#### **Why is this Circuit...', 图像='Comparator38.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:48,113 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "#### **Evidence for Compar...', 图像='Comparator39.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:48,223 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='#### Confirmation of Comparato...', 图像='Comparator4.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:48,336 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "#### **Why This Circuit is...', 图像='Comparator40.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:48,445 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "#### **Evidence Supporting...', 图像='Comparator41.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:48,564 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "#### **Comparator Confirma...', 图像='Comparator42.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:48,692 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "**Evidence That This Circu...', 图像='Comparator43.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:48,810 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "#### Confirmation as Compa...', 图像='Comparator44.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:48,944 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='#### Evidence Confirming Compa...', 图像='Comparator45.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:49,060 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "Based on the detailed anal...', 图像='Comparator46.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:49,171 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "Based on the following evi...', 图像='Comparator47.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:49,283 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "Based on the provided circ...', 图像='Comparator48.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:49,378 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**Comparator Confirmation:**  ...', 图像='Comparator49.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:49,493 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='Based on the circuit structure...', 图像='Comparator5.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:49,618 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "Based on the detailed anal...', 图像='Comparator50.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:49,742 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "#### **Evidence Confirming...', 图像='Comparator51.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:49,854 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "Based on the circuit topol...', 图像='Comparator52.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:49,968 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "### **Comparator Confirmat...', 图像='Comparator53.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:50,091 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='#### Evidence and Confirmation...', 图像='Comparator54.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:50,223 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "#### **Comparator Confirma...', 图像='Comparator55.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:50,373 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "**Analysis Conclusion:**\n",
      "B...', 图像='Comparator56.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:50,525 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "Based on the following evi...', 图像='Comparator57.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:50,635 - INFO - [873340601.py.encode:502] - 编码完成对于 (图像='Comparator58.png')。成功生成的向量: 图像向量。\n",
      "2025-05-12 15:17:50,805 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='Template\n",
      "\n",
      "**Analysis Conclusio...', 图像='Comparator59.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:50,944 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "### **Why This Circuit is ...', 图像='Comparator6.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:51,139 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "Based on the circuit topol...', 图像='Comparator60.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:51,298 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**Confirmed Comparator Circuit...', 图像='Comparator61.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:51,455 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**Confirmation as Comparator C...', 图像='Comparator62.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:51,644 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='Based on explicit component re...', 图像='Comparator63.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:51,836 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='Based on the circuit diagram p...', 图像='Comparator64.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:52,020 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "Based on the detailed comp...', 图像='Comparator65.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:52,205 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='------------------\n",
      "\n",
      "**Conclusi...', 图像='Comparator66.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:52,359 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "#### **Evidence Supporting...', 图像='Comparator67.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:52,552 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "#### **Confirmation as a C...', 图像='Comparator68.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:52,727 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "#### **Why This Circuit is...', 图像='Comparator69.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:52,885 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "**Evidence-Based Confirmat...', 图像='Comparator7.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:53,065 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='Based on the circuit topology ...', 图像='Comparator70.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:53,239 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "#### **Evidence Supporting...', 图像='Comparator71.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:53,415 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "**This circuit is confirme...', 图像='Comparator72.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:53,570 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "Based on the structural an...', 图像='Comparator73.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:53,716 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='The provided circuit is confir...', 图像='Comparator74.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:53,861 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "**The circuit is confirmed...', 图像='Comparator75.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:54,020 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "**Confirmation:**\n",
      "The circ...', 图像='Comparator76.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:54,186 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='Template\n",
      "\n",
      "#### **Analysis Conc...', 图像='Comparator77.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:54,330 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "#### **Evidence for Compar...', 图像='Comparator78.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:54,389 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='#### Evidence of Comparator Fu...')。成功生成的向量: 文本向量。\n",
      "2025-05-12 15:17:54,559 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**Analysis Conclusion:**  \n",
      "Bas...', 图像='Comparator8.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:54,612 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='Template\n",
      "#### Analysis Conclus...')。成功生成的向量: 文本向量。\n",
      "2025-05-12 15:17:54,774 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "#### **Evidence Supporting...', 图像='Comparator81.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:54,832 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "Based on the following evid...')。成功生成的向量: 文本向量。\n",
      "2025-05-12 15:17:54,886 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "**Comparator Confirmation:...')。成功生成的向量: 文本向量。\n",
      "2025-05-12 15:17:55,049 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "Based on the provided circ...', 图像='Comparator84.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:55,105 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "**Based on the following e...')。成功生成的向量: 文本向量。\n",
      "2025-05-12 15:17:55,264 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "**Based on the provided ci...', 图像='Comparator86.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:55,322 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**Confirmation as a Comparator...')。成功生成的向量: 文本向量。\n",
      "2025-05-12 15:17:55,470 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='#### Evidence Supporting Compa...', 图像='Comparator88.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:55,638 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "#### **Comparator Confirma...', 图像='Comparator89.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:55,793 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "#### **Evidence the Circui...', 图像='Comparator9.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:55,948 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='#### Evidence Confirming Compa...', 图像='Comparator90.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:56,136 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "#### **Evidence Supporting...', 图像='Comparator91.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:56,306 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='**\n",
      "\n",
      "Based on the evidence prov...', 图像='Comparator92.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:56,452 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp100.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:56,613 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp101.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:56,773 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp107.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:56,912 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp108.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:57,075 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp109.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:57,231 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp110.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:57,387 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp111.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:57,544 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp114.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:57,695 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp118.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:57,827 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp119.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:57,983 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp12.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:58,134 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp125.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:58,273 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp126.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:58,417 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp127.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:58,563 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp130.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:58,717 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp131.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:58,857 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp132.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:59,001 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp134.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:59,149 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp135.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:59,295 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp137.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:59,444 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp138.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:59,580 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp139.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:59,736 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp14.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:17:59,912 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp140.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:00,120 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp141.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:00,436 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp143.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:01,141 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp146.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:01,391 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp147.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:01,694 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp148.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:01,946 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp149.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:02,140 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp150.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:02,319 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp152.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:02,500 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp153.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:02,665 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp158.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:02,809 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp161.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:02,964 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp162.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:03,124 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp163.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:03,277 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp165.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:03,430 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp18.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:03,579 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp21.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:03,716 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp22.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:03,894 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp23.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:04,046 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp24.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:04,212 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp25.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:04,360 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp26.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:04,494 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp28.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:04,640 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp29.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:04,784 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp30.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:04,938 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp31.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:05,069 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp32.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:05,212 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp34.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:05,349 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp40.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:05,509 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp44.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:05,651 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp45.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:05,794 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp48.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:05,937 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp51.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:06,081 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp53.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:06,232 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp56.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:06,380 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp57.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:06,530 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp58.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:06,682 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp59.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:06,827 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp60.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:06,965 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp61.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:07,100 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp62.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:07,249 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp69.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:07,394 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp70.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:07,540 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp73.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:07,685 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp74.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:07,843 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp8.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:07,984 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp81.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:08,141 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp86.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:08,294 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp88.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:08,442 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp89.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:08,592 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp91.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:08,731 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp92.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:08,880 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp98.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:09,017 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='\"Based on the following eviden...', 图像='op_amp99.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:09,018 - INFO - [873340601.py.index_documents:900] - 所有 219 个输入文档已遍历处理完毕。\n",
      "2025-05-12 15:18:09,019 - INFO - [873340601.py.index_documents:901] - 准备将收集到的向量批量添加到 Faiss 索引中...\n",
      "2025-05-12 15:18:09,020 - INFO - [873340601.py.index_documents:902] -   - 待添加文本向量数量: 218\n",
      "2025-05-12 15:18:09,021 - INFO - [873340601.py.index_documents:903] -   - 待添加图像向量数量: 213\n",
      "2025-05-12 15:18:09,021 - INFO - [873340601.py.index_documents:904] -   - 待添加平均向量数量: 212\n",
      "2025-05-12 15:18:09,023 - INFO - [873340601.py.index_documents:911] - 已成功向文本(Text) Faiss 索引批量添加 218 个向量。当前索引总数: 218\n",
      "2025-05-12 15:18:09,024 - INFO - [873340601.py.index_documents:917] - 已成功向图像(Image) Faiss 索引批量添加 213 个向量。当前索引总数: 213\n",
      "2025-05-12 15:18:09,025 - INFO - [873340601.py.index_documents:923] - 已成功向平均(Mean) Faiss 索引批量添加 212 个向量。当前索引总数: 212\n",
      "2025-05-12 15:18:09,037 - INFO - [873340601.py.index_documents:928] - 数据库事务已成功提交。所有元数据更改已持久化。\n",
      "2025-05-12 15:18:09,038 - INFO - [873340601.py.index_documents:945] - \n",
      "--- 文档索引过程总结 ---\n",
      "2025-05-12 15:18:09,039 - INFO - [873340601.py.index_documents:946] - - 输入文档总数: 219\n",
      "2025-05-12 15:18:09,040 - INFO - [873340601.py.index_documents:947] - - 成功处理并为其生成了至少一个向量的文档数: 219\n",
      "2025-05-12 15:18:09,041 - INFO - [873340601.py.index_documents:948] - - 因 'doc_id' 在数据库中已存在而跳过的文档数: 0\n",
      "2025-05-12 15:18:09,043 - INFO - [873340601.py.index_documents:949] - - 因编码阶段（文本/图像）错误而未能生成向量的文档数: 0\n",
      "2025-05-12 15:18:09,044 - INFO - [873340601.py.index_documents:950] - - 因数据库操作（如插入元数据）错误而跳过的文档数: 0\n",
      "2025-05-12 15:18:09,045 - INFO - [873340601.py.index_documents:951] - - 当前文本 Faiss 索引中的向量总数: 218\n",
      "2025-05-12 15:18:09,046 - INFO - [873340601.py.index_documents:952] - - 当前图像 Faiss 索引中的向量总数: 213\n",
      "2025-05-12 15:18:09,046 - INFO - [873340601.py.index_documents:953] - - 当前平均 Faiss 索引中的向量总数: 212\n",
      "2025-05-12 15:18:09,049 - INFO - [873340601.py.index_documents:956] - - 当前 SQLite 数据库中存储的文档元数据记录总数: 219\n",
      "2025-05-12 15:18:09,050 - INFO - [873340601.py.index_documents:965] - --- 文档索引过程结束 ---\n",
      "2025-05-12 15:18:09,051 - INFO - [873340601.py.<module>:1844] - Index building/loading complete. Current status:\n",
      "2025-05-12 15:18:09,053 - INFO - [873340601.py.<module>:1849] -   - SQLite Database ('multimodal_document_library.db') document records: 219\n",
      "2025-05-12 15:18:09,054 - INFO - [873340601.py.<module>:1850] -   - Text Faiss Index ('text_vector_index.faiss') vectors: 218\n",
      "2025-05-12 15:18:09,055 - INFO - [873340601.py.<module>:1851] -   - Image Faiss Index ('image_vector_index.faiss') vectors: 213\n",
      "2025-05-12 15:18:09,056 - INFO - [873340601.py.<module>:1852] -   - Mean Faiss Index ('mean_vector_index.faiss') vectors: 212\n",
      "2025-05-12 15:18:09,057 - INFO - [873340601.py.<module>:1867] - --- [Main Flow] Step 2 Complete. ---\n",
      "\n",
      "2025-05-12 15:18:09,259 - INFO - [873340601.py.<module>:1873] - --- [Main Flow] Step 3: Initializing Retriever ---\n",
      "2025-05-12 15:18:09,260 - INFO - [873340601.py.__init__:1216] - 开始初始化 Retriever...\n",
      "2025-05-12 15:18:09,261 - INFO - [873340601.py.__init__:1238] -   Retriever 将使用 Indexer 的编码器 (向量维度: 512)。\n",
      "2025-05-12 15:18:09,263 - INFO - [873340601.py.__init__:1255] - Retriever 初始化成功。关联的 Indexer 状态如下:\n",
      "2025-05-12 15:18:09,264 - INFO - [873340601.py.__init__:1256] -     - 文本(Text)索引中向量数: 218\n",
      "2025-05-12 15:18:09,265 - INFO - [873340601.py.__init__:1257] -     - 图像(Image)索引中向量数: 213\n",
      "2025-05-12 15:18:09,266 - INFO - [873340601.py.__init__:1258] -     - 平均(Mean)索引中向量数: 212\n",
      "2025-05-12 15:18:09,266 - INFO - [873340601.py.__init__:1259] - Retriever 初始化完成。\n",
      "2025-05-12 15:18:09,267 - INFO - [873340601.py.<module>:1892] - --- [Main Flow] Step 3 Complete. ---\n",
      "\n",
      "2025-05-12 15:18:09,468 - INFO - [873340601.py.<module>:1898] - --- [Main Flow] Step 4: Initializing Generator (will interact with ZhipuAI API) ---\n",
      "2025-05-12 15:18:09,469 - INFO - [873340601.py.<module>:1910] - ZHIPUAI_API_KEY detected in environment variables. Attempting to initialize Generator...\n",
      "2025-05-12 15:18:09,469 - INFO - [873340601.py.__init__:1515] - 开始初始化 Generator，准备使用 ZhipuAI 模型: glm-4-flash\n",
      "2025-05-12 15:18:09,470 - INFO - [873340601.py.__init__:1529] - 成功获取到 ZhipuAI API Key (来源可能是参数或环境变量)。\n",
      "2025-05-12 15:18:10,022 - INFO - [873340601.py.__init__:1534] - ZhipuAI 客户端已使用模型 'glm-4-flash' 成功初始化。\n",
      "2025-05-12 15:18:10,023 - INFO - [873340601.py.__init__:1543] - Generator 初始化成功完成。\n",
      "2025-05-12 15:18:10,024 - INFO - [873340601.py.<module>:1917] - --- [Main Flow] Step 4 Complete. ---\n",
      "\n",
      "2025-05-12 15:18:10,226 - INFO - [873340601.py.<module>:1923] - --- [Main Flow] Step 5: Executing RAG Query Examples (Retrieval + Generation) ---\n",
      "2025-05-12 15:18:10,228 - INFO - [873340601.py.<module>:1926] - Retriever and Generator have been successfully initialized. Proceeding with example queries...\n",
      "2025-05-12 15:18:10,260 - INFO - [873340601.py.<module>:1968] - Found 213 documents with valid images. Will randomly select 1 for image/multimodal query examples.\n",
      "2025-05-12 15:18:10,262 - INFO - [873340601.py.<module>:2003] - \n",
      "######################################################################\n",
      ">>> Starting Example Queries for Type: [Pure_Text_Queries] (Total in this group: 2) <<<\n",
      "######################################################################\n",
      "\n",
      "2025-05-12 15:18:10,264 - INFO - [873340601.py.<module>:2029] - \n",
      "--- Processing Query #1 (Type: Pure_Text_Queries - Index: 1/2) ---\n",
      "2025-05-12 15:18:10,265 - INFO - [873340601.py.<module>:2030] - Query Description: What is a bandgap voltage reference and its main purpose?\n",
      "2025-05-12 15:18:10,266 - INFO - [873340601.py.<module>:2036] -   -> Question text for Generator: 'What is a bandgap voltage reference and its main purpose?...'\n",
      "2025-05-12 15:18:10,267 - INFO - [873340601.py.<module>:2037] - ------------------------------\n",
      "2025-05-12 15:18:10,267 - INFO - [873340601.py.<module>:2041] -   Detailed results for this query will be saved in: Multimodal_RAG_System_Run_20250512_151657\\query_session_results\\query_001_TextQuery_What_is_a_bandgap_voltage_reference_and_its_main_p\n",
      "2025-05-12 15:18:10,269 - INFO - [873340601.py.<module>:2057] -   [Retrieval Phase] Calling Retriever.retrieve() method...\n",
      "2025-05-12 15:18:10,270 - INFO - [873340601.py.retrieve:1287] - 开始执行检索流程，目标是获取 Top-2 最相关的文档...\n",
      "2025-05-12 15:18:10,270 - INFO - [873340601.py.retrieve:1301] -     查询类型确定为: 纯文本 (字符串输入)\n",
      "2025-05-12 15:18:10,272 - INFO - [873340601.py.retrieve:1302] -     查询文本内容: 'What is a bandgap voltage reference and its main purpose?'\n",
      "2025-05-12 15:18:10,296 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='What is a bandgap voltage refe...')。成功生成的向量: 文本向量。\n",
      "2025-05-12 15:18:10,299 - INFO - [873340601.py.retrieve:1344] -     查询编码完成。\n",
      "2025-05-12 15:18:10,300 - INFO - [873340601.py.retrieve:1368] -     搜索策略: 使用文本查询向量，在 文本(Text)索引 (含 218 个向量) 中搜索。\n",
      "2025-05-12 15:18:10,317 - INFO - [873340601.py.retrieve:1435] -     Faiss 搜索在 '文本(Text)索引' 中完成，初步找到 2 个候选文档的 internal_id。\n",
      "2025-05-12 15:18:10,319 - INFO - [873340601.py.retrieve:1444] -     已成功从数据库中获取了 2 条与 internal_id 对应的文档记录。\n",
      "2025-05-12 15:18:10,321 - INFO - [873340601.py.retrieve:1460] - 检索流程成功完成，最终返回 2 个文档（已按相似度排序）。\n",
      "2025-05-12 15:18:10,321 - INFO - [873340601.py.log_retrieved_docs_summary_for_main_process:1932] -     >> Retrieval Result: Found Top-2 relevant documents. Summary:\n",
      "2025-05-12 15:18:10,322 - INFO - [873340601.py.log_retrieved_docs_summary_for_main_process:1941] -       1. DocID: Bandgap40 (Score: 0.8724)\n",
      "2025-05-12 15:18:10,323 - INFO - [873340601.py.log_retrieved_docs_summary_for_main_process:1942] -          Text Preview: ': Evidence for Bandgap Reference Circuit Identification:**\\n1. **PTAT ...', Associated Image: 'Bandgap40.png'\n",
      "2025-05-12 15:18:10,324 - INFO - [873340601.py.log_retrieved_docs_summary_for_main_process:1941] -       2. DocID: Bandgap31 (Score: 0.8659)\n",
      "2025-05-12 15:18:10,325 - INFO - [873340601.py.log_retrieved_docs_summary_for_main_process:1942] -          Text Preview: '**\\n\\n**Evidence for Bandgap Reference Circuit Identification:**\\n\\n1....', Associated Image: 'Bandgap31.png'\n",
      "2025-05-12 15:18:10,326 - INFO - [873340601.py.log_retrieved_docs_summary_for_main_process:1943] -     ----------------------------------------\n",
      "2025-05-12 15:18:10,327 - INFO - [873340601.py.<module>:2068] -   [Generation Phase] Calling Generator.generate() method (using retrieved context)...\n",
      "2025-05-12 15:18:10,329 - INFO - [873340601.py.generate:1559] - 开始为查询生成最终响应...\n",
      "2025-05-12 15:18:10,330 - INFO - [873340601.py.generate:1560] -   接收到的用户查询: 'What is a bandgap voltage reference and its main purpose?'\n",
      "2025-05-12 15:18:10,331 - INFO - [873340601.py.generate:1561] -   使用 2 个检索到的文档作为生成上下文。\n",
      "2025-05-12 15:18:10,331 - INFO - [873340601.py._build_messages:1686] -     正在将 2 个检索到的文档格式化为 LLM 的上下文...\n",
      "2025-05-12 15:18:10,332 - INFO - [873340601.py.generate:1583] -   - Generator步骤 2: 开始调用 ZhipuAI Chat API (使用模型: glm-4-flash)...\n",
      "2025-05-12 15:18:20,461 - INFO - [873340601.py.generate:1595] -     ZhipuAI API 调用成功。已接收到模型的响应。\n",
      "2025-05-12 15:18:20,463 - INFO - [873340601.py.generate:1606] -       Token 使用情况 -> 输入提示: 1066 tokens, 生成响应: 250 tokens, 总计: 1316 tokens.\n",
      "2025-05-12 15:18:20,463 - INFO - [873340601.py.generate:1642] - LLM 响应生成流程结束。\n",
      "2025-05-12 15:18:20,464 - INFO - [873340601.py.<module>:2072] - \n",
      "  <<< LLM Final Response for Query #1 >>>\n",
      "2025-05-12 15:18:20,465 - INFO - [873340601.py.<module>:2073] - -----------------------------------\n",
      "2025-05-12 15:18:20,465 - INFO - [873340601.py.<module>:2074] - A bandgap voltage reference is a type of electronic circuit used in integrated circuits (ICs) to provide a stable voltage reference that is independent of temperature variations and supply voltage fluctuations. The main purpose of a bandgap voltage reference is to generate a precise and stable reference voltage which can be used for various applications within the IC, such as:\n",
      "\n",
      "1. **Temperature Compensation:** A bandgap reference generates a voltage that is proportional to the temperature, allowing for compensation of temperature-related errors in other circuit components.\n",
      "2. **Supply Voltage Stability:** It provides a stable voltage reference that remains constant despite variations in the supply voltage.\n",
      "3. **Accuracy and Precision:** The bandgap reference is designed to be highly accurate and precise, ensuring reliable performance in the IC.\n",
      "4. **Wide Operating Range:** It can operate over a wide range of temperatures and supply voltages, making it suitable for various environments and applications.\n",
      "\n",
      "The circuit typically consists of transistors and resistors that generate a voltage proportional to the bandgap voltage (approximately 1.2V at room temperature), which is then used as a reference voltage. The bandgap reference is characterized by its low temperature coefficient, which means it maintains a stable output voltage over a wide range of temperatures.\n",
      "2025-05-12 15:18:20,466 - INFO - [873340601.py.<module>:2075] - -----------------------------------\n",
      "2025-05-12 15:18:20,467 - INFO - [873340601.py.<module>:2097] - --- Query #1 processing complete ---\n",
      "2025-05-12 15:18:20,467 - INFO - [873340601.py.<module>:2100] - \n",
      "...Pausing for 0.5 seconds before next query in this group...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "2025-05-12 15:18:20,968 - INFO - [873340601.py.<module>:2029] - \n",
      "--- Processing Query #2 (Type: Pure_Text_Queries - Index: 2/2) ---\n",
      "2025-05-12 15:18:20,970 - INFO - [873340601.py.<module>:2030] - Query Description: Explain how PTAT current is generated and its role in bandgap circuits.\n",
      "2025-05-12 15:18:20,971 - INFO - [873340601.py.<module>:2036] -   -> Question text for Generator: 'Explain how PTAT current is generated and its role in bandgap circuits....'\n",
      "2025-05-12 15:18:20,973 - INFO - [873340601.py.<module>:2037] - ------------------------------\n",
      "2025-05-12 15:18:20,977 - INFO - [873340601.py.<module>:2041] -   Detailed results for this query will be saved in: Multimodal_RAG_System_Run_20250512_151657\\query_session_results\\query_002_TextQuery_Explain_how_PTAT_current_is_generated_and_its_role\n",
      "2025-05-12 15:18:20,978 - INFO - [873340601.py.<module>:2057] -   [Retrieval Phase] Calling Retriever.retrieve() method...\n",
      "2025-05-12 15:18:20,979 - INFO - [873340601.py.retrieve:1287] - 开始执行检索流程，目标是获取 Top-2 最相关的文档...\n",
      "2025-05-12 15:18:20,980 - INFO - [873340601.py.retrieve:1301] -     查询类型确定为: 纯文本 (字符串输入)\n",
      "2025-05-12 15:18:20,980 - INFO - [873340601.py.retrieve:1302] -     查询文本内容: 'Explain how PTAT current is generated and its role in bandgap circuits.'\n",
      "2025-05-12 15:18:21,005 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='Explain how PTAT current is ge...')。成功生成的向量: 文本向量。\n",
      "2025-05-12 15:18:21,006 - INFO - [873340601.py.retrieve:1344] -     查询编码完成。\n",
      "2025-05-12 15:18:21,007 - INFO - [873340601.py.retrieve:1368] -     搜索策略: 使用文本查询向量，在 文本(Text)索引 (含 218 个向量) 中搜索。\n",
      "2025-05-12 15:18:21,008 - INFO - [873340601.py.retrieve:1435] -     Faiss 搜索在 '文本(Text)索引' 中完成，初步找到 2 个候选文档的 internal_id。\n",
      "2025-05-12 15:18:21,010 - INFO - [873340601.py.retrieve:1444] -     已成功从数据库中获取了 2 条与 internal_id 对应的文档记录。\n",
      "2025-05-12 15:18:21,011 - INFO - [873340601.py.retrieve:1460] - 检索流程成功完成，最终返回 2 个文档（已按相似度排序）。\n",
      "2025-05-12 15:18:21,012 - INFO - [873340601.py.log_retrieved_docs_summary_for_main_process:1932] -     >> Retrieval Result: Found Top-2 relevant documents. Summary:\n",
      "2025-05-12 15:18:21,013 - INFO - [873340601.py.log_retrieved_docs_summary_for_main_process:1941] -       1. DocID: Bandgap68 (Score: 0.8875)\n",
      "2025-05-12 15:18:21,013 - INFO - [873340601.py.log_retrieved_docs_summary_for_main_process:1942] -          Text Preview: '**\\n\\nThis circuit can be conclusively identified as a **bandgap refer...', Associated Image: 'Bandgap68.png'\n",
      "2025-05-12 15:18:21,014 - INFO - [873340601.py.log_retrieved_docs_summary_for_main_process:1941] -       2. DocID: Bandgap59 (Score: 0.8867)\n",
      "2025-05-12 15:18:21,014 - INFO - [873340601.py.log_retrieved_docs_summary_for_main_process:1942] -          Text Preview: ': This circuit can be considered a bandgap reference circuit because o...', Associated Image: 'Bandgap59.png'\n",
      "2025-05-12 15:18:21,015 - INFO - [873340601.py.log_retrieved_docs_summary_for_main_process:1943] -     ----------------------------------------\n",
      "2025-05-12 15:18:21,016 - INFO - [873340601.py.<module>:2068] -   [Generation Phase] Calling Generator.generate() method (using retrieved context)...\n",
      "2025-05-12 15:18:21,017 - INFO - [873340601.py.generate:1559] - 开始为查询生成最终响应...\n",
      "2025-05-12 15:18:21,017 - INFO - [873340601.py.generate:1560] -   接收到的用户查询: 'Explain how PTAT current is generated and its role in bandgap circuits.'\n",
      "2025-05-12 15:18:21,018 - INFO - [873340601.py.generate:1561] -   使用 2 个检索到的文档作为生成上下文。\n",
      "2025-05-12 15:18:21,018 - INFO - [873340601.py._build_messages:1686] -     正在将 2 个检索到的文档格式化为 LLM 的上下文...\n",
      "2025-05-12 15:18:21,019 - INFO - [873340601.py.generate:1583] -   - Generator步骤 2: 开始调用 ZhipuAI Chat API (使用模型: glm-4-flash)...\n",
      "2025-05-12 15:18:29,948 - INFO - [873340601.py.generate:1595] -     ZhipuAI API 调用成功。已接收到模型的响应。\n",
      "2025-05-12 15:18:29,949 - INFO - [873340601.py.generate:1606] -       Token 使用情况 -> 输入提示: 1078 tokens, 生成响应: 432 tokens, 总计: 1510 tokens.\n",
      "2025-05-12 15:18:29,950 - INFO - [873340601.py.generate:1642] - LLM 响应生成流程结束。\n",
      "2025-05-12 15:18:29,951 - INFO - [873340601.py.<module>:2072] - \n",
      "  <<< LLM Final Response for Query #2 >>>\n",
      "2025-05-12 15:18:29,952 - INFO - [873340601.py.<module>:2073] - -----------------------------------\n",
      "2025-05-12 15:18:29,952 - INFO - [873340601.py.<module>:2074] - PTAT (Proportional To Absolute Temperature) current is generated in bandgap reference circuits through the use of components whose voltages change with temperature. Here's how it is generated and its role in bandgap circuits:\n",
      "\n",
      "1. **Generation of PTAT Current:**\n",
      "   - **Bipolar Transistors (Q1, Q2, and R0-R2):** In the bandgap reference circuit, transistors Q1 and Q2, along with resistors R0-R2, form a part of the circuit that generates a PTAT voltage. The voltage across these components, specifically the difference in \\( V_{BE} \\) (voltage across the base-emitter junction) of Q1 and Q2, changes with temperature.\n",
      "   - **Temperature Dependence:** The \\( \\Delta V_{BE} \\) (difference in \\( V_{BE} \\)) between Q1 and Q2 is temperature-dependent. This is because the base-emitter junction of a bipolar transistor has a voltage that increases approximately 2.5 millivolts per degree Celsius (mV/°C) at room temperature.\n",
      "\n",
      "2. **Role in Bandgap Circuits:**\n",
      "   - **Temperature Compensation:** The PTAT current and voltage components are crucial for temperature compensation in bandgap reference circuits. They help in reducing the temperature dependence of the reference voltage.\n",
      "   - **Stable Reference Voltage:** By combining the PTAT and CTAT (Coefficient Temperature) components, the bandgap reference circuit can produce a stable reference voltage that is less sensitive to temperature variations. This is essential for ensuring that the output voltage of the circuit remains constant across a range of temperatures.\n",
      "   - **Alignment with Bandgap Energy:** The PTAT voltage in a bandgap reference circuit is often aligned with the bandgap energy of silicon, which is approximately 1.2 volts at room temperature. This alignment provides a stable and accurate reference voltage for various electronic applications.\n",
      "\n",
      "In summary, PTAT current is generated through temperature-dependent components in a bandgap reference circuit, and its role is to provide temperature compensation and contribute to the stability of the reference voltage.\n",
      "2025-05-12 15:18:29,953 - INFO - [873340601.py.<module>:2075] - -----------------------------------\n",
      "2025-05-12 15:18:29,954 - INFO - [873340601.py.<module>:2097] - --- Query #2 processing complete ---\n",
      "2025-05-12 15:18:29,954 - INFO - [873340601.py.<module>:2103] - \n",
      "######################################################################\n",
      ">>> All example queries for type [Pure_Text_Queries] have been processed <<<\n",
      "######################################################################\n",
      "\n",
      "2025-05-12 15:18:30,456 - INFO - [873340601.py.<module>:2003] - \n",
      "######################################################################\n",
      ">>> Starting Example Queries for Type: [Pure_Image_Queries] (Total in this group: 1) <<<\n",
      "######################################################################\n",
      "\n",
      "2025-05-12 15:18:30,458 - INFO - [873340601.py.<module>:2029] - \n",
      "--- Processing Query #3 (Type: Pure_Image_Queries - Index: 1/1) ---\n",
      "2025-05-12 15:18:30,458 - INFO - [873340601.py.<module>:2030] - Query Description: PureImageQuery_About_Bandgap52.png\n",
      "2025-05-12 15:18:30,460 - INFO - [873340601.py.<module>:2035] -   -> Input image for Retriever: 'Bandgap52.png'\n",
      "2025-05-12 15:18:30,460 - INFO - [873340601.py.<module>:2036] -   -> Question text for Generator: 'This image (filename: Bandgap52.png) primarily shows what circuit structure or key concept? Please e...'\n",
      "2025-05-12 15:18:30,461 - INFO - [873340601.py.<module>:2037] - ------------------------------\n",
      "2025-05-12 15:18:30,462 - INFO - [873340601.py.<module>:2041] -   Detailed results for this query will be saved in: Multimodal_RAG_System_Run_20250512_151657\\query_session_results\\query_003_PureImageQuery_About_Bandgap52.png\n",
      "2025-05-12 15:18:30,463 - INFO - [873340601.py.<module>:2057] -   [Retrieval Phase] Calling Retriever.retrieve() method...\n",
      "2025-05-12 15:18:30,464 - INFO - [873340601.py.retrieve:1287] - 开始执行检索流程，目标是获取 Top-2 最相关的文档...\n",
      "2025-05-12 15:18:30,465 - INFO - [873340601.py.retrieve:1320] -     查询类型确定为: 纯图像\n",
      "2025-05-12 15:18:30,465 - INFO - [873340601.py.retrieve:1321] -     查询图像路径: 'Bandgap52.png'\n",
      "2025-05-12 15:18:30,530 - INFO - [873340601.py.encode:502] - 编码完成对于 (图像='Bandgap52.png')。成功生成的向量: 图像向量。\n",
      "2025-05-12 15:18:30,531 - INFO - [873340601.py.retrieve:1344] -     查询编码完成。\n",
      "2025-05-12 15:18:30,531 - INFO - [873340601.py.retrieve:1378] -     搜索策略: 使用图像查询向量，在 图像(Image)索引 (含 213 个向量) 中搜索。\n",
      "2025-05-12 15:18:30,532 - INFO - [873340601.py.retrieve:1435] -     Faiss 搜索在 '图像(Image)索引' 中完成，初步找到 2 个候选文档的 internal_id。\n",
      "2025-05-12 15:18:30,533 - INFO - [873340601.py.retrieve:1444] -     已成功从数据库中获取了 2 条与 internal_id 对应的文档记录。\n",
      "2025-05-12 15:18:30,534 - INFO - [873340601.py.retrieve:1460] - 检索流程成功完成，最终返回 2 个文档（已按相似度排序）。\n",
      "2025-05-12 15:18:30,535 - INFO - [873340601.py.log_retrieved_docs_summary_for_main_process:1932] -     >> Retrieval Result: Found Top-2 relevant documents. Summary:\n",
      "2025-05-12 15:18:30,535 - INFO - [873340601.py.log_retrieved_docs_summary_for_main_process:1941] -       1. DocID: Bandgap52 (Score: 1.0000)\n",
      "2025-05-12 15:18:30,536 - INFO - [873340601.py.log_retrieved_docs_summary_for_main_process:1942] -          Text Preview: '**\\n\\nBased on the provided circuit diagram:\\n\\n1. **Evidence for Band...', Associated Image: 'Bandgap52.png'\n",
      "2025-05-12 15:18:30,536 - INFO - [873340601.py.log_retrieved_docs_summary_for_main_process:1941] -       2. DocID: Bandgap60 (Score: 0.9357)\n",
      "2025-05-12 15:18:30,537 - INFO - [873340601.py.log_retrieved_docs_summary_for_main_process:1942] -          Text Preview: 'The provided circuit is indeed a **Bandgap reference circuit** based o...', Associated Image: 'Bandgap60.png'\n",
      "2025-05-12 15:18:30,537 - INFO - [873340601.py.log_retrieved_docs_summary_for_main_process:1943] -     ----------------------------------------\n",
      "2025-05-12 15:18:30,538 - INFO - [873340601.py.<module>:2068] -   [Generation Phase] Calling Generator.generate() method (using retrieved context)...\n",
      "2025-05-12 15:18:30,539 - INFO - [873340601.py.generate:1559] - 开始为查询生成最终响应...\n",
      "2025-05-12 15:18:30,540 - INFO - [873340601.py.generate:1560] -   接收到的用户查询: 'This image (filename: Bandgap52.png) primarily shows what circuit structure or key concept? Please e...'\n",
      "2025-05-12 15:18:30,540 - INFO - [873340601.py.generate:1561] -   使用 2 个检索到的文档作为生成上下文。\n",
      "2025-05-12 15:18:30,541 - INFO - [873340601.py._build_messages:1686] -     正在将 2 个检索到的文档格式化为 LLM 的上下文...\n",
      "2025-05-12 15:18:30,541 - INFO - [873340601.py.generate:1583] -   - Generator步骤 2: 开始调用 ZhipuAI Chat API (使用模型: glm-4-flash)...\n",
      "2025-05-12 15:18:36,773 - INFO - [873340601.py.generate:1595] -     ZhipuAI API 调用成功。已接收到模型的响应。\n",
      "2025-05-12 15:18:36,774 - INFO - [873340601.py.generate:1606] -       Token 使用情况 -> 输入提示: 1029 tokens, 生成响应: 292 tokens, 总计: 1321 tokens.\n",
      "2025-05-12 15:18:36,775 - INFO - [873340601.py.generate:1642] - LLM 响应生成流程结束。\n",
      "2025-05-12 15:18:36,776 - INFO - [873340601.py.<module>:2072] - \n",
      "  <<< LLM Final Response for Query #3 >>>\n",
      "2025-05-12 15:18:36,778 - INFO - [873340601.py.<module>:2073] - -----------------------------------\n",
      "2025-05-12 15:18:36,778 - INFO - [873340601.py.<module>:2074] - The image with the filename 'Bandgap52.png' primarily shows a Bandgap Reference Circuit. This is detailed in the text description of the associated document as follows:\n",
      "\n",
      "1. **Evidence for Bandgap Reference Identification:**\n",
      "   - Presence of PTAT generator (Q1 & Q2): This refers to the presence of transistors Q1 and Q2 that generate a Positive Temperature Coefficient (PTAT) voltage.\n",
      "   - CTAT source (Q3): This indicates the presence of a transistor Q3 that serves as a Current Temperature Coefficient (CTAT) source.\n",
      "   - Resistor network (R1-R2) for temperature coefficient balancing: This suggests the use of resistors R1 and R2 in a network to balance temperature coefficients.\n",
      "   - Stable output voltage (~1.2V) at V<sub>REF</sub>: This points to the circuit's ability to provide a stable output voltage, approximately 1.2V, at the V<sub>REF</sub> node.\n",
      "   - Feedback and current mirror structures ensuring voltage stability: This implies the presence of feedback and current mirror structures in the circuit to maintain voltage stability.\n",
      "\n",
      "In summary, the image depicts a Bandgap Reference Circuit, which is capable of generating a stable reference voltage independent of temperature and supply variations. This type of circuit is crucial for applications where a stable voltage reference is needed, regardless of temperature changes or fluctuations in the supply voltage.\n",
      "2025-05-12 15:18:36,779 - INFO - [873340601.py.<module>:2075] - -----------------------------------\n",
      "2025-05-12 15:18:36,782 - INFO - [873340601.py.<module>:2097] - --- Query #3 processing complete ---\n",
      "2025-05-12 15:18:36,782 - INFO - [873340601.py.<module>:2103] - \n",
      "######################################################################\n",
      ">>> All example queries for type [Pure_Image_Queries] have been processed <<<\n",
      "######################################################################\n",
      "\n",
      "2025-05-12 15:18:37,284 - INFO - [873340601.py.<module>:2003] - \n",
      "######################################################################\n",
      ">>> Starting Example Queries for Type: [Multimodal_Queries] (Total in this group: 1) <<<\n",
      "######################################################################\n",
      "\n",
      "2025-05-12 15:18:37,286 - INFO - [873340601.py.<module>:2029] - \n",
      "--- Processing Query #4 (Type: Multimodal_Queries - Index: 1/1) ---\n",
      "2025-05-12 15:18:37,287 - INFO - [873340601.py.<module>:2030] - Query Description: MultimodalQuery_Explain_Image_Bandgap52.png\n",
      "2025-05-12 15:18:37,288 - INFO - [873340601.py.<module>:2033] -   -> Input text for Retriever: 'Combining the document content and this image (filename: Bandgap52.png), please ...'\n",
      "2025-05-12 15:18:37,289 - INFO - [873340601.py.<module>:2035] -   -> Input image for Retriever: 'Bandgap52.png'\n",
      "2025-05-12 15:18:37,290 - INFO - [873340601.py.<module>:2036] -   -> Question text for Generator: 'Combining the document content and this image (filename: Bandgap52.png), please explain the working ...'\n",
      "2025-05-12 15:18:37,291 - INFO - [873340601.py.<module>:2037] - ------------------------------\n",
      "2025-05-12 15:18:37,293 - INFO - [873340601.py.<module>:2041] -   Detailed results for this query will be saved in: Multimodal_RAG_System_Run_20250512_151657\\query_session_results\\query_004_MultimodalQuery_Explain_Image_Bandgap52.png\n",
      "2025-05-12 15:18:37,295 - INFO - [873340601.py.<module>:2057] -   [Retrieval Phase] Calling Retriever.retrieve() method...\n",
      "2025-05-12 15:18:37,296 - INFO - [873340601.py.retrieve:1287] - 开始执行检索流程，目标是获取 Top-2 最相关的文档...\n",
      "2025-05-12 15:18:37,298 - INFO - [873340601.py.retrieve:1315] -     查询类型确定为: 多模态\n",
      "2025-05-12 15:18:37,300 - INFO - [873340601.py.retrieve:1316] -     查询文本部分: 'Combining the document content and this image (fil...'\n",
      "2025-05-12 15:18:37,301 - INFO - [873340601.py.retrieve:1317] -     查询图像部分: 'Bandgap52.png'\n",
      "2025-05-12 15:18:37,419 - INFO - [873340601.py.encode:502] - 编码完成对于 (文本='Combining the document content...', 图像='Bandgap52.png')。成功生成的向量: 文本向量, 图像向量, 平均向量。\n",
      "2025-05-12 15:18:37,420 - INFO - [873340601.py.retrieve:1344] -     查询编码完成。\n",
      "2025-05-12 15:18:37,420 - INFO - [873340601.py.retrieve:1388] -     搜索策略: 使用平均查询向量，在 平均(Mean)索引 (含 212 个向量) 中搜索。\n",
      "2025-05-12 15:18:37,421 - INFO - [873340601.py.retrieve:1435] -     Faiss 搜索在 '平均(Mean)索引' 中完成，初步找到 2 个候选文档的 internal_id。\n",
      "2025-05-12 15:18:37,423 - INFO - [873340601.py.retrieve:1444] -     已成功从数据库中获取了 2 条与 internal_id 对应的文档记录。\n",
      "2025-05-12 15:18:37,423 - INFO - [873340601.py.retrieve:1460] - 检索流程成功完成，最终返回 2 个文档（已按相似度排序）。\n",
      "2025-05-12 15:18:37,424 - INFO - [873340601.py.log_retrieved_docs_summary_for_main_process:1932] -     >> Retrieval Result: Found Top-2 relevant documents. Summary:\n",
      "2025-05-12 15:18:37,425 - INFO - [873340601.py.log_retrieved_docs_summary_for_main_process:1941] -       1. DocID: Bandgap52 (Score: 0.9526)\n",
      "2025-05-12 15:18:37,426 - INFO - [873340601.py.log_retrieved_docs_summary_for_main_process:1942] -          Text Preview: '**\\n\\nBased on the provided circuit diagram:\\n\\n1. **Evidence for Band...', Associated Image: 'Bandgap52.png'\n",
      "2025-05-12 15:18:37,426 - INFO - [873340601.py.log_retrieved_docs_summary_for_main_process:1941] -       2. DocID: Bandgap60 (Score: 0.9171)\n",
      "2025-05-12 15:18:37,427 - INFO - [873340601.py.log_retrieved_docs_summary_for_main_process:1942] -          Text Preview: 'The provided circuit is indeed a **Bandgap reference circuit** based o...', Associated Image: 'Bandgap60.png'\n",
      "2025-05-12 15:18:37,428 - INFO - [873340601.py.log_retrieved_docs_summary_for_main_process:1943] -     ----------------------------------------\n",
      "2025-05-12 15:18:37,430 - INFO - [873340601.py.<module>:2068] -   [Generation Phase] Calling Generator.generate() method (using retrieved context)...\n",
      "2025-05-12 15:18:37,431 - INFO - [873340601.py.generate:1559] - 开始为查询生成最终响应...\n",
      "2025-05-12 15:18:37,432 - INFO - [873340601.py.generate:1560] -   接收到的用户查询: 'Combining the document content and this image (filename: Bandgap52.png), please explain the working ...'\n",
      "2025-05-12 15:18:37,433 - INFO - [873340601.py.generate:1561] -   使用 2 个检索到的文档作为生成上下文。\n",
      "2025-05-12 15:18:37,433 - INFO - [873340601.py._build_messages:1686] -     正在将 2 个检索到的文档格式化为 LLM 的上下文...\n",
      "2025-05-12 15:18:37,434 - INFO - [873340601.py.generate:1583] -   - Generator步骤 2: 开始调用 ZhipuAI Chat API (使用模型: glm-4-flash)...\n",
      "2025-05-12 15:18:49,833 - INFO - [873340601.py.generate:1595] -     ZhipuAI API 调用成功。已接收到模型的响应。\n",
      "2025-05-12 15:18:49,835 - INFO - [873340601.py.generate:1606] -       Token 使用情况 -> 输入提示: 1030 tokens, 生成响应: 452 tokens, 总计: 1482 tokens.\n",
      "2025-05-12 15:18:49,836 - INFO - [873340601.py.generate:1642] - LLM 响应生成流程结束。\n",
      "2025-05-12 15:18:49,837 - INFO - [873340601.py.<module>:2072] - \n",
      "  <<< LLM Final Response for Query #4 >>>\n",
      "2025-05-12 15:18:49,838 - INFO - [873340601.py.<module>:2073] - -----------------------------------\n",
      "2025-05-12 15:18:49,839 - INFO - [873340601.py.<module>:2074] - Based on the provided reference documents and the image filename 'Bandgap52.png', the circuit shown is a Bandgap Reference Circuit. Here are the working principle, key features, and design considerations:\n",
      "\n",
      "**Working Principle:**\n",
      "1. **PTAT (Proportional to Absolute Temperature) Generator**: The presence of transistors Q1 and Q2, which function as a PTAT generator, is a key component. This generator produces a voltage that is proportional to the absolute temperature.\n",
      "2. **CTAT (Current-temperature) Source**: Transistor Q3 serves as a CTAT source, providing a voltage that varies inversely with temperature.\n",
      "3. **Temperature Coefficient Balancing**: The resistor network (R1-R2) is designed to balance the temperature coefficients of the PTAT and CTAT components.\n",
      "4. **Stable Output Voltage**: The circuit ensures a stable output voltage at VREF, which is approximately 1.2V, independent of temperature and supply variations.\n",
      "5. **Feedback and Current Mirror Structures**: These structures contribute to the voltage stability of the circuit.\n",
      "\n",
      "**Key Features:**\n",
      "1. **Temperature Independence**: The circuit generates a stable reference voltage that is independent of temperature variations.\n",
      "2. **Supply Variations Insensitivity**: The stability of the reference voltage is not affected by changes in supply voltage.\n",
      "3. **High Precision**: The use of PTAT and CTAT generators, along with the resistor network, ensures high precision in the output voltage.\n",
      "4. **Stable Output Voltage**: The output voltage at VREF is stable and reliable.\n",
      "\n",
      "**Design Considerations:**\n",
      "1. **Accurate PTAT and CTAT Components**: The selection and design of the PTAT and CTAT components are crucial for the accuracy and stability of the reference voltage.\n",
      "2. **Temperature Coefficient Balancing**: Proper configuration of the resistor network (R1-R2) is essential to balance the temperature coefficients of the PTAT and CTAT components.\n",
      "3. **Feedback and Current Mirror Structures**: These structures are designed to maintain voltage stability and accuracy.\n",
      "4. **Output Voltage Stability**: The overall design focuses on ensuring a stable output voltage at VREF, which is crucial for various applications requiring accurate and stable voltage references.\n",
      "2025-05-12 15:18:49,839 - INFO - [873340601.py.<module>:2075] - -----------------------------------\n",
      "2025-05-12 15:18:49,841 - INFO - [873340601.py.<module>:2097] - --- Query #4 processing complete ---\n",
      "2025-05-12 15:18:49,841 - INFO - [873340601.py.<module>:2103] - \n",
      "######################################################################\n",
      ">>> All example queries for type [Multimodal_Queries] have been processed <<<\n",
      "######################################################################\n",
      "\n",
      "2025-05-12 15:18:50,343 - INFO - [873340601.py.<module>:2116] - --- [Main Flow] Step 5 (RAG Query Examples) Complete. ---\n",
      "\n",
      "2025-05-12 15:18:50,345 - INFO - [873340601.py.<module>:2121] - --- [Main Flow] Step 6: Cleaning up and closing system resources ---\n",
      "2025-05-12 15:18:50,346 - INFO - [873340601.py.close:1470] - 开始关闭 Retriever 实例...\n",
      "2025-05-12 15:18:50,348 - INFO - [873340601.py.close:1472] - Retriever 实例关闭完成。\n",
      "2025-05-12 15:18:50,349 - INFO - [873340601.py.close:1744] - 开始关闭 Generator 实例...\n",
      "2025-05-12 15:18:50,349 - INFO - [873340601.py.close:1745] - Generator 实例关闭完成。\n",
      "2025-05-12 15:18:50,350 - INFO - [873340601.py.close:1173] - 开始关闭 Indexer 实例...\n",
      "2025-05-12 15:18:50,350 - INFO - [873340601.py.save_indices:1108] - 开始尝试将所有 Faiss 索引保存到磁盘文件...\n",
      "2025-05-12 15:18:50,353 - INFO - [873340601.py._save_single_index:1156] -   成功：'文本(Text)' Faiss 索引 (包含 218 个向量) 已保存到: Multimodal_RAG_System_Run_20250512_151657\\data_storage\\vector_indices\\text_vector_index.faiss\n",
      "2025-05-12 15:18:50,354 - INFO - [873340601.py._save_single_index:1156] -   成功：'图像(Image)' Faiss 索引 (包含 213 个向量) 已保存到: Multimodal_RAG_System_Run_20250512_151657\\data_storage\\vector_indices\\image_vector_index.faiss\n",
      "2025-05-12 15:18:50,356 - INFO - [873340601.py._save_single_index:1156] -   成功：'平均(Mean)' Faiss 索引 (包含 212 个向量) 已保存到: Multimodal_RAG_System_Run_20250512_151657\\data_storage\\vector_indices\\mean_vector_index.faiss\n",
      "2025-05-12 15:18:50,356 - INFO - [873340601.py.save_indices:1126] - 所有 Faiss 索引的保存操作已完成（或已跳过空索引/不存在的索引）。\n",
      "2025-05-12 15:18:50,357 - INFO - [873340601.py.close:1176] - Indexer 实例关闭完成。所有 Faiss 索引已尝试保存。\n",
      "2025-05-12 15:18:50,357 - INFO - [873340601.py.<module>:2137] - --- [Main Flow] System resource cleanup and shutdown procedures complete. ---\n",
      "\n",
      "2025-05-12 15:18:50,358 - INFO - [873340601.py.<module>:2139] - \n",
      "================================================================================\n",
      "2025-05-12 15:18:50,359 - INFO - [873340601.py.<module>:2140] - ========= Multimodal RAG System Example Program Execution Finished =========\n",
      "2025-05-12 15:18:50,360 - INFO - [873340601.py.<module>:2141] - All outputs (logs, database, indices, query results) have been saved in the top-level directory:\n",
      "2025-05-12 15:18:50,360 - INFO - [873340601.py.<module>:2142] -   d:\\ALL IN AI\\多模态RAG\\IDT_RAG\\MultimodalRAG\\Multimodal_RAG_System_Run_20250512_151657\n",
      "2025-05-12 15:18:50,361 - INFO - [873340601.py.<module>:2143] - Key subdirectories overview:\n",
      "2025-05-12 15:18:50,361 - INFO - [873340601.py.<module>:2144] -   - Multimodal_RAG_System_Run_20250512_151657\\run_logs/\n",
      "2025-05-12 15:18:50,362 - INFO - [873340601.py.<module>:2145] -   - Multimodal_RAG_System_Run_20250512_151657\\data_storage\\database/\n",
      "2025-05-12 15:18:50,363 - INFO - [873340601.py.<module>:2146] -   - Multimodal_RAG_System_Run_20250512_151657\\data_storage\\vector_indices/\n",
      "2025-05-12 15:18:50,364 - INFO - [873340601.py.<module>:2147] -   - Multimodal_RAG_System_Run_20250512_151657\\query_session_results/\n",
      "2025-05-12 15:18:50,364 - INFO - [873340601.py.<module>:2148] -     (Under query_session_results/, each 'query_XXX_...' subdirectory contains detailed I/O for a single query)\n",
      "2025-05-12 15:18:50,365 - INFO - [873340601.py.<module>:2149] - ================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------------------------------------\n",
    "# 导入标准库模块\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "import sqlite3 # 导入 SQLite 数据库模块，用于存储和管理文档的元数据，如ID、文本描述和图像路径。\n",
    "import os      # 导入操作系统模块，提供与操作系统交互的功能，如文件路径操作、检查文件或目录是否存在、创建目录等。\n",
    "import numpy as np # 导入 NumPy 库，用于高效的数值计算，特别是在处理向量（如CLIP模型生成的特征向量）时非常有用。\n",
    "from typing import List, Dict, Union, Optional, Tuple, Any # 导入类型提示模块，用于在代码中添加类型注解，以增强代码的可读性、可维护性，并帮助静态类型检查工具发现潜在错误。 (Added Any for broader compatibility in some dicts)\n",
    "import json    # 导入 JSON 库，用于处理 JSON (JavaScript Object Notation) 格式的数据，常用于配置文件读写、API数据交换等。\n",
    "import time    # 导入时间库，提供时间相关的函数，如获取当前时间、程序暂停（sleep）等。\n",
    "import random  # 导入随机库，用于生成伪随机数，例如在示例查询中随机选择文档。\n",
    "import logging # 导入日志模块，用于记录程序运行过程中的信息、警告和错误，方便调试和监控。\n",
    "import sys     # 导入系统模块，提供访问由 Python 解释器使用或维护的变量和函数的接口，如此处用于配置日志输出到标准输出。\n",
    "import datetime # 导入日期时间模块，用于处理日期和时间，如此处用于生成带有时间戳的目录名，确保每次运行输出的唯一性。\n",
    "import re      # 导入正则表达式模块，用于进行强大的文本模式匹配和字符串操作，如此处用于清理文件名中的非法字符。\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# 导入第三方库模块 (需要预先安装)\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "import faiss   # 导入 Faiss 库，一个由 Facebook AI Research 开发的高效向量相似性搜索和聚类库。\n",
    "               # 安装提示: pip install faiss-cpu (CPU版本) 或 faiss-gpu (GPU版本，需CUDA环境)。\n",
    "from transformers import CLIPProcessor, CLIPModel # 从 Hugging Face Transformers 库导入 CLIP 模型的处理器和模型本身。\n",
    "                                                 # CLIP (Contrastive Language–Image Pre-training) 是一种强大的多模态模型，能将文本和图像编码到同一向量空间。\n",
    "                                                 # 安装提示: pip install transformers torch pillow。\n",
    "from PIL import Image, UnidentifiedImageError # 导入 Pillow 库 (PIL fork)，用于图像文件的加载、处理和保存。 (Added UnidentifiedImageError for specific exception handling)\n",
    "import torch   # 导入 PyTorch 库，一个广泛使用的开源机器学习框架，Transformers 库基于它构建。\n",
    "import zhipuai # 导入 ZhipuAI 客户端库，用于与智谱 AI 开发的大语言模型 API 进行交互。\n",
    "               # 安装提示: pip install zhipuai。\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# 全局日志记录器设置 (在 `if __name__ == \"__main__\":` 中进一步配置)\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "logger = logging.getLogger(__name__) # 初始化一个模块级别的日志记录器实例。`__name__` 会被设置成当前模块的名称。\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# 工具函数定义\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "def setup_logging(log_file_path: str):\n",
    "    \"\"\"\n",
    "    配置全局日志记录器 (logger)。\n",
    "    该函数设置日志记录级别、格式，并指定日志信息同时输出到控制台和指定的日志文件。\n",
    "\n",
    "    Args:\n",
    "        log_file_path (str): 日志文件的完整路径。程序运行的所有日志信息将被写入此文件。\n",
    "    \"\"\"\n",
    "    global logger # 声明我们要修改的是全局变量 `logger`\n",
    "    logger.setLevel(logging.INFO) # 设置日志记录的最低级别为 INFO。只有 INFO 及以上级别（如 WARNING, ERROR, CRITICAL）的日志才会被处理。\n",
    "\n",
    "    # 在添加新的处理器之前，清除可能已存在的旧处理器，以避免重复记录日志。\n",
    "    # 这在脚本被多次调用或在交互式环境中使用时尤其重要。\n",
    "    if logger.hasHandlers():\n",
    "        logger.handlers.clear()\n",
    "\n",
    "    # 创建一个文件处理器 (FileHandler)，用于将日志信息写入到指定的日志文件。\n",
    "    # `encoding='utf-8'` 确保日志文件能正确处理中文字符。\n",
    "    file_handler = logging.FileHandler(log_file_path, encoding='utf-8', mode='w') # 'w' mode to overwrite log for each run\n",
    "    file_handler.setLevel(logging.INFO) # 文件处理器也只处理 INFO 及以上级别的日志。\n",
    "\n",
    "    # 创建一个控制台处理器 (StreamHandler)，用于将日志信息输出到标准输出（通常是终端控制台）。\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setLevel(logging.INFO) # 控制台处理器同样只处理 INFO 及以上级别的日志。\n",
    "\n",
    "    # 定义日志格式器 (Formatter)，它决定了每条日志记录的显示格式。\n",
    "    # 格式字符串包含:\n",
    "    #   %(asctime)s: 日志记录的创建时间。\n",
    "    #   %(levelname)s: 日志级别 (例如 INFO, WARNING)。\n",
    "    #   [%(module)s.%(funcName)s:%(lineno)d]: 日志发出的模块名、函数名和行号，便于定位问题。\n",
    "    #   %(message)s: 实际的日志消息内容。\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - [%(filename)s.%(funcName)s:%(lineno)d] - %(message)s') # Changed module to filename for better clarity\n",
    "    \n",
    "    # 将定义好的格式器应用到文件处理器和控制台处理器。\n",
    "    file_handler.setFormatter(formatter)\n",
    "    console_handler.setFormatter(formatter)\n",
    "\n",
    "    # 将配置好的文件处理器和控制台处理器添加到全局日志记录器中。\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "    logger.info(\"全局日志记录器配置完成。日志将输出到控制台，并写入文件: %s\", log_file_path) # 记录一条日志，表明配置成功。\n",
    "\n",
    "def sanitize_filename(filename: str, max_length: int = 100, is_dir_component: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    清理字符串，使其成为一个有效的文件名或目录名组件。\n",
    "    该函数会替换或移除文件名中不被大多数文件系统允许的特殊字符，并将文件名截断到指定的最大长度。\n",
    "\n",
    "    Args:\n",
    "        filename (str): 需要被清理的原始字符串。\n",
    "        max_length (int): 清理后文件名的最大允许长度。默认为 100 个字符。\n",
    "        is_dir_component (bool): (此参数在此实现中未产生不同行为) 指示该字符串是否用作目录路径的一部分。\n",
    "                                 理论上，目录组件可能对某些字符（如路径分隔符）有不同处理，但为简单和安全起见，\n",
    "                                 此函数对文件名和目录名组件采用相同的严格清理规则。\n",
    "\n",
    "    Returns:\n",
    "        str: 清理和截断后的、可以用作文件系统名称的字符串。\n",
    "    \"\"\"\n",
    "    # 如果输入的文件名为空或 None，返回一个默认的占位符名称。\n",
    "    if not filename:\n",
    "        return \"unnamed_component\" # 未命名组件\n",
    "    \n",
    "    # 使用正则表达式替换掉文件名中常见的非法字符。\n",
    "    # 这些字符包括: \\ / * ? : \" < > | (反斜杠, 正斜杠, 星号, 问号, 冒号, 双引号, 小于号, 大于号, 竖线)\n",
    "    # 将这些非法字符统一替换为下划线 \"_\"。\n",
    "    sanitized = re.sub(r'[\\\\/*?:\"<>|]', \"_\", filename)\n",
    "    \n",
    "    # 将字符串两端的空白字符（空格、制表符、换行符等）去除。\n",
    "    # 然后，将字符串内部的一个或多个连续空白字符替换为单个下划线 \"_\"。\n",
    "    sanitized = re.sub(r'\\s+', '_', sanitized.strip())\n",
    "    \n",
    "    # 移除文件名开头可能存在的点和下划线，避免生成隐藏文件或不规范的名称\n",
    "    sanitized = re.sub(r'^[\\._]+', '', sanitized)\n",
    "\n",
    "    # 将清理后的字符串截断到 `max_length` 指定的最大长度。\n",
    "    # 注意：简单的切片可能在多字节字符（如某些中文）的中间截断，导致乱码。\n",
    "    # 对于主要处理英文或简单场景，此方法可行。若需完美处理多字节字符，需要更复杂的截断逻辑。\n",
    "    sanitized = sanitized[:max_length]\n",
    "\n",
    "    # 再次检查，如果清理和截断后字符串变为空，或者只包含点号 \".\" (可能导致隐藏文件或路径问题)，\n",
    "    # 则返回一个特定的占位符名称。\n",
    "    if not sanitized or all(c == '.' for c in sanitized):\n",
    "        return \"sanitized_empty_name\" # 清理后为空的名称\n",
    "    \n",
    "    # 避免使用 Windows 系统中的保留设备名作为文件名（不区分大小写）。\n",
    "    # 例如: CON, PRN, AUX, NUL, COM1-COM9, LPT1-LPT9。\n",
    "    # 如果清理后的名称（转换为大写后）匹配这些保留名，则在其前后添加下划线以作区分。\n",
    "    # 这是一个简化的检查，完整的跨平台文件名验证会更复杂。\n",
    "    reserved_names_check = sanitized.upper()\n",
    "    if reserved_names_check in [\"CON\", \"PRN\", \"AUX\", \"NUL\"] or \\\n",
    "       re.match(r\"COM[1-9]$\", reserved_names_check) or \\\n",
    "       re.match(r\"LPT[1-9]$\", reserved_names_check):\n",
    "        sanitized = f\"_{sanitized}_\" # 在保留名称前后加下划线\n",
    "\n",
    "    return sanitized # 返回最终清理后的文件名字符串。\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# 数据加载与预处理模块\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "def load_data_from_json_and_associate_images(json_path: str, image_dir: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    从指定的 JSON 文件加载文档的元数据 (如 ID 和描述文本)，\n",
    "    并根据文档 ID (JSON中的 'name' 字段) 在指定的图像目录中查找并关联对应的图像文件。\n",
    "    函数假设图像文件名是文档 ID 加上常见的图片扩展名 (如 .png, .jpg)。\n",
    "\n",
    "    Args:\n",
    "        json_path (str): 包含文档元数据的 JSON 文件路径。\n",
    "                         JSON 文件应为一个列表，其中每个对象至少包含 'name' 和 'description' 字段。\n",
    "        image_dir (str): 存放与 JSON 数据对应的图片文件的目录路径。\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: 一个包含处理后文档信息的字典列表。\n",
    "                    每个字典包含以下键：\n",
    "                    - 'id': 文档的唯一标识符 (来自 JSON 'name' 字段，确保为字符串)。\n",
    "                    - 'text': 文档的文本描述 (来自 JSON 'description' 字段，确保为字符串或 None)。\n",
    "                    - 'image_path': 找到的对应图像文件的完整路径 (str)。如果未找到图像或 image_dir 无效，则为 None。\n",
    "                    如果 JSON 文件不存在、无法解析或读取失败，则返回空列表 ([]).\n",
    "    \"\"\"\n",
    "    # 获取当前模块的日志记录器实例，用于记录此函数的执行信息。\n",
    "    func_logger = logging.getLogger(__name__) # 使用模块级 logger\n",
    "    func_logger.info(f\"开始从 JSON 文件 '{json_path}' 加载数据，并在目录 '{image_dir}' 中关联图像...\")\n",
    "\n",
    "    # 步骤 1: 检查 JSON 文件是否存在。\n",
    "    if not os.path.exists(json_path):\n",
    "        func_logger.error(f\"错误：JSON 文件 '{json_path}' 未找到。请检查文件路径是否正确。\")\n",
    "        return [] # 文件不存在，无法继续，返回空列表。\n",
    "\n",
    "    # 初始化用于存储最终处理后文档信息的列表。\n",
    "    documents: List[Dict[str, Any]] = [] \n",
    "    # 定义一个包含常见图像文件扩展名的列表，用于查找匹配的图像文件。\n",
    "    image_extensions = ['.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff', '.webp'] # 增加了 .webp 格式\n",
    "\n",
    "    # 步骤 2: 尝试打开并解析 JSON 文件。\n",
    "    try:\n",
    "        # 使用 'with' 语句确保文件在使用后自动关闭，即使发生错误。\n",
    "        # 'r' 表示以只读模式打开文件。\n",
    "        # 'encoding='utf-8'' 指定使用 UTF-8 编码读取文件，以正确处理中文字符。\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            json_data = json.load(f) # 解析 JSON 数据，将其转换为 Python 的列表或字典。\n",
    "            if not isinstance(json_data, list):\n",
    "                func_logger.error(f\"错误: JSON 文件 '{json_path}' 的顶层结构不是一个列表。请确保JSON文件格式正确。\")\n",
    "                return []\n",
    "    except json.JSONDecodeError as e:\n",
    "        # 如果 JSON 文件内容格式不正确，json.load() 会抛出 JSONDecodeError。\n",
    "        func_logger.error(f\"错误：JSON 文件 '{json_path}' 解析失败。错误详情: {e}\")\n",
    "        func_logger.error(f\"        请确保文件内容是有效的 JSON 格式 (一个包含对象的列表)。\")\n",
    "        return [] # JSON 格式错误，返回空列表。\n",
    "    except Exception as e:\n",
    "        # 捕获其他可能的读取文件错误，例如权限问题。\n",
    "        func_logger.error(f\"错误：读取 JSON 文件 '{json_path}' 时发生未知错误。错误详情: {e}\")\n",
    "        return [] # 其他读取错误，返回空列表。\n",
    "\n",
    "    func_logger.info(f\"已成功从 '{json_path}' 加载 {len(json_data)} 条原始记录。\")\n",
    "    \n",
    "    # 初始化计数器，用于统计数据处理过程中的情况。\n",
    "    found_images_count = 0    # 成功关联到图像的文档数量。\n",
    "    missing_key_count = 0     # 因缺少必要字段 ('name' 或 'description') 而被跳过的记录数量。\n",
    "\n",
    "    # 步骤 3: 遍历从 JSON 文件加载的每一条原始记录。\n",
    "    for item_index, item in enumerate(json_data): # 使用 enumerate 获取索引，方便日志记录\n",
    "        if not isinstance(item, dict):\n",
    "            func_logger.warning(f\"警告：跳过第 {item_index + 1} 条记录，因其不是一个有效的字典对象。记录内容: {item}\")\n",
    "            missing_key_count += 1\n",
    "            continue\n",
    "\n",
    "        doc_id = item.get('name')         # 尝试获取 'name' 字段作为文档 ID。\n",
    "        text_content = item.get('description') # 尝试获取 'description' 字段作为文本内容。\n",
    "\n",
    "        # 检查关键字段 'name' 和 'description' 是否存在且有值。\n",
    "        # 如果任一字段缺失，则跳过该条记录。\n",
    "        if not doc_id or not text_content: # Both name and description must exist\n",
    "            missing_key_count += 1\n",
    "            func_logger.warning(f\"警告：跳过第 {item_index + 1} 条记录（JSON索引 {item_index}），因缺少 'name' 或 'description' 字段。记录内容: {item}\")\n",
    "            continue # 继续处理下一条记录。\n",
    "\n",
    "        # 初始化图像路径为 None。如果在指定目录中找不到匹配的图像，它将保持为 None。\n",
    "        image_path: Optional[str] = None \n",
    "        # 检查图像目录路径是否有效（已提供且存在于文件系统中）。\n",
    "        if image_dir and os.path.isdir(image_dir): # 确保 image_dir 是一个存在的目录\n",
    "            # 遍历预定义的图像扩展名列表，尝试构建并查找图像文件。\n",
    "            for ext in image_extensions:\n",
    "                # 构建潜在的图像文件名：文档ID（来自 'name' 字段）+ 当前扩展名。\n",
    "                # 使用 str(doc_id) 确保即使 doc_id 是数字也能正确拼接。\n",
    "                potential_image_filename = str(doc_id) + ext\n",
    "                # 使用 os.path.join 安全地构建跨平台的完整图像文件路径。\n",
    "                potential_image_path = os.path.join(image_dir, potential_image_filename)\n",
    "                \n",
    "                # 检查构建的图像文件路径是否存在于文件系统中。\n",
    "                if os.path.exists(potential_image_path) and os.path.isfile(potential_image_path): # 确保是文件\n",
    "                    image_path = potential_image_path # 找到图像，记录其完整路径。\n",
    "                    found_images_count += 1           # 增加找到图像的计数。\n",
    "                    break # 找到一个匹配的图像后，无需再检查其他扩展名，跳出内层循环。\n",
    "        elif image_dir and not os.path.isdir(image_dir):\n",
    "            # 如果提供了 image_dir 但它不是一个有效的目录，记录一次警告。\n",
    "            # 为避免日志泛滥，此警告只在第一次检测到时发出（通过在循环外设置一个标志）\n",
    "            # (为简化，此处每次都记录，但可优化)\n",
    "            func_logger.warning(f\"提供的图像目录 '{image_dir}' 不是一个有效的目录，将无法关联图像。\")\n",
    "        elif not image_dir:\n",
    "            func_logger.debug(f\"未提供图像目录 (image_dir is None or empty)，将不尝试关联图像。\")\n",
    "\n",
    "\n",
    "        # 将处理后的文档信息（包括 ID、文本和可能的图像路径）添加到 `documents` 列表中。\n",
    "        documents.append({\n",
    "            'id': str(doc_id), # 确保文档 ID 是字符串类型。\n",
    "            'text': str(text_content) if text_content is not None else None, # 确保文本是字符串；如果原始为 None，则保持 None。\n",
    "            'image_path': image_path # 存储找到的图像路径，如果未找到则为 None。\n",
    "        })\n",
    "\n",
    "    # 步骤 4: 打印数据加载和关联过程的总结信息。\n",
    "    func_logger.info(f\"成功准备了 {len(documents)} 个文档用于后续处理。\")\n",
    "    if missing_key_count > 0:\n",
    "        func_logger.warning(f\"在原始 JSON 数据中，共有 {missing_key_count} 条记录因格式无效或缺少 'name'/'description' 字段而被跳过。\")\n",
    "    func_logger.info(f\"在有效文档中，共有 {found_images_count} 个文档成功关联了图像文件。\")\n",
    "    \n",
    "    # 如果指定了图像目录，但没有找到任何图像文件（并且至少有一个文档被处理了），则给出提示。\n",
    "    if len(documents) > 0 and found_images_count == 0 and image_dir and os.path.isdir(image_dir):\n",
    "         func_logger.info(f\"提示: 未在目录 '{image_dir}' 中找到任何与文档 ID 匹配的图像文件。\")\n",
    "         func_logger.info(f\"        请检查图像文件名是否严格遵循 '文档ID.扩展名' 的格式 (例如，如果文档 'name' 是 'item01'，则图像应为 'item01.png')。\")\n",
    "    \n",
    "    func_logger.info(f\"--- 数据加载与图像关联流程结束 ---\")\n",
    "    return documents # 返回包含所有已处理文档信息的列表。\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# 多模态编码器类 (MultimodalEncoder)\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "class MultimodalEncoder:\n",
    "    \"\"\"\n",
    "    使用 Hugging Face Transformers 库中的 CLIP (Contrastive Language–Image Pre-training) 模型\n",
    "    来对文本和/或图像进行编码，将它们转换为高维向量表示 (特征向量)。\n",
    "    CLIP 模型能够将文本和图像映射到同一个语义向量空间，使得它们的向量表示具有可比性，\n",
    "    这是多模态检索和理解的基础。\n",
    "\n",
    "    核心功能:\n",
    "    - 在初始化时加载预训练的 CLIP 模型和对应的处理器 (processor)。\n",
    "    - 提供 `encode` 方法，该方法可以接受文本字符串、图像文件路径，或两者都接受。\n",
    "    - `encode` 方法对输入进行预处理、通过 CLIP 模型进行编码，然后对输出的向量进行 L2 归一化。\n",
    "    - 返回一个字典，包含文本向量、图像向量以及（如果两者都提供了）两者的平均向量。\n",
    "    - 自动检测并优先使用 GPU (如果 CUDA 可用) 进行计算加速，否则回退到 CPU。\n",
    "    - L2 归一化对于后续使用 Faiss 进行基于内积 (Inner Product) 的相似度搜索至关重要，\n",
    "      因为归一化向量的内积等价于它们之间的余弦相似度。\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name: str = \"openai/clip-vit-base-patch32\"):\n",
    "        \"\"\"\n",
    "        初始化 MultimodalEncoder 类。\n",
    "\n",
    "        Args:\n",
    "            model_name (str): 指定要加载的 Hugging Face Hub 上的 CLIP 模型名称。\n",
    "                              例如 \"openai/clip-vit-base-patch32\"。\n",
    "                              不同的 CLIP 模型变体具有不同的性能、速度和输出向量维度。\n",
    "                              选择合适的模型取决于具体的应用需求和可用资源。\n",
    "                              老板请注意: \"openai/clip-vit-base-patch32\" 是一个性能和资源消耗均衡的基准模型。\n",
    "                              若资源极度受限，可研究更轻量模型，但可能影响编码质量。\n",
    "\n",
    "        Raises:\n",
    "            Exception: 如果在加载 CLIP 模型或处理器时发生任何错误（例如，网络问题导致无法下载模型文件、\n",
    "                       指定的模型名称无效、或者相关的依赖库未正确安装），则会抛出异常。\n",
    "                       由于模型是编码器的核心，加载失败意味着编码器无法工作。\n",
    "        \"\"\"\n",
    "        # 获取一个特定于此类实例的日志记录器，方便追踪和调试。\n",
    "        self.logger = logging.getLogger(__name__ + \".\" + self.__class__.__name__)\n",
    "        self.logger.info(f\"开始初始化 MultimodalEncoder，尝试加载 CLIP 模型: {model_name}\")\n",
    "        \n",
    "        try:\n",
    "            # 步骤 1: 加载与指定 CLIP 模型相关联的处理器 (CLIPProcessor)。\n",
    "            # 处理器负责将原始的文本和图像数据转换为 CLIP 模型期望的输入格式。\n",
    "            # 对于文本，这通常包括分词 (tokenization)、添加特殊标记、转换为 token ID。\n",
    "            # 对于图像，这通常包括调整大小 (resizing)、归一化 (normalization) 像素值。\n",
    "            self.processor = CLIPProcessor.from_pretrained(model_name)\n",
    "            self.logger.info(f\"CLIP Processor for '{model_name}' 加载成功。\")\n",
    "\n",
    "            # 步骤 2: 加载预训练的 CLIP 模型本身 (CLIPModel)。\n",
    "            self.model = CLIPModel.from_pretrained(model_name)\n",
    "            self.logger.info(f\"CLIP Model '{model_name}' 加载成功。\")\n",
    "\n",
    "            # 步骤 3: 获取模型的输出向量维度。\n",
    "            # 对于 CLIP 模型，文本编码器和图像编码器的输出向量维度通常是相同的。\n",
    "            # 这个维度信息对于后续创建 Faiss 索引等操作非常重要。\n",
    "            # text_model.config.hidden_size 通常存储了这个维度值。\n",
    "            self.vector_dimension = self.model.text_model.config.hidden_size\n",
    "            self.logger.info(f\"CLIP 模型的特征向量维度为: {self.vector_dimension}\")\n",
    "\n",
    "            # 步骤 4: 将模型设置为评估模式 (evaluation mode)。\n",
    "            # 调用 .eval() 会关闭模型中的 Dropout 层和 Batch Normalization 层的更新行为。\n",
    "            # 这对于推理（编码）阶段非常重要，以确保结果的一致性和确定性。\n",
    "            self.model.eval()\n",
    "\n",
    "            # 步骤 5: 检测可用的计算设备 (GPU 或 CPU)，并将模型迁移到该设备。\n",
    "            if torch.cuda.is_available(): # 检查系统中是否有可用的 CUDA GPU。\n",
    "                self.device = torch.device(\"cuda\") # 如果有，则选择使用 GPU。\n",
    "                self.logger.info(\"检测到 CUDA 支持，模型将运行在 GPU 上以获得更快的编码速度。\")\n",
    "            else:\n",
    "                self.device = torch.device(\"cpu\")  # 如果没有 GPU，则使用 CPU。\n",
    "                self.logger.info(\"未检测到 CUDA 支持，模型将运行在 CPU 上 (编码速度可能较慢)。\")\n",
    "            \n",
    "            self.model.to(self.device) # 将模型的所有参数和缓冲区移动到选定的设备。\n",
    "            self.logger.info(f\"模型已成功移动到设备: {self.device}\")\n",
    "            self.logger.info(\"MultimodalEncoder 初始化成功完成。\")\n",
    "\n",
    "        except Exception as e:\n",
    "             # 如果在上述任何步骤中发生错误，记录详细的错误信息并重新抛出异常。\n",
    "             self.logger.error(f\"初始化 MultimodalEncoder 失败：加载 CLIP 模型 '{model_name}' 时发生严重错误。\")\n",
    "             self.logger.error(f\"错误详情: {e}\", exc_info=True) # exc_info=True 会记录完整的堆栈跟踪。\n",
    "             self.logger.error(\"请检查以下几点：\")\n",
    "             self.logger.error(f\"  1. 确保指定的模型名称 '{model_name}' 正确且在 Hugging Face Hub 上可用。\")\n",
    "             self.logger.error(\"  2. 确保已正确安装必要的 Python 库: 'transformers', 'torch', 'pillow'。\")\n",
    "             self.logger.error(\"     (例如，通过命令: pip install transformers torch pillow)\")\n",
    "             self.logger.error(\"  3. 确保网络连接正常，以便能够从 Hugging Face Hub 下载模型文件 (首次加载时需要)。\")\n",
    "             raise RuntimeError(f\"MultimodalEncoder 初始化失败: {e}\") from e # Re-raise as RuntimeError\n",
    "\n",
    "    def _normalize_vector(self, vector: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        对输入的 NumPy 向量进行 L2 范数归一化 (L2 Normalization)。\n",
    "        L2 归一化将向量缩放，使其 L2 范数（欧几里得长度）为 1。\n",
    "        这对于计算余弦相似度非常重要：两个 L2 归一化向量的点积（内积）等于它们之间的余弦相似度。\n",
    "\n",
    "        Args:\n",
    "            vector (np.ndarray): 需要进行 L2 归一化的 NumPy 浮点数向量。\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: 经过 L2 归一化后的向量。如果输入向量的范数非常接近于零（即零向量），\n",
    "                        则直接返回一个相同形状的零向量，以避免除以零的错误。\n",
    "        \"\"\"\n",
    "        # 计算向量的 L2 范数 (向量的欧几里得长度)。\n",
    "        norm = np.linalg.norm(vector)\n",
    "        \n",
    "        # 检查范数是否大于一个很小的阈值 (epsilon)，以避免除以零或因浮点数精度问题导致的数值不稳定。\n",
    "        # 1e-9 是一个常用的小正数。\n",
    "        if norm > 1e-9: \n",
    "            # 如果范数足够大，则将向量的每个元素除以该范数，得到归一化向量。\n",
    "            return vector / norm\n",
    "        else:\n",
    "            # 如果范数非常小（向量接近零向量），直接返回一个与输入向量形状相同但所有元素为零的向量。\n",
    "            self.logger.debug(\"尝试归一化一个范数接近零的向量。返回零向量。\")\n",
    "            return np.zeros_like(vector)\n",
    "\n",
    "    def encode(self, text: Optional[str] = None, image_path: Optional[str] = None) -> Dict[str, Optional[np.ndarray]]:\n",
    "        \"\"\"\n",
    "        对输入的文本字符串和/或图像文件路径进行编码，生成它们对应的归一化特征向量。\n",
    "\n",
    "        Args:\n",
    "            text (Optional[str]): 需要编码的文本字符串。如果为 None 或空字符串，则不进行文本编码。\n",
    "            image_path (Optional[str]): 需要编码的图像文件的完整路径。如果为 None 或路径无效，则不进行图像编码。\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, Optional[np.ndarray]]: 一个字典，包含以下可能的键值对：\n",
    "                - 'text_vector': 如果提供了有效的文本且编码成功，则为该文本的 L2 归一化 NumPy 向量 (float32)。否则为 None。\n",
    "                - 'image_vector': 如果提供了有效的图像路径、图像文件可读且编码成功，则为该图像的 L2 归一化 NumPy 向量 (float32)。否则为 None。\n",
    "                - 'mean_vector': 如果文本和图像都提供了，并且两者都成功编码，则为两者特征向量的 L2 归一化平均向量 (float32)。\n",
    "                                 这个平均向量可以作为文本和图像结合的多模态表示。如果任一编码失败或未提供，则为 None。\n",
    "            如果 `text` 和 `image_path` 都为 None，将记录错误并返回所有值为 None 的字典。\n",
    "        \"\"\"\n",
    "        # 输入有效性检查：必须至少提供文本或图像路径之一。\n",
    "        if text is None and image_path is None:\n",
    "            self.logger.error(\"编码错误：必须至少提供文本或图像路径才能进行编码。\")\n",
    "            return {'text_vector': None, 'image_vector': None, 'mean_vector': None}\n",
    "\n",
    "        # 初始化各个向量为 None，它们将在编码成功后被赋值。\n",
    "        text_vector: Optional[np.ndarray] = None\n",
    "        image_vector: Optional[np.ndarray] = None\n",
    "        mean_vector: Optional[np.ndarray] = None\n",
    "        \n",
    "        # 使用 torch.no_grad() 上下文管理器进行推理。\n",
    "        # 这会禁用 PyTorch 的梯度计算，从而减少内存消耗并加速计算，因为在编码（推理）阶段不需要进行反向传播。\n",
    "        with torch.no_grad():\n",
    "            # --- 步骤 A: 编码文本 (如果提供了文本) ---\n",
    "            if text is not None and text.strip(): # 确保文本非None且非空（去除两端空白后）\n",
    "                self.logger.debug(f\"开始编码文本: '{text[:50]}{'...' if len(text)>50 else ''}'\")\n",
    "                try:\n",
    "                    # 1. 预处理文本: 使用 CLIP Processor 将文本字符串转换为模型所需的输入格式。\n",
    "                    #    `return_tensors=\"pt\"`: 返回 PyTorch 张量 (tensors)。\n",
    "                    #    `padding=True`: 将批次内的文本填充到相同长度 (批次中最长文本的长度)。\n",
    "                    #    `truncation=True`: 如果文本超过模型的最大输入长度，则进行截断。\n",
    "                    #    `.to(self.device)`: 将生成的输入张量移动到之前确定的计算设备 (CPU 或 GPU)。\n",
    "                    text_inputs = self.processor(text=text, return_tensors=\"pt\", padding=True, truncation=True).to(self.device)\n",
    "\n",
    "                    # 2. 获取文本特征: 调用 CLIP 模型的 `get_text_features` 方法，传入预处理后的输入。\n",
    "                    #    使用 `**text_inputs` 将字典解包为关键字参数。\n",
    "                    text_features_tensor = self.model.get_text_features(**text_inputs)\n",
    "\n",
    "                    # 3. 后处理特征张量:\n",
    "                    #    `.squeeze()`: 如果批次大小为1，移除批次维度，得到一个一维张量 (向量)。\n",
    "                    #    `.cpu()`: 将结果张量从 GPU (如果在使用) 移回 CPU，因为 NumPy 操作通常在 CPU 上进行。\n",
    "                    #    `.numpy()`: 将 PyTorch 张量转换为 NumPy 数组。\n",
    "                    #    `.astype('float32')`: 确保数据类型为 float32，这是 Faiss 常用的数值类型，也节省内存。\n",
    "                    text_vector_raw = text_features_tensor.squeeze().cpu().numpy().astype('float32')\n",
    "\n",
    "                    # 4. L2 归一化: 对原始的文本特征向量进行 L2 范数归一化。\n",
    "                    text_vector = self._normalize_vector(text_vector_raw)\n",
    "                    self.logger.debug(\"文本编码成功并已归一化。\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    # 如果文本编码过程中发生任何错误，记录错误信息。\n",
    "                    self.logger.error(f\"编码文本时发生错误。文本: '{text[:50]}...'. 错误详情: {e}\", exc_info=False) # exc_info=False 避免在每次文本编码失败时都打印完整堆栈\n",
    "                    text_vector = None # 确保在失败时 text_vector 为 None。\n",
    "\n",
    "            # --- 步骤 B: 编码图像 (如果提供了图像路径) ---\n",
    "            if image_path is not None and image_path.strip(): # 确保图像路径非None且非空\n",
    "                self.logger.debug(f\"开始编码图像: '{image_path}'\")\n",
    "                try:\n",
    "                    # 1. 加载图像: 使用 Pillow (PIL) 库的 Image.open() 方法打开图像文件。\n",
    "                    #    `.convert(\"RGB\")`: 确保图像转换为 RGB 格式。CLIP 模型通常期望 RGB 图像作为输入。\n",
    "                    #                       即使原始图像是 RGBA 或灰度图，也会被转换为 RGB。\n",
    "                    image_pil = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "                    # 2. 预处理图像: 使用 CLIP Processor 将 PIL.Image 对象转换为模型所需的输入格式。\n",
    "                    #    `return_tensors=\"pt\"`: 返回 PyTorch 张量。\n",
    "                    #    `.to(self.device)`: 将输入张量移动到计算设备。\n",
    "                    image_inputs = self.processor(images=image_pil, return_tensors=\"pt\").to(self.device)\n",
    "\n",
    "                    # 3. 获取图像特征: 调用 CLIP 模型的 `get_image_features` 方法。\n",
    "                    image_features_tensor = self.model.get_image_features(**image_inputs)\n",
    "\n",
    "                    # 4. 后处理特征张量 (与文本编码类似): 转换为归一化的 NumPy float32 数组。\n",
    "                    image_vector_raw = image_features_tensor.squeeze().cpu().numpy().astype('float32')\n",
    "                    image_vector = self._normalize_vector(image_vector_raw)\n",
    "                    self.logger.debug(f\"图像 '{os.path.basename(image_path)}' 编码成功并已归一化。\")\n",
    "\n",
    "                except FileNotFoundError:\n",
    "                    # 如果指定的图像文件路径不存在。\n",
    "                    self.logger.warning(f\"图像编码警告: 图像文件未找到于路径 '{image_path}'。将跳过此图像的编码。\")\n",
    "                    image_vector = None\n",
    "                except UnidentifiedImageError: # Pillow 无法识别图像格式\n",
    "                    self.logger.error(f\"图像编码错误: 无法识别或打开图像文件 '{image_path}'。文件可能已损坏或格式不受支持。\")\n",
    "                    image_vector = None\n",
    "                except Exception as e:\n",
    "                    # 如果在加载或处理图像时发生其他错误 (例如，图像文件损坏、权限问题)。\n",
    "                    self.logger.error(f\"编码图像 '{image_path}' 时发生错误。错误详情: {e}\", exc_info=False)\n",
    "                    image_vector = None\n",
    "\n",
    "        # --- 步骤 C: 计算平均向量 (仅当文本和图像都成功编码时) ---\n",
    "        # 检查 text_vector 和 image_vector 是否都成功生成 (即它们都不是 None)。\n",
    "        if text_vector is not None and image_vector is not None:\n",
    "            self.logger.debug(\"文本和图像均成功编码，开始计算它们的平均向量...\")\n",
    "            try:\n",
    "                # 1. 计算平均: 使用 NumPy 的 `mean` 函数计算两个向量的逐元素平均值。\n",
    "                #    `axis=0` 表示沿着第一个轴（即向量本身）计算平均值。\n",
    "                #    确保结果的数据类型为 float32。\n",
    "                mean_vector_raw = np.mean(np.array([text_vector, image_vector]), axis=0).astype('float32')\n",
    "\n",
    "                # 2. L2 归一化: 对计算出的原始平均向量再次进行 L2 归一化。\n",
    "                #    这很重要，因为两个单位向量的平均向量长度通常不为 1。\n",
    "                mean_vector = self._normalize_vector(mean_vector_raw)\n",
    "                self.logger.debug(\"平均向量计算并归一化成功。\")\n",
    "            except Exception as e:\n",
    "                # 如果计算平均向量时出错。\n",
    "                self.logger.error(f\"计算文本和图像的平均向量时发生错误。错误详情: {e}\", exc_info=False)\n",
    "                mean_vector = None\n",
    "        elif (text_vector is not None or image_vector is not None):\n",
    "             self.logger.debug(\"仅文本或图像之一被成功编码，因此不计算平均向量。\")\n",
    "\n",
    "\n",
    "        # 总结编码结果，用于日志记录。\n",
    "        results_summary = []\n",
    "        if text_vector is not None: results_summary.append(\"文本向量\")\n",
    "        if image_vector is not None: results_summary.append(\"图像向量\")\n",
    "        if mean_vector is not None: results_summary.append(\"平均向量\")\n",
    "        \n",
    "        input_summary_parts = []\n",
    "        if text and text.strip(): input_summary_parts.append(f\"文本='{text[:30]}...'\")\n",
    "        if image_path and image_path.strip(): input_summary_parts.append(f\"图像='{os.path.basename(image_path)}'\")\n",
    "        input_desc = \", \".join(input_summary_parts) if input_summary_parts else \"无有效输入\"\n",
    "\n",
    "\n",
    "        if not results_summary and ( (text and text.strip()) or (image_path and image_path.strip()) ):\n",
    "             self.logger.warning(f\"编码完成，但对于输入 ({input_desc})，未能生成任何有效向量。\")\n",
    "        elif results_summary:\n",
    "             self.logger.info(f\"编码完成对于 ({input_desc})。成功生成的向量: {', '.join(results_summary)}。\")\n",
    "\n",
    "        # 返回包含所有结果向量的字典。\n",
    "        return {\n",
    "            'text_vector': text_vector,\n",
    "            'image_vector': image_vector,\n",
    "            'mean_vector': mean_vector\n",
    "        }\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# 索引器类 (Indexer)\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "class Indexer:\n",
    "    \"\"\"\n",
    "    Indexer 类是多模态 RAG (Retrieval Augmented Generation) 系统的数据管理核心。它负责：\n",
    "    1.  **接收文档数据**: 从外部（例如，`load_data_from_json_and_associate_images` 函数）获取包含文本和图像路径的文档列表。\n",
    "    2.  **调用编码器**: 使用内部的 `MultimodalEncoder` 实例对每个文档的文本内容和/或关联图像进行向量化，生成特征向量。\n",
    "    3.  **存储元数据**: 将文档的原始信息（如原始ID、文本内容、图像文件路径）存储在 SQLite 数据库中。\n",
    "        数据库中会为每个文档生成一个自增的整数主键 `internal_id`，这个ID将用作 Faiss 索引中对应向量的唯一标识符。\n",
    "    4.  **构建和管理向量索引**:\n",
    "        -   创建并维护 **三个独立** 的 Faiss 索引：一个用于存储纯文本向量，一个用于存储纯图像向量，一个用于存储文本和图像结合的平均向量。\n",
    "        -   每个 Faiss 索引都使用 `IndexIDMap2` 类型，这允许我们将向量与我们自定义的 `internal_id` (来自SQLite数据库) 关联起来，方便后续检索和数据回溯。\n",
    "        -   索引使用内积 (`IndexFlatIP`) 作为相似度度量方法。由于所有向量都经过了L2归一化，内积等价于余弦相似度，值越大表示越相似。\n",
    "    5.  **持久化**: 能够从指定文件路径加载先前已保存的索引文件和数据库，或者在首次运行时创建它们。在关闭时，会将当前的索引状态保存到文件，以便下次使用。\n",
    "\n",
    "    这种分离索引的设计（文本、图像、平均）允许在检索阶段根据用户查询的类型（纯文本、纯图像、或图文多模态）灵活地选择最合适的索引进行搜索，从而提高检索的准确性和效率。\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 db_path: str, \n",
    "                 faiss_text_index_path: str, \n",
    "                 faiss_image_index_path: str, \n",
    "                 faiss_mean_index_path: str, \n",
    "                 clip_model_name: str = \"openai/clip-vit-base-patch32\"):\n",
    "        \"\"\"\n",
    "        初始化 Indexer 实例。\n",
    "\n",
    "        Args:\n",
    "            db_path (str): 指定 SQLite 数据库文件的保存路径。\n",
    "            faiss_text_index_path (str): 指定文本向量 Faiss 索引文件的保存路径。\n",
    "            faiss_image_index_path (str): 指定图像向量 Faiss 索引文件的保存路径。\n",
    "            faiss_mean_index_path (str): 指定平均向量 Faiss 索引文件的保存路径。\n",
    "            clip_model_name (str): 传递给内部 `MultimodalEncoder` 的 CLIP 模型名称。\n",
    "                                   此模型名称必须与后续用于查询编码的模型保持一致，以确保向量空间的一致性。\n",
    "        \"\"\"\n",
    "        self.logger = logging.getLogger(__name__ + \".\" + self.__class__.__name__)\n",
    "        self.logger.info(\"开始初始化 Indexer...\")\n",
    "        \n",
    "        # 保存传入的路径和模型名称配置。\n",
    "        self.db_path = db_path\n",
    "        self.faiss_text_index_path = faiss_text_index_path\n",
    "        self.faiss_image_index_path = faiss_image_index_path\n",
    "        self.faiss_mean_index_path = faiss_mean_index_path\n",
    "        self.logger.info(f\"  数据库路径: {self.db_path}\")\n",
    "        self.logger.info(f\"  文本索引路径: {self.faiss_text_index_path}\")\n",
    "        self.logger.info(f\"  图像索引路径: {self.faiss_image_index_path}\")\n",
    "        self.logger.info(f\"  平均向量索引路径: {self.faiss_mean_index_path}\")\n",
    "\n",
    "        # 步骤 1: 初始化多模态编码器 (MultimodalEncoder)。\n",
    "        # Indexer 内部拥有一个 Encoder 实例，专门用于对其接收的文档进行编码。\n",
    "        self.logger.info(f\"  - 正在初始化内部 MultimodalEncoder，使用 CLIP 模型: {clip_model_name}...\")\n",
    "        try:\n",
    "            self.encoder = MultimodalEncoder(clip_model_name) # 创建编码器实例。\n",
    "            self.vector_dimension = self.encoder.vector_dimension # 从编码器获取产生的向量维度\n",
    "            self.logger.info(f\"  - MultimodalEncoder 初始化完成。特征向量维度为: {self.vector_dimension}。\")\n",
    "        except Exception as e_encoder:\n",
    "            self.logger.critical(f\"Indexer 初始化严重失败：内部 MultimodalEncoder 创建失败。错误: {e_encoder}\", exc_info=True)\n",
    "            raise RuntimeError(f\"Indexer 无法初始化 Encoder: {e_encoder}\") from e_encoder\n",
    "\n",
    "        # 步骤 2: 初始化 SQLite 数据库 (用于存储文档元数据)。\n",
    "        # 调用私有方法 `_init_db` 来确保数据库文件存在，并创建所需的表结构（如果尚不存在）。\n",
    "        self.logger.info(f\"  - 正在初始化 SQLite 数据库，路径: '{self.db_path}'...\")\n",
    "        try:\n",
    "            self._init_db() # 此方法会处理数据库目录的创建。\n",
    "            self.logger.info(f\"  - SQLite 数据库初始化完成。\")\n",
    "        except Exception as e_db_init:\n",
    "            self.logger.critical(f\"Indexer 初始化严重失败：SQLite 数据库初始化失败。错误: {e_db_init}\", exc_info=True)\n",
    "            raise RuntimeError(f\"Indexer 无法初始化数据库: {e_db_init}\") from e_db_init\n",
    "\n",
    "\n",
    "        # 步骤 3: 加载或创建三个独立的 Faiss 向量索引。\n",
    "        # 分别为文本向量、图像向量和平均向量（文本+图像组合）加载或创建 Faiss 索引。\n",
    "        # `_load_or_create_faiss_index` 方法会处理文件存在性检查、维度匹配和新索引创建的逻辑。\n",
    "        self.logger.info(f\"  - 正在加载或创建 Faiss 向量索引...\")\n",
    "        try:\n",
    "            self.text_index = self._load_or_create_faiss_index(self.faiss_text_index_path, \"文本(Text)\")\n",
    "            self.image_index = self._load_or_create_faiss_index(self.faiss_image_index_path, \"图像(Image)\")\n",
    "            self.mean_index = self._load_or_create_faiss_index(self.faiss_mean_index_path, \"平均(Mean)\")\n",
    "            self.logger.info(f\"  - 所有 Faiss 索引均已准备就绪。\")\n",
    "        except Exception as e_faiss_init:\n",
    "            self.logger.critical(f\"Indexer 初始化严重失败：一个或多个 Faiss 索引加载/创建失败。错误: {e_faiss_init}\", exc_info=True)\n",
    "            raise RuntimeError(f\"Indexer 无法初始化 Faiss 索引: {e_faiss_init}\") from e_faiss_init\n",
    "\n",
    "\n",
    "        self.logger.info(\"Indexer 初始化成功完成。\")\n",
    "\n",
    "\n",
    "    def _init_db(self):\n",
    "        \"\"\"\n",
    "        初始化 SQLite 数据库连接并创建所需的 'documents' 表（如果它还不存在）。\n",
    "        这个表用于存储文档的元数据，并将原始文档 ID (doc_id) 映射到数据库生成的\n",
    "        自增主键 `internal_id`。这个 `internal_id` 将作为 Faiss 索引中对应向量的 ID。\n",
    "        此方法还会确保数据库文件所在的目录存在。\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"正在连接并初始化数据库表结构于路径: '{self.db_path}'...\")\n",
    "        \n",
    "        # 确保数据库文件所在的目录存在，如果不存在则创建它。\n",
    "        db_directory = os.path.dirname(self.db_path)\n",
    "        if db_directory and not os.path.exists(db_directory): \n",
    "            try:\n",
    "                os.makedirs(db_directory, exist_ok=True) # exist_ok=True 表示如果目录已存在则不抛出错误。\n",
    "                self.logger.debug(f\"已确保数据库目录 '{db_directory}' 存在 (或已创建)。\")\n",
    "            except OSError as e:\n",
    "                self.logger.error(f\"创建数据库目录 '{db_directory}' 失败: {e}\", exc_info=True)\n",
    "                raise # Re-raise the exception as this is critical\n",
    "\n",
    "        try:\n",
    "            # 使用 'with' 语句确保数据库连接在使用后自动关闭，并能自动处理事务（默认提交，出错回滚）。\n",
    "            with sqlite3.connect(self.db_path) as conn:\n",
    "                cursor = conn.cursor() # 获取数据库游标，用于执行 SQL 命令。\n",
    "                \n",
    "                # SQL 语句，用于创建 'documents' 表。\n",
    "                # `IF NOT EXISTS` 确保如果表已经存在，则不会尝试重新创建它，从而避免错误。\n",
    "                # 表结构定义:\n",
    "                #   - internal_id: 整数类型，主键，自动增长。这是数据库内部ID，也将用作Faiss索引的ID。\n",
    "                #   - doc_id: 文本类型，唯一约束，不能为空。这是原始文档的唯一标识符 (例如来自JSON的'name'字段)。\n",
    "                #   - text: 文本类型，存储文档的文本内容，允许为空 (NULL)。\n",
    "                #   - image_path: 文本类型，存储关联图像文件的路径，允许为空。\n",
    "                cursor.execute('''\n",
    "                    CREATE TABLE IF NOT EXISTS documents (\n",
    "                        internal_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                        doc_id TEXT UNIQUE NOT NULL,\n",
    "                        text TEXT,\n",
    "                        image_path TEXT\n",
    "                    )\n",
    "                ''')\n",
    "                \n",
    "                # 可选：在 'doc_id' 列上创建一个索引。\n",
    "                # 这可以加快通过原始 `doc_id` 查找记录的速度，例如在 `index_documents` 方法中检查重复文档时。\n",
    "                cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_doc_id ON documents (doc_id)\")\n",
    "                \n",
    "                conn.commit() # 提交事务，使表结构更改和索引创建生效。\n",
    "                self.logger.info(f\"数据库表 'documents' (及索引 'idx_doc_id') 初始化成功，或已存在。\")\n",
    "        except sqlite3.Error as e: # Catch specific SQLite errors\n",
    "             self.logger.error(f\"严重错误：初始化 SQLite 数据库 '{self.db_path}' 失败。错误详情: {e}\", exc_info=True)\n",
    "             raise RuntimeError(f\"SQLite数据库操作失败: {e}\") from e # Re-raise as a more generic runtime error\n",
    "        except Exception as e_general:\n",
    "            self.logger.error(f\"初始化 SQLite 数据库 '{self.db_path}' 时发生未知错误。错误详情: {e_general}\", exc_info=True)\n",
    "            raise RuntimeError(f\"SQLite数据库初始化未知错误: {e_general}\") from e_general\n",
    "\n",
    "\n",
    "    def _load_or_create_faiss_index(self, index_path: str, index_type_description: str) -> faiss.Index:\n",
    "        \"\"\"\n",
    "        尝试从指定路径加载一个 Faiss 索引文件。\n",
    "        - 如果文件存在且其内部存储的向量维度与当前编码器 (`self.encoder`) 的输出维度匹配，则加载该索引。\n",
    "        - 如果文件不存在，或者文件存在但维度不匹配（表明该索引可能是用不同模型创建的），则创建一个新的、空的 Faiss 索引。\n",
    "        - 使用 `faiss.IndexIDMap2` 类型的索引，它允许我们将自定义的 64 位整数 ID 与每个向量关联起来。\n",
    "        此方法还会确保索引文件所在的目录存在。\n",
    "\n",
    "        Args:\n",
    "            index_path (str): Faiss 索引文件的期望路径。\n",
    "            index_type_description (str): 索引类型的描述性名称 (例如 \"文本\", \"图像\", \"平均\")，主要用于日志记录。\n",
    "\n",
    "        Returns:\n",
    "            faiss.Index: 加载的或新创建的 Faiss 索引对象 (具体类型为 `faiss.IndexIDMap2`)。\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"正在为 '{index_type_description}' 索引加载或创建 Faiss 文件于路径: '{index_path}'...\")\n",
    "\n",
    "        # 确保 Faiss 索引文件所在的目录存在，如果不存在则创建它。\n",
    "        index_directory = os.path.dirname(index_path)\n",
    "        if index_directory and not os.path.exists(index_directory): \n",
    "            try:\n",
    "                os.makedirs(index_directory, exist_ok=True)\n",
    "                self.logger.debug(f\"已确保 '{index_type_description}' 索引的目录 '{index_directory}' 存在 (或已创建)。\")\n",
    "            except OSError as e:\n",
    "                self.logger.error(f\"创建Faiss索引目录 '{index_directory}' 失败: {e}\", exc_info=True)\n",
    "                raise # Re-raise as this is critical\n",
    "\n",
    "\n",
    "        try:\n",
    "            # 检查指定的索引文件是否已经存在于文件系统中。\n",
    "            if os.path.exists(index_path) and os.path.isfile(index_path): # 确保是文件\n",
    "                self.logger.info(f\"发现已存在的 '{index_type_description}' Faiss 索引文件，尝试加载: {index_path}\")\n",
    "                # 使用 faiss.read_index 函数读取磁盘上的索引文件。\n",
    "                index = faiss.read_index(index_path)\n",
    "                self.logger.info(f\"文件 '{index_path}' 读取成功，包含 {index.ntotal} 个向量，维度为 {index.d}。\")\n",
    "\n",
    "                # **重要**: 检查加载的索引的维度 (`index.d`) 是否与当前编码器模型产生的向量维度 (`self.vector_dimension`) 一致。\n",
    "                if index.d != self.vector_dimension:\n",
    "                    # 如果维度不匹配，这意味着已加载的索引是用不同的（或不同配置的）CLIP 模型创建的，因此不能直接使用。\n",
    "                    self.logger.warning(f\"维度不匹配警告! 加载的 '{index_type_description}' 索引维度 ({index.d}) 与当前编码器配置的维度 ({self.vector_dimension}) 不一致。\")\n",
    "                    self.logger.warning(f\"这通常意味着之前的索引是用不同的模型创建的。将忽略已加载的旧索引，并创建一个新的空 '{index_type_description}' 索引。\")\n",
    "                    # 创建一个新的、空的 Faiss 索引来替换掉加载的不兼容的旧索引。\n",
    "                    index = self._create_new_faiss_index(index_type_description)\n",
    "                else:\n",
    "                    # 维度匹配，加载成功。\n",
    "                    self.logger.info(f\"成功加载 '{index_type_description}' Faiss 索引，维度 ({index.d}) 与当前模型匹配。索引中包含 {index.ntotal} 个向量。\")\n",
    "            else:\n",
    "                # 如果索引文件不存在。\n",
    "                self.logger.info(f\"未找到 '{index_type_description}' Faiss 索引文件: '{index_path}'。将创建一个新的空索引。\")\n",
    "                # 调用内部方法创建新的空索引。\n",
    "                index = self._create_new_faiss_index(index_type_description)\n",
    "        except Exception as e:\n",
    "            # 处理在加载或读取索引文件过程中可能发生的任何其他错误。\n",
    "            self.logger.error(f\"错误：加载或处理 '{index_type_description}' Faiss 索引 '{index_path}' 失败。错误详情: {e}\", exc_info=True)\n",
    "            self.logger.info(f\"作为安全回退机制，将创建一个新的空 '{index_type_description}' 索引。\")\n",
    "            # 即使加载失败，也创建一个新的空索引，以保证程序能够继续运行（尽管可能没有历史数据）。\n",
    "            index = self._create_new_faiss_index(index_type_description)\n",
    "        return index\n",
    "\n",
    "    def _create_new_faiss_index(self, index_type_description: str) -> faiss.Index:\n",
    "         \"\"\"\n",
    "         创建一个新的、空的 Faiss 索引。\n",
    "         该索引被配置为使用内积 (`IndexFlatIP`) 进行相似度搜索，并使用 `IndexIDMap2` 包装器\n",
    "         来支持为每个向量存储自定义的 64 位整数 ID。\n",
    "         `IndexFlatIP` 适用于存储原始（未压缩）向量并进行精确的、暴力的内积搜索。\n",
    "         对于已经 L2 归一化的向量，内积得分等价于余弦相似度。\n",
    "\n",
    "         Args:\n",
    "             index_type_description (str): 索引类型的描述 (例如 \"文本\", \"图像\")，用于日志记录。\n",
    "\n",
    "         Returns:\n",
    "             faiss.Index: 新创建的、空的 `faiss.IndexIDMap2` 索引对象。\n",
    "         \"\"\"\n",
    "         self.logger.info(f\"开始为 '{index_type_description}' 创建一个新的空 Faiss 索引...\")\n",
    "         # 步骤 1: 创建基础索引 (也称为 quantizer，在更复杂的索引类型中作用更明显)。\n",
    "         # 这里使用 `faiss.IndexFlatIP`:\n",
    "         #   - `IndexFlat`: 表示 Faiss 将存储完整的、未经压缩或量化的原始向量。这提供了最精确的搜索结果，但需要更多内存。\n",
    "         #   - `IP` (Inner Product): 表示该索引将使用内积作为向量间的距离/相似度度量。\n",
    "         #   当存储的向量都经过 L2 归一化时，它们之间的内积值等于它们之间的余弦相似度。\n",
    "         #   `self.vector_dimension` 是从 CLIP 模型获取的特征向量的维度。\n",
    "         quantizer = faiss.IndexFlatIP(self.vector_dimension)\n",
    "         self.logger.debug(f\"  为 '{index_type_description}' 创建了 IndexFlatIP 基础索引，维度: {self.vector_dimension}。\")\n",
    "\n",
    "         # 步骤 2: 创建 ID 映射包装器 `faiss.IndexIDMap2`。\n",
    "         #   - `IndexIDMap2` 包装了一个基础索引 (此处是 `quantizer`)。\n",
    "         #   - 它允许我们在向索引添加向量时，为每个向量指定一个我们自己定义的 64 位整数 ID。\n",
    "         #   - 在搜索时，它会返回这些我们指定的 ID，而不是 Faiss 内部的连续行号。\n",
    "         #   - '2' 在名称中通常表示它使用了更现代或更灵活的内部ID重映射机制。\n",
    "         #   - 我们将使用从 SQLite 数据库生成的 `internal_id` 作为这个自定义 ID。\n",
    "         index = faiss.IndexIDMap2(quantizer)\n",
    "         self.logger.debug(f\"  将 IndexFlatIP 包装在 IndexIDMap2 中，以支持自定义向量 ID。\")\n",
    "\n",
    "         self.logger.info(f\"已成功为 '{index_type_description}' 创建一个新的、空的 Faiss 索引 (类型: IndexIDMap2 包裹 IndexFlatIP)。\")\n",
    "         self.logger.info(f\"    索引维度: {self.vector_dimension}。\")\n",
    "         self.logger.info(f\"    相似度度量: 内积 (Inner Product) - 对于归一化向量，这等同于余弦相似度。\")\n",
    "         return index\n",
    "\n",
    "    def index_documents(self, documents: List[Dict[str, Any]]):\n",
    "        \"\"\"\n",
    "        核心的文档索引流程。\n",
    "        该方法接收一个文档列表，对每个文档进行多模态编码（文本和/或图像），\n",
    "        然后将文档的元数据存储到 SQLite 数据库中，并将生成的特征向量（文本向量、图像向量、平均向量）\n",
    "        及其对应的数据库内部ID (`internal_id`) 添加到各自的 Faiss 索引中。\n",
    "        此方法会处理基于 `doc_id` 的重复文档（即，如果一个具有相同 `doc_id` 的文档已存在于数据库中，则跳过它）。\n",
    "        为了提高效率，向量会分批收集，然后一次性批量添加到 Faiss 索引中。\n",
    "\n",
    "        Args:\n",
    "            documents (List[Dict[str, Any]]): 一个字典列表，其中每个字典代表一个待索引的文档。\n",
    "                                    每个字典应至少包含 'id' (原始文档ID), 'text' (文本内容), \n",
    "                                    和 'image_path' (关联图像的路径，可能为None) 这几个键。\n",
    "                                    这通常是 `load_data_from_json_and_associate_images` 函数的输出格式。\n",
    "        \"\"\"\n",
    "        # 检查输入的文档列表是否为空。\n",
    "        if not documents:\n",
    "            self.logger.info(\"未提供任何文档进行索引操作。流程结束。\")\n",
    "            return\n",
    "\n",
    "        self.logger.info(f\"开始执行文档索引流程，准备处理 {len(documents)} 个文档...\")\n",
    "        \n",
    "        # 初始化列表，用于批量收集需要添加到 Faiss 索引的向量和它们对应的 ID。\n",
    "        # 分别为文本、图像和平均向量准备独立的批处理列表。\n",
    "        text_vectors_batch: List[np.ndarray] = []   # 存储文本特征向量 (NumPy 数组)。\n",
    "        text_ids_batch: List[int] = []              # 存储与文本向量对应的 `internal_id` (整数)。\n",
    "        image_vectors_batch: List[np.ndarray] = []  # 存储图像特征向量。\n",
    "        image_ids_batch: List[int] = []             # 存储与图像向量对应的 `internal_id`。\n",
    "        mean_vectors_batch: List[np.ndarray] = []   # 存储平均（文本+图像）特征向量。\n",
    "        mean_ids_batch: List[int] = []              # 存储与平均向量对应的 `internal_id`。\n",
    "\n",
    "        # 初始化计数器，用于跟踪索引过程的各种统计数据。\n",
    "        processed_count = 0          # 成功处理并至少尝试了编码的文档数量。\n",
    "        skipped_duplicate_count = 0  # 因 `doc_id` 已存在于数据库中而被跳过的文档数量。\n",
    "        encoding_failure_count = 0   # 因编码阶段（文本或图像）出错而未能为其生成向量的文档数量。\n",
    "        db_insert_error_count = 0    # 因数据库插入操作出错而被跳过的文档数量。\n",
    "\n",
    "        conn: Optional[sqlite3.Connection] = None # 初始化数据库连接变量，确保在 try...finally 块中可见。\n",
    "        try:\n",
    "            # 步骤 1: 建立与 SQLite 数据库的连接。\n",
    "            self.logger.debug(f\"正在连接到数据库: {self.db_path}\")\n",
    "            conn = sqlite3.connect(self.db_path)\n",
    "            cursor = conn.cursor() # 获取数据库游标。\n",
    "            # sqlite3 默认在执行 DML 语句 (如 INSERT) 时会自动开始一个事务。\n",
    "            # 我们将在所有文档处理完毕后，在循环外部统一提交 (commit) 或回滚 (rollback) 事务，\n",
    "            # 以确保数据库操作的原子性（相对于整个批次而言）。\n",
    "\n",
    "            # 步骤 2: 遍历每个待索引的文档。\n",
    "            self.logger.info(f\"开始遍历 {len(documents)} 个文档进行处理和编码...\")\n",
    "            for i, doc_data in enumerate(documents): # 使用 enumerate 获取索引和文档数据。\n",
    "                doc_id = doc_data.get('id')          # 获取原始文档 ID。\n",
    "                text_content = doc_data.get('text')  # 获取文本内容。\n",
    "                image_file_path = doc_data.get('image_path') # 获取图像路径。\n",
    "\n",
    "                self.logger.debug(f\"处理文档 {i+1}/{len(documents)}: ID='{doc_id}'\")\n",
    "\n",
    "                # 基本有效性验证：`doc_id` 必须存在。\n",
    "                if not doc_id:\n",
    "                    self.logger.warning(f\"跳过列表中的第 {i+1} 条记录（原始索引 {i}），因其缺少 'id' 字段。记录: {doc_data}\")\n",
    "                    continue # 跳到下一个文档。\n",
    "                # 至少需要文本或图像路径之一才能进行有意义的编码。\n",
    "                if not text_content and not image_file_path:\n",
    "                     self.logger.warning(f\"跳过文档 ID '{doc_id}'，因为它既没有文本内容，也没有关联的图像路径。无法为其生成任何向量。\")\n",
    "                     continue # 跳到下一个文档。\n",
    "\n",
    "                # --- 2a. 检查文档是否已在数据库中存在 (基于 `doc_id`) ---\n",
    "                try:\n",
    "                    cursor.execute(\"SELECT internal_id FROM documents WHERE doc_id = ?\", (str(doc_id),)) # Ensure doc_id is string\n",
    "                    existing_record = cursor.fetchone() # 获取查询结果（如果存在的话）。\n",
    "                    if existing_record:\n",
    "                         self.logger.debug(f\"文档 ID '{doc_id}' 已存在于数据库中 (其 internal_id 为: {existing_record[0]})。将跳过此重复文档的索引。\")\n",
    "                         skipped_duplicate_count += 1\n",
    "                         continue # 跳到下一个文档。\n",
    "                except sqlite3.Error as e_check:\n",
    "                    self.logger.error(f\"检查文档 ID '{doc_id}' 是否存在时发生数据库错误: {e_check}。将跳过此文档。\")\n",
    "                    db_insert_error_count +=1 # 计入数据库错误\n",
    "                    continue\n",
    "\n",
    "\n",
    "                # --- 2b. 将文档元数据插入到数据库，并获取生成的 `internal_id` ---\n",
    "                internal_id: Optional[int] = None # 初始化 internal_id。\n",
    "                try:\n",
    "                    # 执行 INSERT 语句将新文档的元数据插入到 'documents' 表。\n",
    "                    # 使用参数化查询 (问号占位符) 来防止 SQL 注入攻击。\n",
    "                    cursor.execute(\n",
    "                        \"INSERT INTO documents (doc_id, text, image_path) VALUES (?, ?, ?)\",\n",
    "                        (str(doc_id), text_content, image_file_path) # Ensure doc_id is string\n",
    "                    )\n",
    "                    # 获取刚刚插入行的自增主键 (`internal_id`)。\n",
    "                    # `cursor.lastrowid` 返回最后插入行的 ROWID。\n",
    "                    internal_id = cursor.lastrowid\n",
    "                    if internal_id is None: \n",
    "                        self.logger.error(f\"严重数据库错误：为文档 '{doc_id}' 插入元数据后，未能获取有效的 internal_id (lastrowid is None)。\")\n",
    "                        raise sqlite3.Error(f\"数据库错误：未能为文档 '{doc_id}' 获取 internal_id。\")\n",
    "                    self.logger.debug(f\"文档 '{doc_id}' 的元数据已成功插入数据库，获得的 internal_id: {internal_id}\")\n",
    "\n",
    "                except sqlite3.IntegrityError:\n",
    "                    # 当尝试插入的 `doc_id` 违反了表的 UNIQUE 约束时（理论上不应发生，因为前面已检查过）。\n",
    "                    self.logger.error(f\"数据库完整性错误：尝试插入已存在的文档 ID '{doc_id}'（可能是并发问题或检查逻辑遗漏）。将跳过此文档。\")\n",
    "                    skipped_duplicate_count += 1 \n",
    "                    continue \n",
    "                except sqlite3.Error as db_e:\n",
    "                    self.logger.error(f\"数据库错误：在为文档 '{doc_id}' 插入元数据时发生错误: {db_e}。将跳过此文档的索引。\")\n",
    "                    db_insert_error_count += 1\n",
    "                    continue \n",
    "\n",
    "                # --- 2c. 使用内部 Encoder 对文档进行多模态向量化 ---\n",
    "                encoded_data: Optional[Dict[str, Optional[np.ndarray]]] = None # 初始化编码结果。\n",
    "                if internal_id is not None: # 只有成功获取 internal_id 后才进行编码\n",
    "                    try:\n",
    "                        self.logger.debug(f\"开始为文档 '{doc_id}' (internal_id: {internal_id}) 进行多模态编码...\")\n",
    "                        encoded_data = self.encoder.encode(text=text_content, image_path=image_file_path)\n",
    "                    except Exception as encode_e:\n",
    "                        self.logger.error(f\"严重错误：在编码文档 '{doc_id}' (internal_id: {internal_id}) 时发生意外错误: {encode_e}\", exc_info=True)\n",
    "                        self.logger.warning(f\"注意：此文档的元数据可能已存入数据库，但其向量将不会被添加到 Faiss 索引中，因为它编码失败。\")\n",
    "                        encoding_failure_count += 1\n",
    "                        continue \n",
    "\n",
    "                # --- 2d. 将成功编码的向量添加到对应的批处理列表中 ---\n",
    "                at_least_one_vector_added_for_doc = False\n",
    "                if encoded_data and internal_id is not None: \n",
    "                    if encoded_data.get('text_vector') is not None:\n",
    "                        text_vectors_batch.append(encoded_data['text_vector']) # type: ignore\n",
    "                        text_ids_batch.append(internal_id)\n",
    "                        at_least_one_vector_added_for_doc = True\n",
    "                        self.logger.debug(f\"  文本向量已为文档 '{doc_id}' (internal_id: {internal_id}) 准备好加入批处理。\")\n",
    "                    \n",
    "                    if encoded_data.get('image_vector') is not None:\n",
    "                        image_vectors_batch.append(encoded_data['image_vector']) # type: ignore\n",
    "                        image_ids_batch.append(internal_id)\n",
    "                        at_least_one_vector_added_for_doc = True\n",
    "                        self.logger.debug(f\"  图像向量已为文档 '{doc_id}' (internal_id: {internal_id}) 准备好加入批处理。\")\n",
    "\n",
    "                    if encoded_data.get('mean_vector') is not None:\n",
    "                        mean_vectors_batch.append(encoded_data['mean_vector']) # type: ignore\n",
    "                        mean_ids_batch.append(internal_id)\n",
    "                        at_least_one_vector_added_for_doc = True\n",
    "                        self.logger.debug(f\"  平均向量已为文档 '{doc_id}' (internal_id: {internal_id}) 准备好加入批处理。\")\n",
    "                    \n",
    "                    if not at_least_one_vector_added_for_doc and (text_content or image_file_path):\n",
    "                        self.logger.warning(f\"文档 '{doc_id}' (internal_id: {internal_id}) 有内容，但编码后未生成任何有效向量。\")\n",
    "                        encoding_failure_count += 1\n",
    "                    elif at_least_one_vector_added_for_doc:\n",
    "                        processed_count += 1 \n",
    "                \n",
    "                elif internal_id is not None and (text_content or image_file_path): \n",
    "                    self.logger.warning(f\"文档 '{doc_id}' (internal_id: {internal_id}) 编码返回 None，尽管有内容。计为编码失败。\")\n",
    "                    encoding_failure_count += 1\n",
    "\n",
    "\n",
    "            # --- 文档遍历和初步处理完成 ---\n",
    "            self.logger.info(f\"所有 {len(documents)} 个输入文档已遍历处理完毕。\")\n",
    "            self.logger.info(f\"准备将收集到的向量批量添加到 Faiss 索引中...\")\n",
    "            self.logger.info(f\"  - 待添加文本向量数量: {len(text_ids_batch)}\")\n",
    "            self.logger.info(f\"  - 待添加图像向量数量: {len(image_ids_batch)}\")\n",
    "            self.logger.info(f\"  - 待添加平均向量数量: {len(mean_ids_batch)}\")\n",
    "\n",
    "            # --- 步骤 3: 批量将向量和 ID 添加到对应的 Faiss 索引 ---\n",
    "            if text_vectors_batch: \n",
    "                ids_np_text = np.array(text_ids_batch, dtype='int64')\n",
    "                vectors_np_text = np.array(text_vectors_batch, dtype='float32')\n",
    "                self.text_index.add_with_ids(vectors_np_text, ids_np_text) \n",
    "                self.logger.info(f\"已成功向文本(Text) Faiss 索引批量添加 {len(text_vectors_batch)} 个向量。当前索引总数: {self.text_index.ntotal}\")\n",
    "\n",
    "            if image_vectors_batch:\n",
    "                ids_np_image = np.array(image_ids_batch, dtype='int64')\n",
    "                vectors_np_image = np.array(image_vectors_batch, dtype='float32')\n",
    "                self.image_index.add_with_ids(vectors_np_image, ids_np_image)\n",
    "                self.logger.info(f\"已成功向图像(Image) Faiss 索引批量添加 {len(image_vectors_batch)} 个向量。当前索引总数: {self.image_index.ntotal}\")\n",
    "\n",
    "            if mean_vectors_batch:\n",
    "                ids_np_mean = np.array(mean_ids_batch, dtype='int64')\n",
    "                vectors_np_mean = np.array(mean_vectors_batch, dtype='float32')\n",
    "                self.mean_index.add_with_ids(vectors_np_mean, ids_np_mean)\n",
    "                self.logger.info(f\"已成功向平均(Mean) Faiss 索引批量添加 {len(mean_vectors_batch)} 个向量。当前索引总数: {self.mean_index.ntotal}\")\n",
    "\n",
    "            # --- 步骤 4: 提交数据库事务 ---\n",
    "            if conn: \n",
    "                conn.commit()\n",
    "                self.logger.info(\"数据库事务已成功提交。所有元数据更改已持久化。\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.critical(f\"严重错误：在文档索引过程中发生意外的顶级异常: {e}\", exc_info=True)\n",
    "            if conn:\n",
    "                self.logger.info(\"检测到严重错误，正在尝试回滚数据库事务以撤销未提交的更改...\")\n",
    "                try:\n",
    "                    conn.rollback()\n",
    "                    self.logger.info(\"数据库事务已成功回滚。\")\n",
    "                except Exception as rb_e:\n",
    "                    self.logger.error(f\"错误：尝试回滚数据库事务时失败: {rb_e}\", exc_info=True)\n",
    "        finally:\n",
    "            if conn:\n",
    "                conn.close()\n",
    "                self.logger.debug(\"数据库连接已关闭。\")\n",
    "\n",
    "        # --- 打印索引过程的最终总结信息 ---\n",
    "        self.logger.info(f\"\\n--- 文档索引过程总结 ---\")\n",
    "        self.logger.info(f\"- 输入文档总数: {len(documents)}\")\n",
    "        self.logger.info(f\"- 成功处理并为其生成了至少一个向量的文档数: {processed_count}\")\n",
    "        self.logger.info(f\"- 因 'doc_id' 在数据库中已存在而跳过的文档数: {skipped_duplicate_count}\")\n",
    "        self.logger.info(f\"- 因编码阶段（文本/图像）错误而未能生成向量的文档数: {encoding_failure_count}\")\n",
    "        self.logger.info(f\"- 因数据库操作（如插入元数据）错误而跳过的文档数: {db_insert_error_count}\")\n",
    "        self.logger.info(f\"- 当前文本 Faiss 索引中的向量总数: {getattr(self.text_index, 'ntotal', 'N/A')}\")\n",
    "        self.logger.info(f\"- 当前图像 Faiss 索引中的向量总数: {getattr(self.image_index, 'ntotal', 'N/A')}\")\n",
    "        self.logger.info(f\"- 当前平均 Faiss 索引中的向量总数: {getattr(self.mean_index, 'ntotal', 'N/A')}\")\n",
    "        \n",
    "        db_final_count = self.get_document_count() \n",
    "        self.logger.info(f\"- 当前 SQLite 数据库中存储的文档元数据记录总数: {db_final_count}\")\n",
    "        \n",
    "        max_faiss_vectors = 0\n",
    "        if hasattr(self.text_index, 'ntotal'): max_faiss_vectors = max(max_faiss_vectors, self.text_index.ntotal)\n",
    "        if hasattr(self.image_index, 'ntotal'): max_faiss_vectors = max(max_faiss_vectors, self.image_index.ntotal)\n",
    "        if hasattr(self.mean_index, 'ntotal'): max_faiss_vectors = max(max_faiss_vectors, self.mean_index.ntotal)\n",
    "\n",
    "        if db_final_count < max_faiss_vectors:\n",
    "             self.logger.warning(f\"数据一致性警告：数据库记录数 ({db_final_count}) 少于某个 Faiss 索引中的最大向量数 ({max_faiss_vectors})。数据可能存在不一致！请检查日志。\")\n",
    "        self.logger.info(f\"--- 文档索引过程结束 ---\")\n",
    "\n",
    "\n",
    "    def get_document_by_internal_id(self, internal_id: int) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        根据 Faiss 搜索返回的 `internal_id` (即数据库中的主键)，从 SQLite 数据库中检索对应的原始文档元数据。\n",
    "\n",
    "        Args:\n",
    "            internal_id (int): 要查询的文档在数据库中的 `internal_id` (通常由 Faiss 搜索返回)。\n",
    "\n",
    "        Returns:\n",
    "            Optional[Dict[str, Any]]: 如果找到文档，则返回一个包含文档信息的字典。\n",
    "                            该字典通常包含 'id' (原始 doc_id), 'text', 'image_path', 和 'internal_id'。\n",
    "                            如果数据库中找不到具有该 `internal_id` 的记录，则返回 None。\n",
    "        \"\"\"\n",
    "        self.logger.debug(f\"尝试从数据库根据 internal_id '{internal_id}' 获取文档元数据...\")\n",
    "        try:\n",
    "            # 连接到 SQLite 数据库。\n",
    "            with sqlite3.connect(self.db_path) as conn:\n",
    "                # 设置 conn.row_factory = sqlite3.Row 使得查询结果可以像字典一样通过列名访问，更方便。\n",
    "                conn.row_factory = sqlite3.Row \n",
    "                cursor = conn.cursor()\n",
    "                # 执行 SELECT 查询，根据 internal_id 查找记录。\n",
    "                cursor.execute(\n",
    "                    \"SELECT internal_id, doc_id, text, image_path FROM documents WHERE internal_id = ?\",\n",
    "                    (internal_id,) # 注意参数是一个元组。\n",
    "                )\n",
    "                row = cursor.fetchone() # 获取一行结果。\n",
    "                \n",
    "                if row:\n",
    "                    # 如果找到了记录 (row 不为 None)。\n",
    "                    doc_data = dict(row) # 将 sqlite3.Row 对象转换为标准的 Python 字典。\n",
    "                    # 为了与外部接口或数据结构保持一致（例如，原始输入时的 'id'），\n",
    "                    # 将从数据库中取出的 'doc_id' 键重命名为 'id'。\n",
    "                    doc_data['id'] = doc_data.pop('doc_id')\n",
    "                    self.logger.debug(f\"成功为 internal_id '{internal_id}' 找到文档元数据: ID='{doc_data['id']}'\")\n",
    "                    return doc_data # 返回包含文档信息的字典。\n",
    "                else:\n",
    "                    # 如果没有找到具有该 internal_id 的记录。\n",
    "                    self.logger.warning(f\"未能在数据库中找到 internal_id 为 '{internal_id}' 的文档元数据。\")\n",
    "                    return None # 返回 None。\n",
    "        except sqlite3.Error as e_sql:\n",
    "             self.logger.error(f\"数据库错误：从数据库根据 internal_id '{internal_id}' 获取文档时发生错误: {e_sql}\", exc_info=True)\n",
    "             return None \n",
    "        except Exception as e_general:\n",
    "             self.logger.error(f\"未知错误：从数据库根据 internal_id '{internal_id}' 获取文档时发生: {e_general}\", exc_info=True)\n",
    "             return None \n",
    "\n",
    "    def get_documents_by_internal_ids(self, internal_ids: List[int]) -> Dict[int, Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        根据一个 `internal_id` 的列表，从 SQLite 数据库中批量检索对应的多个文档的元数据。\n",
    "        使用批量查询 (SELECT ... WHERE internal_id IN (...)) 通常比多次单独查询更高效，\n",
    "        尤其是在处理 Faiss 返回的 Top-K 结果列表时。\n",
    "\n",
    "        Args:\n",
    "            internal_ids (List[int]): 一个包含多个数据库 `internal_id` 的整数列表。\n",
    "\n",
    "        Returns:\n",
    "            Dict[int, Dict[str, Any]]: 一个字典，其中键是 `internal_id`，值是对应的文档数据字典\n",
    "                             (通常包含 'id', 'text', 'image_path', 'internal_id')。\n",
    "                             如果列表中的某个 ID 在数据库中找不到，则结果字典中不会包含该 ID 的条目。\n",
    "                             如果输入的 `internal_ids` 列表为空，则返回一个空字典。\n",
    "        \"\"\"\n",
    "        # 如果输入的 ID 列表为空，直接返回空字典，无需查询数据库。\n",
    "        if not internal_ids:\n",
    "            self.logger.debug(\"请求批量获取文档，但提供的 internal_id 列表为空。返回空结果。\")\n",
    "            return {}\n",
    "\n",
    "        self.logger.debug(f\"尝试从数据库根据 internal_id 列表 (共 {len(internal_ids)} 个) 批量获取文档元数据...\")\n",
    "        results: Dict[int, Dict[str, Any]] = {} # 初始化结果字典。\n",
    "        try:\n",
    "            # 连接到 SQLite 数据库。\n",
    "            with sqlite3.connect(self.db_path) as conn:\n",
    "                conn.row_factory = sqlite3.Row # 设置行工厂，方便处理查询结果。\n",
    "                cursor = conn.cursor()\n",
    "\n",
    "                # 构建 SQL 查询语句，使用 IN 操作符和参数占位符进行批量查询。\n",
    "                # 1. 创建占位符字符串: \"(?, ?, ..., ?)\" - 每个 ID 对应一个 '?'。\n",
    "                placeholders = ','.join('?' for _ in internal_ids)\n",
    "                # 2. 构建完整的 SQL 查询语句。\n",
    "                query = f\"SELECT internal_id, doc_id, text, image_path FROM documents WHERE internal_id IN ({placeholders})\"\n",
    "                self.logger.debug(f\"执行批量查询SQL: {query} (参数数量: {len(internal_ids)})\")\n",
    "\n",
    "                # 执行查询，将 ID 列表作为参数传递给 execute 方法。\n",
    "                cursor.execute(query, internal_ids)\n",
    "                rows = cursor.fetchall() # 获取所有匹配的行。\n",
    "                self.logger.debug(f\"数据库批量查询返回了 {len(rows)} 行记录。\")\n",
    "\n",
    "                # 遍历查询结果。\n",
    "                for row in rows:\n",
    "                    doc_data = dict(row) # 将 sqlite3.Row 转换为字典。\n",
    "                    doc_data['id'] = doc_data.pop('doc_id') # 重命名 'doc_id' 为 'id'。\n",
    "                    # 使用 internal_id 作为键，将文档数据存入结果字典。\n",
    "                    results[doc_data['internal_id']] = doc_data\n",
    "                \n",
    "                # 检查是否有ID未找到 (如果 len(results) < len(internal_ids))\n",
    "                if len(results) < len(internal_ids):\n",
    "                    found_ids_set = set(results.keys()) # More efficient for checking\n",
    "                    missing_ids = [id_val for id_val in internal_ids if id_val not in found_ids_set]\n",
    "                    if missing_ids:\n",
    "                         self.logger.warning(f\"在批量获取文档时，以下 internal_id 未在数据库中找到: {missing_ids}\")\n",
    "\n",
    "        except sqlite3.Error as e_sql:\n",
    "             self.logger.error(f\"数据库错误：从数据库根据 internal_id 列表批量获取文档时发生: {e_sql}\", exc_info=True)\n",
    "        except Exception as e_general:\n",
    "            self.logger.error(f\"未知错误：从数据库根据 internal_id 列表批量获取文档时发生: {e_general}\", exc_info=True)\n",
    "        \n",
    "        self.logger.debug(f\"批量获取文档元数据完成，共返回 {len(results)} 个文档的信息。\")\n",
    "        return results\n",
    "\n",
    "    def get_document_count(self) -> int:\n",
    "         \"\"\"\n",
    "         获取当前 SQLite 数据库 'documents' 表中存储的文档总数量。\n",
    "\n",
    "         Returns:\n",
    "             int: 数据库中 'documents' 表的总行数。如果发生错误，则返回 0。\n",
    "         \"\"\"\n",
    "         self.logger.debug(f\"开始从数据库 '{self.db_path}' 获取文档总数...\")\n",
    "         try:\n",
    "             # 连接到 SQLite 数据库。\n",
    "             with sqlite3.connect(self.db_path) as conn:\n",
    "                 cursor = conn.cursor()\n",
    "                 # 执行 COUNT(*) 查询获取总行数。\n",
    "                 cursor.execute(\"SELECT COUNT(*) FROM documents\")\n",
    "                 # fetchone() 返回一个包含单个值的元组，例如 (50,)。\n",
    "                 count_result = cursor.fetchone()\n",
    "                 # 提取元组中的计数值。如果查询无结果（理论上 COUNT(*) 总有结果，但做个健壮性检查），则默认为 0。\n",
    "                 count = count_result[0] if count_result and count_result[0] is not None else 0\n",
    "                 self.logger.debug(f\"数据库中文档总数为: {count}\")\n",
    "                 return count\n",
    "         except sqlite3.Error as e_sql:\n",
    "              self.logger.error(f\"数据库错误：从数据库获取文档总数时发生错误: {e_sql}\", exc_info=True)\n",
    "              return 0 \n",
    "         except Exception as e_general:\n",
    "              self.logger.error(f\"未知错误：从数据库获取文档总数时发生: {e_general}\", exc_info=True)\n",
    "              return 0 \n",
    "\n",
    "    def save_indices(self):\n",
    "        \"\"\"\n",
    "        将内存中的所有三个 Faiss 索引（文本、图像、平均）分别保存到它们对应的文件路径中。\n",
    "        这个方法用于持久化索引的状态，以便在下次程序启动时可以加载这些索引，从而避免重新处理和编码所有文档。\n",
    "        只有当索引非空（即包含至少一个向量）时，才会执行保存操作。\n",
    "        \"\"\"\n",
    "        self.logger.info(\"开始尝试将所有 Faiss 索引保存到磁盘文件...\")\n",
    "        # 调用内部辅助方法 `_save_single_index` 分别保存每个索引。\n",
    "        # 传递索引对象、目标文件路径和索引类型描述（用于日志）。\n",
    "        if hasattr(self, 'text_index'):\n",
    "             self._save_single_index(self.text_index, self.faiss_text_index_path, \"文本(Text)\")\n",
    "        else:\n",
    "            self.logger.warning(\"文本(Text)索引对象不存在，无法保存。\")\n",
    "\n",
    "        if hasattr(self, 'image_index'):\n",
    "            self._save_single_index(self.image_index, self.faiss_image_index_path, \"图像(Image)\")\n",
    "        else:\n",
    "            self.logger.warning(\"图像(Image)索引对象不存在，无法保存。\")\n",
    "        \n",
    "        if hasattr(self, 'mean_index'):\n",
    "            self._save_single_index(self.mean_index, self.faiss_mean_index_path, \"平均(Mean)\")\n",
    "        else:\n",
    "            self.logger.warning(\"平均(Mean)索引对象不存在，无法保存。\")\n",
    "\n",
    "        self.logger.info(\"所有 Faiss 索引的保存操作已完成（或已跳过空索引/不存在的索引）。\")\n",
    "\n",
    "    def _save_single_index(self, index: Optional[faiss.Index], index_path: str, index_type_description: str):\n",
    "        \"\"\"\n",
    "        辅助方法：保存单个 Faiss 索引到指定的文件路径。\n",
    "        仅当索引对象有效且包含至少一个向量时才执行保存。\n",
    "        此方法还会确保索引文件要保存到的目录存在。\n",
    "\n",
    "        Args:\n",
    "            index (Optional[faiss.Index]): 需要保存的 Faiss 索引对象。可能是 None。\n",
    "            index_path (str): 保存索引的目标文件完整路径。\n",
    "            index_type_description (str): 索引类型的描述性名称 (例如 \"文本\", \"图像\")，用于日志记录。\n",
    "        \"\"\"\n",
    "        self.logger.debug(f\"准备保存 '{index_type_description}' Faiss 索引到路径: '{index_path}'...\")\n",
    "        \n",
    "        if index is None:\n",
    "            self.logger.warning(f\"  警告：'{index_type_description}' Faiss 索引对象为 None，无法执行保存操作。\")\n",
    "            return\n",
    "\n",
    "        # 检查索引对象是否有效（存在 `ntotal` 属性，表示向量数量）以及向量数量是否大于 0。\n",
    "        if hasattr(index, 'ntotal') and index.ntotal > 0:\n",
    "            try:\n",
    "                # 确保索引文件要保存到的目录存在，如果不存在则创建它。\n",
    "                index_directory = os.path.dirname(index_path)\n",
    "                if index_directory and not os.path.exists(index_directory): \n",
    "                    os.makedirs(index_directory, exist_ok=True)\n",
    "                    self.logger.debug(f\"  已确保 '{index_type_description}' 索引的保存目录 '{index_directory}' 存在 (或已创建)。\")\n",
    "\n",
    "                # 使用 faiss.write_index 函数将内存中的索引对象写入到指定的磁盘文件。\n",
    "                faiss.write_index(index, index_path)\n",
    "                self.logger.info(f\"  成功：'{index_type_description}' Faiss 索引 (包含 {index.ntotal} 个向量) 已保存到: {index_path}\")\n",
    "            except Exception as e:\n",
    "                # 处理在保存索引过程中可能发生的错误 (例如，磁盘空间不足、文件写入权限问题)。\n",
    "                self.logger.error(f\"  错误：保存 '{index_type_description}' Faiss 索引到 '{index_path}' 失败。错误详情: {e}\", exc_info=True)\n",
    "        elif hasattr(index, 'ntotal'): # 索引存在但为空 (ntotal == 0)\n",
    "             self.logger.info(f\"  跳过：'{index_type_description}' Faiss 索引为空 (ntotal={index.ntotal})，因此不保存到 '{index_path}'。\")\n",
    "        else: # 索引对象无效或未正确初始化 \n",
    "             self.logger.warning(f\"  警告：'{index_type_description}' Faiss 索引似乎未正确初始化 (缺少 ntotal 属性)，无法执行保存操作。\")\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        关闭 Indexer 实例时调用的清理方法。\n",
    "        主要职责是确保所有内存中的 Faiss 索引都已尝试保存到磁盘。\n",
    "        SQLite 数据库连接是通过 `with sqlite3.connect(...)` 语句管理的，在每个相关方法结束时会自动关闭，\n",
    "        因此这里不需要显式关闭数据库连接。\n",
    "        Faiss 索引对象本身在 Python 中是内存对象，它们不需要像文件句柄那样显式关闭；保存它们的状态即是“关闭”操作。\n",
    "        \"\"\"\n",
    "        self.logger.info(\"开始关闭 Indexer 实例...\")\n",
    "        # 调用 save_indices 方法，确保存储所有 Faiss 索引的最新状态。\n",
    "        self.save_indices()\n",
    "        self.logger.info(\"Indexer 实例关闭完成。所有 Faiss 索引已尝试保存。\")\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# 检索器类 (Retriever)\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "class Retriever:\n",
    "    \"\"\"\n",
    "    Retriever 类负责处理用户的查询（可以是文本、图像路径或两者结合的多模态查询），\n",
    "    并从已建立的索引中检索最相关的文档。其工作流程如下：\n",
    "\n",
    "    1.  **接收查询**: 用户通过 `retrieve` 方法提交查询。\n",
    "    2.  **查询编码**: 利用与 `Indexer` 中相同的 `MultimodalEncoder` 实例对用户查询进行向量化，\n",
    "        将其转换为与索引文档相同向量空间中的特征向量（可能包括文本向量、图像向量和/或平均向量）。\n",
    "    3.  **选择策略**: 根据查询的类型（纯文本、纯图像、多模态）和可用性，\n",
    "        选择最合适的 Faiss 索引（文本索引、图像索引或平均向量索引）以及对应的查询向量进行搜索。\n",
    "        例如，纯文本查询将使用文本向量在文本索引中搜索。\n",
    "    4.  **相似度搜索**: 在选定的 Faiss 索引中执行 Top-K 相似度搜索，找出与查询向量最相似的 K 个向量。\n",
    "        搜索结果是这些向量的 `internal_id` (与数据库主键对应) 和它们与查询向量的相似度得分。\n",
    "    5.  **获取元数据**: 使用检索到的 `internal_id` 列表，通过 `Indexer` 的接口从 SQLite 数据库中批量获取\n",
    "        这些最相关文档的完整元数据（如原始ID、文本内容、图像路径等）。\n",
    "    6.  **结果组合与返回**: 将获取到的文档元数据与它们各自的相似度得分结合起来，\n",
    "        并按照相似度得分从高到低（表示最相关）排序，最终返回一个包含这些信息的文档列表。\n",
    "\n",
    "    Retriever 依赖于一个已经初始化并填充了数据和索引的 `Indexer` 实例。\n",
    "    它复用 `Indexer` 的编码器以保证查询和文档编码的一致性，并访问 `Indexer` 中的 Faiss 索引和数据库。\n",
    "    \"\"\"\n",
    "    def __init__(self, indexer: Indexer):\n",
    "        \"\"\"\n",
    "        初始化 Retriever 实例。\n",
    "\n",
    "        Args:\n",
    "            indexer (Indexer): 一个已经初始化并包含了数据和索引的 `Indexer` 类的实例。\n",
    "                               Retriever 的所有操作都依赖于这个 `Indexer` 实例提供的资源。\n",
    "\n",
    "        Raises:\n",
    "            ValueError: 如果传入的 `indexer` 不是 `Indexer` 类的有效实例，或者该实例似乎缺少\n",
    "                        必要的 Faiss 索引属性 (text_index, image_index, mean_index)，则抛出此异常。\n",
    "                        一个没有有效索引源的 Retriever 是无法工作的。\n",
    "        \"\"\"\n",
    "        self.logger = logging.getLogger(__name__ + \".\" + self.__class__.__name__)\n",
    "        self.logger.info(\"开始初始化 Retriever...\")\n",
    "        \n",
    "        # 验证传入的 indexer 参数的有效性。\n",
    "        if not isinstance(indexer, Indexer):\n",
    "             msg = \"Retriever 初始化错误: 需要一个有效的 Indexer 实例，但收到的不是。\"\n",
    "             self.logger.error(msg)\n",
    "             raise ValueError(msg)\n",
    "        \n",
    "        # 进一步验证 Indexer 实例是否已成功创建了所需的 Faiss 索引对象。\n",
    "        required_indices_attributes = ['text_index', 'image_index', 'mean_index', 'encoder', 'vector_dimension']\n",
    "        missing_attrs = [attr for attr in required_indices_attributes if not hasattr(indexer, attr) or getattr(indexer, attr) is None]\n",
    "        if missing_attrs:\n",
    "            msg = f\"Retriever 初始化错误: 提供的 Indexer 实例缺少以下必需的属性: {', '.join(missing_attrs)}。请确保 Indexer 已成功初始化。\"\n",
    "            self.logger.error(msg)\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        # 保存对传入的 Indexer 实例的引用。\n",
    "        self.indexer: Indexer = indexer\n",
    "        # 复用 Indexer 内部的 Encoder 实例。\n",
    "        self.encoder: MultimodalEncoder = self.indexer.encoder\n",
    "        # 从 Indexer 获取向量维度。\n",
    "        self.vector_dimension: int = self.indexer.vector_dimension\n",
    "        self.logger.info(f\"  Retriever 将使用 Indexer 的编码器 (向量维度: {self.vector_dimension})。\")\n",
    "\n",
    "        # 获取对 Indexer 中三个 Faiss 索引的直接引用。\n",
    "        self.text_index: faiss.Index = self.indexer.text_index\n",
    "        self.image_index: faiss.Index = self.indexer.image_index\n",
    "        self.mean_index: faiss.Index = self.indexer.mean_index\n",
    "\n",
    "        # 检查所有关联的 Faiss 索引是否都为空。\n",
    "        text_index_ntotal = getattr(self.text_index, 'ntotal', 0) \n",
    "        image_index_ntotal = getattr(self.image_index, 'ntotal', 0)\n",
    "        mean_index_ntotal = getattr(self.mean_index, 'ntotal', 0)\n",
    "        \n",
    "        if text_index_ntotal == 0 and image_index_ntotal == 0 and mean_index_ntotal == 0:\n",
    "             self.logger.warning(\"Retriever 初始化警告: Indexer 中的所有 Faiss 索引当前都为空。\")\n",
    "             self.logger.warning(\"  这意味着任何检索操作都将无法找到任何匹配的文档。\")\n",
    "             self.logger.warning(\"  请确保 Indexer 已成功索引了数据，或者检查索引建立过程的日志。\")\n",
    "        else:\n",
    "             self.logger.info(f\"Retriever 初始化成功。关联的 Indexer 状态如下:\")\n",
    "             self.logger.info(f\"    - 文本(Text)索引中向量数: {text_index_ntotal}\")\n",
    "             self.logger.info(f\"    - 图像(Image)索引中向量数: {image_index_ntotal}\")\n",
    "             self.logger.info(f\"    - 平均(Mean)索引中向量数: {mean_index_ntotal}\")\n",
    "        self.logger.info(\"Retriever 初始化完成。\")\n",
    "\n",
    "\n",
    "    def retrieve(self, query: Union[str, Dict[str, str]], k: int = 5) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        执行完整的检索流程：接收用户查询 -> 对查询进行编码 -> 根据查询类型选择合适的索引和查询向量 ->\n",
    "        在选定的 Faiss 索引中搜索相似向量 -> 获取这些向量对应的原始文档元数据 -> 组合信息并返回结果。\n",
    "\n",
    "        Args:\n",
    "            query (Union[str, Dict[str, str]]): 用户提交的查询。可以是：\n",
    "                - str: 一个纯文本查询字符串。\n",
    "                - Dict: 一个字典，用于表示更复杂的查询类型：\n",
    "                    - {'text': '文本内容', 'image_path': '图像路径'} : 多模态查询，结合文本和图像信息。\n",
    "                    - {'image_path': '图像路径'} : 纯图像查询，仅使用图像内容进行检索。\n",
    "                    - {'text': '文本内容'} : 纯文本查询 (与直接传入字符串的效果相同，但通过字典形式提供)。\n",
    "                    字典中必须至少包含 'text' 或 'image_path' 键及其对应值，且值不能为空字符串。\n",
    "            k (int): 指定希望检索的最相似文档的数量 (Top-K)。默认为 5。\n",
    "\n",
    "        Returns:\n",
    "            List[Dict[str, Any]]: 一个按相似度得分降序排列的文档列表。\n",
    "                        列表中的每个字典代表一个检索到的文档，包含以下键（但不限于）：\n",
    "                        - 'id': 原始文档 ID (str)。\n",
    "                        - 'text': 文档的文本内容 (str 或 None)。\n",
    "                        - 'image_path': 关联图像的路径 (str 或 None)。\n",
    "                        - 'internal_id': 数据库和 Faiss 使用的内部 ID (int)。\n",
    "                        - 'score': 该文档与查询的相似度得分 (float)。对于内积搜索，得分越高表示越相似。\n",
    "                        如果查询无效、编码失败、所选索引为空或搜索无结果，则返回空列表 `[]`。\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"开始执行检索流程，目标是获取 Top-{k} 最相关的文档...\")\n",
    "        self.logger.debug(f\"  接收到的原始查询: {str(query)[:200]}{'...' if len(str(query))>200 else ''}, k={k}\")\n",
    "\n",
    "        query_text: Optional[str] = None        \n",
    "        query_image_path: Optional[str] = None  \n",
    "        query_type: str = \"unknown\"             \n",
    "\n",
    "        # --- 步骤 1: 解析查询输入，确定查询类型和具体内容 ---\n",
    "        self.logger.debug(\"  - Retriever步骤 1: 解析用户查询输入...\")\n",
    "        if isinstance(query, str): \n",
    "            query_text_stripped = query.strip()\n",
    "            if query_text_stripped:\n",
    "                query_text = query_text_stripped\n",
    "                query_type = \"纯文本\"\n",
    "                self.logger.info(f\"    查询类型确定为: {query_type} (字符串输入)\")\n",
    "                self.logger.info(f\"    查询文本内容: '{query_text[:100]}{'...' if len(query_text)>100 else ''}'\")\n",
    "            else:\n",
    "                self.logger.error(\"查询错误: 纯文本查询字符串为空或只包含空白。\")\n",
    "                return []\n",
    "        elif isinstance(query, dict): \n",
    "            query_text_from_dict = query.get('text')\n",
    "            query_image_path_from_dict = query.get('image_path')\n",
    "\n",
    "            query_text = query_text_from_dict.strip() if isinstance(query_text_from_dict, str) and query_text_from_dict.strip() else None\n",
    "            query_image_path = query_image_path_from_dict.strip() if isinstance(query_image_path_from_dict, str) and query_image_path_from_dict.strip() else None\n",
    "            \n",
    "            if query_text and query_image_path: \n",
    "                query_type = \"多模态\"\n",
    "                self.logger.info(f\"    查询类型确定为: {query_type}\")\n",
    "                self.logger.info(f\"    查询文本部分: '{query_text[:50]}{'...' if len(query_text)>50 else ''}'\")\n",
    "                self.logger.info(f\"    查询图像部分: '{os.path.basename(query_image_path)}'\")\n",
    "            elif query_image_path: \n",
    "                query_type = \"纯图像\"\n",
    "                self.logger.info(f\"    查询类型确定为: {query_type}\")\n",
    "                self.logger.info(f\"    查询图像路径: '{os.path.basename(query_image_path)}'\")\n",
    "            elif query_text: \n",
    "                query_type = \"纯文本\"\n",
    "                self.logger.info(f\"    查询类型确定为: {query_type} (字典输入)\")\n",
    "                self.logger.info(f\"    查询文本内容: '{query_text[:100]}{'...' if len(query_text)>100 else ''}'\")\n",
    "            else: \n",
    "                self.logger.error(\"查询错误: 查询字典无效，必须至少包含有效的 'text' 或 'image_path' 键及其对应值。\")\n",
    "                return [] \n",
    "        else: \n",
    "            self.logger.error(f\"查询错误: 不支持的查询类型 ({type(query)}) 或查询内容为空。查询必须是有效的非空字符串或包含有效内容的字典。\")\n",
    "            return [] \n",
    "\n",
    "        # --- 步骤 2: 使用内部的 MultimodalEncoder 对查询进行编码 ---\n",
    "        self.logger.debug(f\"  - Retriever步骤 2: 使用 MultimodalEncoder 对 '{query_type}' 查询进行编码...\")\n",
    "        try:\n",
    "            encoded_query_vectors = self.encoder.encode(text=query_text, image_path=query_image_path)\n",
    "            query_text_vec = encoded_query_vectors.get('text_vector')\n",
    "            query_image_vec = encoded_query_vectors.get('image_vector')\n",
    "            query_mean_vec = encoded_query_vectors.get('mean_vector')\n",
    "            \n",
    "            if query_text_vec is None and query_image_vec is None and query_mean_vec is None:\n",
    "                 self.logger.warning(\"查询编码警告: MultimodalEncoder 未能为当前查询生成任何有效的特征向量。无法继续检索。\")\n",
    "                 return [] \n",
    "            self.logger.info(\"    查询编码完成。\")\n",
    "            if query_text_vec is not None: self.logger.debug(\"      - 生成了文本查询向量。\")\n",
    "            if query_image_vec is not None: self.logger.debug(\"      - 生成了图像查询向量。\")\n",
    "            if query_mean_vec is not None: self.logger.debug(\"      - 生成了平均查询向量。\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"查询编码严重错误: 在对查询进行编码时发生意外错误: {e}\", exc_info=True)\n",
    "            return [] \n",
    "\n",
    "        # --- 步骤 3: 根据查询类型选择目标 Faiss 索引和相应的查询向量 ---\n",
    "        self.logger.debug(f\"  - Retriever步骤 3: 根据查询类型 '{query_type}' 选择搜索策略 (Faiss索引和查询向量)...\")\n",
    "        target_faiss_index: Optional[faiss.Index] = None   \n",
    "        search_query_vector: Optional[np.ndarray] = None   \n",
    "        selected_index_name: str = \"N/A\"                   \n",
    "\n",
    "        text_index_ntotal = getattr(self.text_index, 'ntotal', 0)\n",
    "        image_index_ntotal = getattr(self.image_index, 'ntotal', 0)\n",
    "        mean_index_ntotal = getattr(self.mean_index, 'ntotal', 0)\n",
    "\n",
    "        if query_type == \"纯文本\":\n",
    "            if query_text_vec is not None and text_index_ntotal > 0:\n",
    "                target_faiss_index = self.text_index\n",
    "                search_query_vector = query_text_vec\n",
    "                selected_index_name = \"文本(Text)索引\"\n",
    "                self.logger.info(f\"    搜索策略: 使用文本查询向量，在 {selected_index_name} (含 {text_index_ntotal} 个向量) 中搜索。\")\n",
    "            else:\n",
    "                 reason = \"文本查询向量编码失败\" if query_text_vec is None else f\"文本(Text) Faiss 索引为空 (仅含 {text_index_ntotal} 个向量)\"\n",
    "                 self.logger.warning(f\"无法执行纯文本查询，因为: {reason}。\")\n",
    "                 return []\n",
    "        elif query_type == \"纯图像\":\n",
    "            if query_image_vec is not None and image_index_ntotal > 0:\n",
    "                target_faiss_index = self.image_index\n",
    "                search_query_vector = query_image_vec\n",
    "                selected_index_name = \"图像(Image)索引\"\n",
    "                self.logger.info(f\"    搜索策略: 使用图像查询向量，在 {selected_index_name} (含 {image_index_ntotal} 个向量) 中搜索。\")\n",
    "            else:\n",
    "                reason = \"图像查询向量编码失败\" if query_image_vec is None else f\"图像(Image) Faiss 索引为空 (仅含 {image_index_ntotal} 个向量)\"\n",
    "                self.logger.warning(f\"无法执行纯图像查询，因为: {reason}。\")\n",
    "                return []\n",
    "        elif query_type == \"多模态\":\n",
    "            if query_mean_vec is not None and mean_index_ntotal > 0:\n",
    "                target_faiss_index = self.mean_index\n",
    "                search_query_vector = query_mean_vec\n",
    "                selected_index_name = \"平均(Mean)索引\"\n",
    "                self.logger.info(f\"    搜索策略: 使用平均查询向量，在 {selected_index_name} (含 {mean_index_ntotal} 个向量) 中搜索。\")\n",
    "            elif query_text_vec is not None and text_index_ntotal > 0:\n",
    "                 self.logger.warning(\"多模态查询警告: 平均(Mean)索引或平均查询向量不可用/索引为空。\")\n",
    "                 self.logger.info(f\"    应用回退策略: 改为使用文本查询向量，在文本(Text)索引 (含 {text_index_ntotal} 个向量) 中搜索。\")\n",
    "                 target_faiss_index = self.text_index\n",
    "                 search_query_vector = query_text_vec\n",
    "                 selected_index_name = \"文本(Text)索引 (作为多模态查询的回退)\"\n",
    "            else:\n",
    "                reason_parts = []\n",
    "                if query_mean_vec is None and query_text_vec is None: reason_parts.append(\"平均查询向量和文本查询向量都编码失败\")\n",
    "                if mean_index_ntotal == 0 and text_index_ntotal == 0: reason_parts.append(f\"平均(Mean)索引(含{mean_index_ntotal}向量)和文本(Text)索引(含{text_index_ntotal}向量)都为空\")\n",
    "                if not reason_parts: reason_parts.append(\"由于平均(Mean)索引和文本(Text)索引（用于回退）都不可用，或对应的查询向量缺失\")\n",
    "                final_reason = \"; \".join(reason_parts)\n",
    "                self.logger.warning(f\"无法执行多模态查询，因为: {final_reason}。\")\n",
    "                return []\n",
    "        else: \n",
    "             self.logger.error(\"内部逻辑错误: 无法为当前查询确定有效的查询类型或找不到可用的查询向量/索引组合。\")\n",
    "             return []\n",
    "        \n",
    "        if target_faiss_index is None or search_query_vector is None:\n",
    "            self.logger.error(\"内部错误: 搜索目标 Faiss 索引或查询向量未能正确设置，尽管已尝试选择策略。无法继续搜索。\")\n",
    "            return []\n",
    "\n",
    "\n",
    "        # --- 步骤 4: 在选定的 Faiss 索引中执行 Top-K 相似度搜索 ---\n",
    "        self.logger.debug(f\"  - Retriever步骤 4: 在选定的 '{selected_index_name}' 中执行 Faiss Top-{k} 搜索...\")\n",
    "        try:\n",
    "            query_vector_for_faiss = search_query_vector.reshape(1, self.vector_dimension)\n",
    "\n",
    "            self.logger.debug(f\"    Faiss search: k={k}, query_vector_shape={query_vector_for_faiss.shape}\")\n",
    "            scores_matrix, internal_ids_matrix = target_faiss_index.search(query_vector_for_faiss, k)\n",
    "            self.logger.debug(f\"    Faiss search returned scores_matrix shape: {scores_matrix.shape}, ids_matrix shape: {internal_ids_matrix.shape}\")\n",
    "\n",
    "            retrieved_internal_ids: List[int] = []\n",
    "            retrieved_scores: List[float] = []\n",
    "            \n",
    "            for id_val, score_val in zip(internal_ids_matrix[0], scores_matrix[0]):\n",
    "                if id_val != -1: \n",
    "                    retrieved_internal_ids.append(int(id_val))   \n",
    "                    retrieved_scores.append(float(score_val)) \n",
    "                else:\n",
    "                    self.logger.debug(f\"    Faiss search: Encountered -1 ID, indicating fewer than k={k} results or padding.\")\n",
    "            \n",
    "            if not retrieved_internal_ids:\n",
    "                self.logger.info(f\"    Faiss 搜索在 '{selected_index_name}' 中完成，但未返回任何有效的结果 ID。\")\n",
    "                return [] \n",
    "            \n",
    "            self.logger.info(f\"    Faiss 搜索在 '{selected_index_name}' 中完成，初步找到 {len(retrieved_internal_ids)} 个候选文档的 internal_id。\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Faiss 搜索错误: 在 '{selected_index_name}' 中执行 Faiss 搜索时发生错误: {e}\", exc_info=True)\n",
    "            return [] \n",
    "\n",
    "        # --- 步骤 5: 根据检索到的 internal_ids 从 SQLite 数据库批量获取这些文档的完整元数据 ---\n",
    "        self.logger.debug(f\"  - Retriever步骤 5: 使用找到的 {len(retrieved_internal_ids)} 个 internal_id，从 SQLite 数据库批量获取文档元数据...\")\n",
    "        documents_map_from_db = self.indexer.get_documents_by_internal_ids(retrieved_internal_ids)\n",
    "        self.logger.info(f\"    已成功从数据库中获取了 {len(documents_map_from_db)} 条与 internal_id 对应的文档记录。\")\n",
    "\n",
    "        # --- 步骤 6: 组合结果：将元数据与相似度得分结合，并保持 Faiss 返回的原始排序 ---\n",
    "        self.logger.debug(f\"  - Retriever步骤 6: 组合文档元数据与相似度得分，并按 Faiss 原始顺序排列...\")\n",
    "        final_retrieved_docs: List[Dict[str, Any]] = [] \n",
    "        \n",
    "        for internal_id, score in zip(retrieved_internal_ids, retrieved_scores):\n",
    "            doc_data_from_db = documents_map_from_db.get(internal_id)\n",
    "            \n",
    "            if doc_data_from_db:\n",
    "                doc_data_from_db['score'] = score \n",
    "                final_retrieved_docs.append(doc_data_from_db)\n",
    "            else:\n",
    "                self.logger.warning(f\"数据不一致警告: 在数据库中未能找到 Faiss 返回的 internal_id: {internal_id}。\")\n",
    "                self.logger.warning(f\"                 这可能表示 Faiss 索引与数据库元数据之间存在不一致。将跳过此条检索结果。\")\n",
    "\n",
    "        self.logger.info(f\"检索流程成功完成，最终返回 {len(final_retrieved_docs)} 个文档（已按相似度排序）。\")\n",
    "        return final_retrieved_docs\n",
    "\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        关闭 Retriever 实例时调用的清理方法。\n",
    "        Retriever 本身通常没有需要显式关闭的外部资源 (因为它主要依赖于 Indexer 提供的资源)。\n",
    "        此方法主要用于记录 Retriever 的关闭事件。\n",
    "        \"\"\"\n",
    "        self.logger.info(\"开始关闭 Retriever 实例...\")\n",
    "        # 通常无需执行特定的资源释放操作，因为 Encoder, Faiss索引, DB连接等由 Indexer 管理。\n",
    "        self.logger.info(\"Retriever 实例关闭完成。\")\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# 生成器类 (Generator)\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "class Generator:\n",
    "    \"\"\"\n",
    "    Generator 类负责与大语言模型 (LLM) API (此处特指 ZhipuAI 的 API) 进行交互，\n",
    "    以根据用户查询和检索到的上下文信息生成最终的自然语言答案。\n",
    "\n",
    "    其核心工作流程包括：\n",
    "    1.  **构建提示 (Prompt)**: 将用户的原始查询和由 Retriever 检索到的相关文档上下文列表，\n",
    "        组合成一个结构化的提示 (prompt)。这个提示会指导 LLM 如何根据提供的上下文来回答问题，\n",
    "        并遵循特定的规则（例如，要求 LLM 仅基于提供的上下文作答、如何处理信息不足的情况等）。\n",
    "    2.  **调用 LLM API**: 将构建好的提示发送给指定的 ZhipuAI 大语言模型 API。\n",
    "    3.  **处理响应**: 对 LLM API 返回的原始文本响应进行基本的后处理（例如，去除多余的空白字符）。\n",
    "\n",
    "    此类依赖于 `zhipuai` Python 库来与 ZhipuAI API 进行通信，并且需要一个有效的 API Key。\n",
    "    API Key 的获取优先级如下：\n",
    "    - 首先，从构造函数参数 `api_key` 获取。\n",
    "    - 如果构造函数未提供，则尝试从环境变量 `ZHIPUAI_API_KEY` 读取。\n",
    "    如果没有有效的 API Key，Generator 将无法工作。\n",
    "    \"\"\"\n",
    "    def __init__(self, api_key: Optional[str] = None, model_name: str = \"glm-4-flash\"):\n",
    "        \"\"\"\n",
    "        初始化 Generator 实例。\n",
    "\n",
    "        Args:\n",
    "            api_key (Optional[str]): ZhipuAI 的 API Key。如果在此处提供，将优先使用这个 Key。\n",
    "                                     如果为 None，则会尝试从环境变量 `ZHIPUAI_API_KEY` 中读取。\n",
    "            model_name (str): 指定要调用的 ZhipuAI 平台的模型名称。例如 \"glm-4-flash\", \"glm-4\" 等。\n",
    "                              不同的模型具有不同的能力、速度、上下文窗口大小和调用成本。\n",
    "                              默认值为 \"glm-4-flash\"，这是一个速度较快且性价比较高的模型。\n",
    "                              老板请注意: \"glm-4-flash\" 已经是智谱AI的轻快版模型，平衡了性能与资源。\n",
    "                              若需调整，请参考智谱AI官方文档选择合适的模型。\n",
    "                              请查阅 ZhipuAI 官方文档以获取最新的可用模型列表和特性。\n",
    "\n",
    "        Raises:\n",
    "            ValueError: 如果 `api_key` 参数为 None 并且在环境变量 `ZHIPUAI_API_KEY` 中也找不到有效的 Key。\n",
    "                        没有 API Key，Generator 将无法与 ZhipuAI 服务通信。\n",
    "            RuntimeError: 如果 ZhipuAI 客户端在初始化过程中发生其他错误 (例如，网络问题、`zhipuai`库安装问题等)。\n",
    "        \"\"\"\n",
    "        self.logger = logging.getLogger(__name__ + \".\" + self.__class__.__name__)\n",
    "        self.logger.info(f\"开始初始化 Generator，准备使用 ZhipuAI 模型: {model_name}\")\n",
    "        \n",
    "        # 决定最终使用的 API Key：优先使用通过参数传入的，否则尝试从环境变量获取。\n",
    "        final_api_key = api_key if api_key else os.getenv(\"ZHIPUAI_API_KEY\")\n",
    "\n",
    "        # 检查是否成功获取到 API Key。\n",
    "        if not final_api_key:\n",
    "            error_message = (\"Generator 初始化错误: ZhipuAI API Key 未提供。\\n\"\n",
    "                             \"请通过以下方式之一提供 API Key：\\n\"\n",
    "                             \"  1. 在初始化 Generator 时，通过 'api_key' 参数传入。\\n\"\n",
    "                             \"  2. 将 API Key 设置到名为 'ZHIPUAI_API_KEY' 的环境变量中。\")\n",
    "            self.logger.critical(error_message) \n",
    "            raise ValueError(error_message)\n",
    "        else:\n",
    "            self.logger.info(\"成功获取到 ZhipuAI API Key (来源可能是参数或环境变量)。\")\n",
    "\n",
    "        try:\n",
    "            self.client = zhipuai.ZhipuAI(api_key=final_api_key)\n",
    "            self.model_name = model_name\n",
    "            self.logger.info(f\"ZhipuAI 客户端已使用模型 '{self.model_name}' 成功初始化。\")\n",
    "        except Exception as e:\n",
    "             self.logger.error(f\"Generator 初始化错误: 初始化 ZhipuAI 客户端失败。错误详情: {e}\", exc_info=True)\n",
    "             self.logger.error(f\"请确认以下几点：\")\n",
    "             self.logger.error(f\"  - 提供的 API Key 是否有效且具有调用模型 '{self.model_name}' 的权限。\")\n",
    "             self.logger.error(f\"  - 'zhipuai' Python 库是否已正确安装 (例如，通过 pip install zhipuai)。\")\n",
    "             self.logger.error(f\"  - 网络连接是否正常，能否访问 ZhipuAI API 服务端点。\")\n",
    "             raise RuntimeError(f\"ZhipuAI客户端初始化失败: {e}\") from e \n",
    "        \n",
    "        self.logger.info(\"Generator 初始化成功完成。\")\n",
    "\n",
    "    def generate(self, query: str, context: List[Dict[str, Any]]) -> str:\n",
    "        \"\"\"\n",
    "        根据用户提供的原始查询和由 Retriever 返回的文档上下文列表，调用大语言模型 (LLM) 生成回答。\n",
    "\n",
    "        Args:\n",
    "            query (str): 用户提出的原始问题或查询字符串。\n",
    "            context (List[Dict[str, Any]]): 一个文档字典列表，通常由 Retriever 的 `retrieve` 方法返回。\n",
    "                                 每个字典代表一个检索到的相关文档，应包含诸如 'id', 'text', \n",
    "                                 'image_path', 'score' 等信息。\n",
    "\n",
    "        Returns:\n",
    "            str: 由大语言模型生成并经过基本后处理的文本响应。\n",
    "                 如果在调用 LLM API 时发生错误，会返回一条包含错误信息的提示性字符串。\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"开始为查询生成最终响应...\")\n",
    "        self.logger.info(f\"  接收到的用户查询: '{query[:100]}{'...' if len(query)>100 else ''}'\")\n",
    "        self.logger.info(f\"  使用 {len(context)} 个检索到的文档作为生成上下文。\")\n",
    "\n",
    "        # --- 步骤 1: 构建发送给 LLM 的 Prompt (通常表现为消息列表 `messages`) ---\n",
    "        self.logger.debug(\"  - Generator步骤 1: 构建 Prompt (包含系统指令、上下文和用户查询)...\")\n",
    "        messages_for_llm = self._build_messages(query, context)\n",
    "\n",
    "        if messages_for_llm:\n",
    "            if messages_for_llm[0]['role'] == 'system':\n",
    "                 system_prompt_content = messages_for_llm[0]['content']\n",
    "                 context_start_marker = \"# 参考文档:\"\n",
    "                 context_start_index = system_prompt_content.find(context_start_marker)\n",
    "                 if context_start_index != -1:\n",
    "                     system_instructions_part = system_prompt_content[:context_start_index].strip()\n",
    "                     self.logger.debug(f\"    生成的系统消息 (指令部分): {system_instructions_part[:400]}{'...' if len(system_instructions_part)>400 else ''}\")\n",
    "                 else: \n",
    "                     self.logger.debug(f\"    生成的系统消息 (部分): {system_prompt_content[:400]}{'...' if len(system_prompt_content)>400 else ''}\")\n",
    "\n",
    "            if len(messages_for_llm) > 1 and messages_for_llm[1]['role'] == 'user':\n",
    "                 self.logger.debug(f\"    生成的用户消息 (原始查询): {messages_for_llm[1]['content']}\")\n",
    "        self.logger.debug(\"    Prompt 构建完成。\")\n",
    "\n",
    "        # --- 步骤 2: 调用 ZhipuAI Chat Completions API ---\n",
    "        self.logger.info(f\"  - Generator步骤 2: 开始调用 ZhipuAI Chat API (使用模型: {self.model_name})...\")\n",
    "        llm_raw_response_content = \"抱歉，在尝试从语言模型生成响应时遇到了一个未知问题。\" \n",
    "        try:\n",
    "            api_response = self.client.chat.completions.create(\n",
    "                model=self.model_name,      \n",
    "                messages=messages_for_llm,   \n",
    "                temperature=0.7,            \n",
    "                max_tokens=1500,            \n",
    "            )\n",
    "            \n",
    "            if api_response.choices and api_response.choices[0].message and api_response.choices[0].message.content:\n",
    "                llm_raw_response_content = api_response.choices[0].message.content\n",
    "                self.logger.info(f\"    ZhipuAI API 调用成功。已接收到模型的响应。\")\n",
    "            else:\n",
    "                self.logger.warning(\"    ZhipuAI API 调用似乎成功，但响应结构不符合预期 (choices, message, or content为空)。将使用默认错误消息。\")\n",
    "                # Log the actual response for debugging if it's not as expected\n",
    "                self.logger.debug(f\"    Actual API response object: {api_response.model_dump_json(indent=2)}\")\n",
    "\n",
    "\n",
    "            if hasattr(api_response, 'usage') and api_response.usage:\n",
    "                completion_tokens = api_response.usage.completion_tokens \n",
    "                prompt_tokens = api_response.usage.prompt_tokens         \n",
    "                total_tokens = api_response.usage.total_tokens           \n",
    "                self.logger.info(f\"      Token 使用情况 -> 输入提示: {prompt_tokens} tokens, 生成响应: {completion_tokens} tokens, 总计: {total_tokens} tokens.\")\n",
    "            else:\n",
    "                self.logger.info(\"      未能从 API 响应中获取详细的 token 使用情况。\")\n",
    "\n",
    "\n",
    "        except zhipuai.APIStatusError as e_status:\n",
    "             self.logger.error(f\"  错误：ZhipuAI API 返回了状态错误。\")\n",
    "             self.logger.error(f\"        HTTP 状态码: {e_status.status_code}\")\n",
    "             # Accessing type and message safely\n",
    "             error_type = getattr(e_status, 'type', 'N/A')\n",
    "             error_message_detail = getattr(e_status, 'message', str(e_status))\n",
    "             self.logger.error(f\"        错误类型: {error_type}\")\n",
    "             self.logger.error(f\"        错误消息: {error_message_detail}\")\n",
    "             llm_raw_response_content = (f\"抱歉，调用语言模型时遇到 API 错误 (状态码: {e_status.status_code})。 \"\n",
    "                                         f\"请检查您的 API Key、账户状态或请求参数，或稍后重试。错误信息: {error_message_detail}\")\n",
    "        except zhipuai.APIConnectionError as e_conn:\n",
    "             self.logger.error(f\"  错误：无法连接到 ZhipuAI API 服务器: {e_conn}\")\n",
    "             llm_raw_response_content = (\"抱歉，无法连接到语言模型服务。 \"\n",
    "                                         \"请检查您的网络连接，或确认 ZhipuAI API 端点是否正确且可访问。\")\n",
    "        except zhipuai.APIRequestFailedError as e_req_failed:\n",
    "            self.logger.error(f\"  错误: ZhipuAI API 请求失败: {e_req_failed}\")\n",
    "            error_message_detail = getattr(e_req_failed, 'message', str(e_req_failed))\n",
    "            llm_raw_response_content = f\"抱歉，语言模型API请求失败。可能原因包括请求参数无效或服务内部错误。详情: {error_message_detail}\"\n",
    "        except zhipuai.APITimeoutError as e_timeout:\n",
    "            self.logger.error(f\"  错误: ZhipuAI API 请求超时: {e_timeout}\")\n",
    "            llm_raw_response_content = \"抱歉，与语言模型的通信超时。请稍后重试，或检查网络延迟。\"\n",
    "        except Exception as e_unknown:\n",
    "             self.logger.error(f\"  错误：调用 LLM 时发生未预料的异常: {e_unknown}\", exc_info=True) \n",
    "             llm_raw_response_content = (\"抱歉，在与语言模型交互并生成响应的过程中，发生了一个意外的内部错误。 \"\n",
    "                                         \"请查看详细日志以获取更多信息。\")\n",
    "\n",
    "        # --- 步骤 3: 对 LLM 的原始响应进行后处理 ---\n",
    "        self.logger.debug(\"  - Generator步骤 3: 对 LLM 的原始响应进行后处理...\")\n",
    "        final_processed_response = self._postprocess_response(llm_raw_response_content)\n",
    "        self.logger.debug(\"    LLM 响应后处理完成。\")\n",
    "        \n",
    "        self.logger.info(\"LLM 响应生成流程结束。\")\n",
    "        return final_processed_response\n",
    "\n",
    "    def _build_messages(self, query: str, context: List[Dict[str, Any]]) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        根据用户查询和检索到的上下文文档，构建符合 ZhipuAI Chat API 要求的消息列表 (messages)。\n",
    "        这个列表通常包含两条主要消息：\n",
    "        1.  **System Message (`role: \"system\"`)**: 提供系统级的指令，设定 LLM 的角色、行为规则，\n",
    "            并在此处注入检索到的上下文信息（格式化为文本）。\n",
    "        2.  **User Message (`role: \"user\"`)**: 包含用户原始的查询字符串。\n",
    "\n",
    "        Args:\n",
    "            query (str): 用户的原始查询。\n",
    "            context (List[Dict[str, Any]]): Retriever 返回的上下文文档列表。每个文档字典应包含 'id', 'text', 'score' 等键。\n",
    "\n",
    "        Returns:\n",
    "            List[Dict[str, str]]: 一个包含字典的列表，每个字典有 'role' 和 'content' 键，\n",
    "                                  可以直接传递给 ZhipuAI Chat API 的 `messages` 参数。\n",
    "        \"\"\"\n",
    "        self.logger.debug(\"开始构建用于 LLM 的消息列表...\")\n",
    "        system_message_content = \"\"\"\n",
    "        你是一个高度专业且严谨的文档问答助手。你的任务是根据下面提供的 \"参考文档\" 部分中的信息来精确地回答用户提出的问题。\n",
    "\n",
    "        # 核心指令与行为准则:\n",
    "        1.  **严格依据参考信息**: 你的回答必须 **完全且仅** 基于 \"参考文档\" 中明确提供的信息。严禁使用任何你在训练数据中学习到的外部知识、个人观点、进行任何形式的推断、猜测或联想超出文档内容。\n",
    "        2.  **处理信息不足**: 如果 \"参考文档\" 中的信息不足以回答用户的问题，或者问题与所有提供的文档内容均不相关，你必须明确指出信息的缺乏。标准回答是：“根据提供的参考文档，我无法找到回答该问题所需的信息。”或者类似表述，如“参考文档中没有包含足够的信息来回答关于...的问题。”。不要试图编造答案。\n",
    "        3.  **关于图像内容的理解**: 你无法直接“看到”或解析图像。你对图像的理解 **必须且只能** 来源于 \"参考文档\" 中与该图像关联的 **文本描述内容**，以及文档中可能提及的 **图像文件名**。绝不能声称你能直接感知图像内容。\n",
    "        4.  **回答涉及图像的问题**:\n",
    "            - 如果用户的问题涉及到某张图片（例如，通过图片文件名或描述性提问），请首先在 \"参考文档\" 的文本描述中仔细查找是否有与该图片相关的说明。\n",
    "            - 如果找到了相关的文本描述，请依据该文本描述来回答。\n",
    "            - 如果文档中只提供了图片的文件名但没有相应的文本描述，你可以提及这个文件名（例如，“文档提到了一个名为 'circuit_diagram.png' 的关联图片”），并明确说明文档中缺少对该图片内容的具体文字描述，因此无法进一步回答。\n",
    "            - 如果文档中既没有图片描述也没有文件名信息，或者问题与文档中提及的任何图片都无关，请按照上述第2条“处理信息不足”的规则进行回复。\n",
    "        5.  **引用来源 (推荐)**: 在可能的情况下，如果你的答案基于某一个或某几个特定的参考文档，请在回答中指明这些来源。例如：“根据文档 ID 'BGREF_01' 的描述...” 或 “参考文档 1 (ID: XXX) 和文档 3 (ID: YYY) 提到...”。这有助于用户追溯信息源。\n",
    "        6.  **回答风格与格式**: 你的回答应尽可能地简洁、清晰、直接，并且专业。避免使用冗长的前缀、不必要的客套话或模棱两可的表述。如果答案包含多个要点，可以使用列表或分点来组织，以提高可读性。\n",
    "\n",
    "        # 参考文档:\n",
    "        --- 开始参考文档部分 ---\n",
    "        \"\"\".strip() \n",
    "\n",
    "        context_parts_for_prompt: List[str] = [] \n",
    "        if not context:\n",
    "            self.logger.info(\"    注意: 未向LLM提供任何检索到的上下文文档 (可能是因为检索无结果)。\")\n",
    "            context_parts_for_prompt.append(\"\\n（系统提示：本次未能从知识库中检索到与用户问题相关的文档。请基于此情况进行回答，并遵循“处理信息不足”的规则。）\")\n",
    "        else:\n",
    "            self.logger.info(f\"    正在将 {len(context)} 个检索到的文档格式化为 LLM 的上下文...\")\n",
    "            for i, doc_info in enumerate(context):\n",
    "                doc_id = doc_info.get('id', '未知ID')\n",
    "                score_value = doc_info.get('score', 'N/A') \n",
    "                text_content = doc_info.get('text', '无可用文本内容')\n",
    "                image_file_path = doc_info.get('image_path') \n",
    "\n",
    "                image_info_str = f\"关联图片文件名: '{os.path.basename(image_file_path)}'\" if image_file_path else \"无明确关联的图片信息\"\n",
    "\n",
    "                max_text_len_for_llm = 700 \n",
    "                truncated_text_content = text_content[:max_text_len_for_llm] + \\\n",
    "                                         ('...' if len(text_content) > max_text_len_for_llm else '')\n",
    "\n",
    "                context_parts_for_prompt.append(f\"\\n--- 参考文档 {i+1} ---\") \n",
    "                context_parts_for_prompt.append(f\"  原始文档ID: {doc_id}\")\n",
    "                context_parts_for_prompt.append(f\"  与查询的相关度得分: {score_value:.4f}\" if isinstance(score_value, float) else f\"  与查询的相关度得分: {score_value}\")\n",
    "                context_parts_for_prompt.append(f\"  文本内容摘要: {truncated_text_content}\")\n",
    "                context_parts_for_prompt.append(f\"  {image_info_str}\")\n",
    "\n",
    "        formatted_context_section = \"\\n\".join(context_parts_for_prompt)\n",
    "        system_message_content += \"\\n\" + formatted_context_section + \"\\n--- 结束参考文档部分 ---\"\n",
    "\n",
    "        final_messages: List[Dict[str, str]] = [\n",
    "            {\"role\": \"system\", \"content\": system_message_content}, \n",
    "            {\"role\": \"user\", \"content\": query}                     \n",
    "        ]\n",
    "        self.logger.debug(f\"为 LLM 构建的消息列表完成。共 {len(final_messages)} 条消息。\")\n",
    "        return final_messages\n",
    "\n",
    "    def _postprocess_response(self, llm_raw_response: str) -> str:\n",
    "        \"\"\"\n",
    "        对从 LLM API 获取的原始响应字符串进行基本的后处理。\n",
    "        目前主要执行去除首尾空白字符的操作。\n",
    "        未来可以根据需要在这里添加更复杂的处理逻辑。\n",
    "\n",
    "        Args:\n",
    "            llm_raw_response (str): 从 LLM API 收到的原始文本响应。\n",
    "\n",
    "        Returns:\n",
    "            str: 经过后处理的文本响应，准备好呈现给用户或用于后续流程。\n",
    "        \"\"\"\n",
    "        self.logger.debug(f\"开始对 LLM 原始响应进行后处理。原始响应 (前100字符): '{llm_raw_response[:100]}...'\")\n",
    "        processed_response = llm_raw_response.strip()\n",
    "        \n",
    "        # 示例：移除特定前缀 (如果模型经常添加)\n",
    "        # unwanted_prefix = \"根据您提供的参考文档，\"\n",
    "        # if processed_response.startswith(unwanted_prefix):\n",
    "        #     processed_response = processed_response[len(unwanted_prefix):].strip()\n",
    "        #     self.logger.debug(f\"  移除了不希望的前缀 '{unwanted_prefix}'。\")\n",
    "\n",
    "        self.logger.debug(f\"LLM 响应后处理完成。处理后响应 (前100字符): '{processed_response[:100]}...'\")\n",
    "        return processed_response\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        关闭 Generator 实例时调用的清理方法。\n",
    "        ZhipuAI 客户端通常不需要显式关闭。\n",
    "        \"\"\"\n",
    "        self.logger.info(\"开始关闭 Generator 实例...\")\n",
    "        self.logger.info(\"Generator 实例关闭完成。\")\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# 主程序执行入口 (示例使用流程)\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # =============================================================================================\n",
    "    # 步骤 0: 配置运行参数和输出目录 (老板，请在这里按需修改！)\n",
    "    # =============================================================================================\n",
    "    \n",
    "    # --- 用户可配置的运行标识符 ---\n",
    "    # 请为本次运行设置一个有意义的描述性名称，例如项目名、实验批次等。\n",
    "    # 这将作为顶级输出目录名称的一部分，方便区分和查找不同运行的产出。\n",
    "    RUN_IDENTIFIER_BASE: str = \"Multimodal_RAG_System_Run\" # 使用英文以保证跨平台兼容性\n",
    "    \n",
    "    # 清理运行标识符，确保它能作为有效目录名。\n",
    "    sanitized_run_identifier: str = sanitize_filename(RUN_IDENTIFIER_BASE, max_length=50) \n",
    "\n",
    "    # --- 构建本次运行的顶级输出目录 ---\n",
    "    # 目录名格式: [清理后的运行标识符]_[时间戳YYYYMMDD_HHMMSS]\n",
    "    run_timestamp: str = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    OUTPUT_BASE_DIR: str = f\"{sanitized_run_identifier}_{run_timestamp}\"\n",
    "    \n",
    "    os.makedirs(OUTPUT_BASE_DIR, exist_ok=True)\n",
    "\n",
    "    # --- 配置日志记录 ---\n",
    "    LOG_DIR: str = os.path.join(OUTPUT_BASE_DIR, \"run_logs\")\n",
    "    os.makedirs(LOG_DIR, exist_ok=True)\n",
    "    LOG_FILE_PATH: str = os.path.join(LOG_DIR, \"system_execution_log.txt\")\n",
    "    setup_logging(LOG_FILE_PATH) \n",
    "\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"========= Multimodal Retrieval Augmented Generation (RAG) System =========\")\n",
    "    logger.info(\"=========                     Main Program Execution Start               =========\")\n",
    "    logger.info(\"=\"*80 + \"\\n\")\n",
    "    logger.info(f\"User Defined Run Identifier (Base): {RUN_IDENTIFIER_BASE}\")\n",
    "    logger.info(f\"Sanitized Run Identifier: {sanitized_run_identifier}\")\n",
    "    logger.info(f\"All output data will be saved in the directory: {os.path.abspath(OUTPUT_BASE_DIR)}\")\n",
    "\n",
    "    # --- 数据源配置文件路径 ---\n",
    "    JSON_DATA_PATH: str = 'data.json'\n",
    "    IMAGE_DIR_PATH: str = 'images'\n",
    "    logger.info(f\"Data Source Config: JSON Metadata File='{JSON_DATA_PATH}', Image Directory='{IMAGE_DIR_PATH}'\")\n",
    "\n",
    "    # --- 持久化存储文件路径定义 ---\n",
    "    DB_STORAGE_DIR: str = os.path.join(OUTPUT_BASE_DIR, \"data_storage\")\n",
    "    DB_DIR: str = os.path.join(DB_STORAGE_DIR, \"database\")\n",
    "    DB_FILE: str = os.path.join(DB_DIR, 'multimodal_document_library.db')\n",
    "\n",
    "    FAISS_DIR: str = os.path.join(DB_STORAGE_DIR, \"vector_indices\")\n",
    "    FAISS_TEXT_INDEX_FILE: str = os.path.join(FAISS_DIR, 'text_vector_index.faiss')\n",
    "    FAISS_IMAGE_INDEX_FILE: str = os.path.join(FAISS_DIR, 'image_vector_index.faiss')\n",
    "    FAISS_MEAN_INDEX_FILE: str = os.path.join(FAISS_DIR, 'mean_vector_index.faiss')\n",
    "    \n",
    "    QUERY_RESULTS_DIR: str = os.path.join(OUTPUT_BASE_DIR, \"query_session_results\")\n",
    "    os.makedirs(QUERY_RESULTS_DIR, exist_ok=True) \n",
    "\n",
    "    logger.info(f\"Database file will be saved to: {DB_FILE}\")\n",
    "    logger.info(f\"Faiss index files will be saved to directory: {FAISS_DIR}\")\n",
    "    logger.info(f\"Query session results will be saved to directory: {QUERY_RESULTS_DIR}\")\n",
    "\n",
    "\n",
    "    # --- 模型配置 ---\n",
    "    # 老板请注意：以下模型是经过审慎选择的，旨在平衡性能与资源消耗。\n",
    "    # CLIP 模型: \"openai/clip-vit-base-patch32\" 是一个广泛应用的基准模型。\n",
    "    # LLM 模型: \"glm-4-flash\" 是智谱AI提供的轻快版模型，适合快速响应和资源有限的场景。\n",
    "    CLIP_MODEL: str = \"openai/clip-vit-base-patch32\"\n",
    "    LLM_MODEL: str = \"glm-4-flash\" \n",
    "    logger.info(f\"Model Configuration: CLIP Model='{CLIP_MODEL}', Large Language Model (LLM)='{LLM_MODEL}'\")\n",
    "\n",
    "    # =============================================================================================\n",
    "    # 步骤 1: 加载原始数据并尝试关联图片\n",
    "    # =============================================================================================\n",
    "    logger.info(\"\\n--- [Main Flow] Step 1: Loading document data from JSON and associating image files ---\")\n",
    "    documents_to_index: List[Dict[str, Any]] = load_data_from_json_and_associate_images(JSON_DATA_PATH, IMAGE_DIR_PATH)\n",
    "    \n",
    "    if not documents_to_index:\n",
    "        logger.critical(\"CRITICAL ERROR: Failed to load any valid document data from the JSON file, or the list is empty after image association.\")\n",
    "        logger.critical(f\"          Please check if '{JSON_DATA_PATH}' exists, is correctly formatted, and contains valid records.\")\n",
    "        logger.critical(\"          The program will now exit due to this critical data loading failure.\")\n",
    "        exit(1) \n",
    "    logger.info(f\"--- [Main Flow] Step 1 Complete: Successfully loaded and prepared {len(documents_to_index)} documents for indexing. ---\\n\")\n",
    "    time.sleep(0.2) \n",
    "\n",
    "    # =============================================================================================\n",
    "    # 步骤 2: 初始化 Indexer 并对加载的文档建立索引\n",
    "    # =============================================================================================\n",
    "    logger.info(\"--- [Main Flow] Step 2: Initializing Indexer and building indices for loaded documents ---\")\n",
    "    indexer_instance: Optional[Indexer] = None \n",
    "    try:\n",
    "        indexer_instance = Indexer(\n",
    "            db_path=DB_FILE,\n",
    "            faiss_text_index_path=FAISS_TEXT_INDEX_FILE,\n",
    "            faiss_image_index_path=FAISS_IMAGE_INDEX_FILE,\n",
    "            faiss_mean_index_path=FAISS_MEAN_INDEX_FILE,\n",
    "            clip_model_name=CLIP_MODEL\n",
    "        )\n",
    "        indexer_instance.index_documents(documents_to_index)\n",
    "\n",
    "        logger.info(\"Index building/loading complete. Current status:\")\n",
    "        text_count = getattr(indexer_instance.text_index, 'ntotal', 0)   \n",
    "        image_count = getattr(indexer_instance.image_index, 'ntotal', 0) \n",
    "        mean_count = getattr(indexer_instance.mean_index, 'ntotal', 0)  \n",
    "        db_doc_count = indexer_instance.get_document_count()             \n",
    "        logger.info(f\"  - SQLite Database ('{os.path.basename(DB_FILE)}') document records: {db_doc_count}\")\n",
    "        logger.info(f\"  - Text Faiss Index ('{os.path.basename(FAISS_TEXT_INDEX_FILE)}') vectors: {text_count}\")\n",
    "        logger.info(f\"  - Image Faiss Index ('{os.path.basename(FAISS_IMAGE_INDEX_FILE)}') vectors: {image_count}\")\n",
    "        logger.info(f\"  - Mean Faiss Index ('{os.path.basename(FAISS_MEAN_INDEX_FILE)}') vectors: {mean_count}\")\n",
    "\n",
    "        if text_count == 0 and image_count == 0 and mean_count == 0 and db_doc_count > 0:\n",
    "             logger.warning(\"WARNING: Database contains document records, but all Faiss indices are empty!\")\n",
    "             logger.warning(\"      This might indicate that the encoding process failed for all documents or no valid vectors were generated.\")\n",
    "             logger.warning(\"      Subsequent retrieval operations will not be able to return results based on vector similarity. Please review Indexer and Encoder logs carefully.\")\n",
    "        elif db_doc_count == 0: \n",
    "             logger.warning(\"WARNING: Both the database and all Faiss indices are currently empty.\")\n",
    "             logger.warning(\"      This could be due to empty input JSON data or all entries being skipped during loading and processing.\")\n",
    "\n",
    "    except Exception as e:\n",
    "         logger.critical(f\"CRITICAL ERROR: A top-level exception occurred during Indexer initialization or index building: {e}\", exc_info=True)\n",
    "         logger.critical(\"          As the Indexer failed to prepare successfully, subsequent retrieval and generation steps may not function correctly.\")\n",
    "         indexer_instance = None \n",
    "\n",
    "    logger.info(\"--- [Main Flow] Step 2 Complete. ---\\n\")\n",
    "    time.sleep(0.2)\n",
    "\n",
    "    # =============================================================================================\n",
    "    # 步骤 3: 初始化 Retriever (检索器)\n",
    "    # =============================================================================================\n",
    "    logger.info(\"--- [Main Flow] Step 3: Initializing Retriever ---\")\n",
    "    retriever_instance: Optional[Retriever] = None \n",
    "    if indexer_instance and (getattr(indexer_instance.text_index, 'ntotal', 0) > 0 or \n",
    "                             getattr(indexer_instance.image_index, 'ntotal', 0) > 0 or \n",
    "                             getattr(indexer_instance.mean_index, 'ntotal', 0) > 0):\n",
    "        try:\n",
    "            retriever_instance = Retriever(indexer=indexer_instance)\n",
    "        except Exception as e:\n",
    "             logger.error(f\"ERROR: An exception occurred during Retriever initialization: {e}\", exc_info=True)\n",
    "             retriever_instance = None \n",
    "    else:\n",
    "         logger.warning(\"Skipping Retriever initialization.\")\n",
    "         if indexer_instance is None:\n",
    "             logger.warning(\"  Reason: Indexer failed to initialize. Please check logs for Step 2 (Indexer initialization and index building).\")\n",
    "         elif indexer_instance: \n",
    "             logger.warning(\"  Reason: Indexer initialized successfully, but all its Faiss indices are currently empty.\")\n",
    "             logger.warning(\"        This might be due to encoding issues, data problems, or index building logic. Please check detailed logs for Step 2.\")\n",
    "             logger.warning(\"        Without searchable vectors, the Retriever cannot perform effective operations.\")\n",
    "\n",
    "    logger.info(\"--- [Main Flow] Step 3 Complete. ---\\n\")\n",
    "    time.sleep(0.2)\n",
    "\n",
    "    # =============================================================================================\n",
    "    # 步骤 4: 初始化 Generator (生成器)\n",
    "    # =============================================================================================\n",
    "    logger.info(\"--- [Main Flow] Step 4: Initializing Generator (will interact with ZhipuAI API) ---\")\n",
    "    generator_instance: Optional[Generator] = None \n",
    "    zhipuai_api_key_from_env: Optional[str] = os.getenv(\"ZHIPUAI_API_KEY\")\n",
    "    if not zhipuai_api_key_from_env:\n",
    "        logger.warning(\"WARNING: 'ZHIPUAI_API_KEY' not found in environment variables.\")\n",
    "        logger.warning(\"      The Generator will not be able to communicate with the ZhipuAI API, and the answer generation step will be skipped.\")\n",
    "        logger.warning(\"      To enable LLM answer generation, please do one of the following:\")\n",
    "        logger.warning(\"        1. (Recommended) Set your ZhipuAI API Key as an environment variable named 'ZHIPUAI_API_KEY'.\")\n",
    "        logger.warning(\"           Example (Linux/macOS): export ZHIPUAI_API_KEY='your_valid_api_key'\")\n",
    "        logger.warning(\"           Then, re-run this script in the same terminal session.\")\n",
    "        logger.warning(\"        2. (Alternative) Pass the API Key directly via the `api_key` parameter when initializing the Generator in the code (less secure for this example).\")\n",
    "    else:\n",
    "        logger.info(\"ZHIPUAI_API_KEY detected in environment variables. Attempting to initialize Generator...\")\n",
    "        try:\n",
    "            generator_instance = Generator(api_key=zhipuai_api_key_from_env, model_name=LLM_MODEL)\n",
    "        except Exception as e:\n",
    "             logger.error(f\"ERROR: An exception occurred during Generator initialization: {e}\", exc_info=True)\n",
    "             generator_instance = None \n",
    "\n",
    "    logger.info(\"--- [Main Flow] Step 4 Complete. ---\\n\")\n",
    "    time.sleep(0.2)\n",
    "\n",
    "    # =============================================================================================\n",
    "    # 步骤 5: 执行 RAG 查询示例 (包括检索 和 生成 两个阶段)\n",
    "    # =============================================================================================\n",
    "    logger.info(\"--- [Main Flow] Step 5: Executing RAG Query Examples (Retrieval + Generation) ---\")\n",
    "\n",
    "    if retriever_instance and generator_instance:\n",
    "        logger.info(\"Retriever and Generator have been successfully initialized. Proceeding with example queries...\")\n",
    "\n",
    "        def log_retrieved_docs_summary_for_main_process(docs_list: List[Dict[str, Any]], query_log_prefix: str = \"    \"):\n",
    "            if not docs_list:\n",
    "                logger.info(f\"{query_log_prefix}>> Retrieval Result: No relevant documents found for the query.\")\n",
    "                return\n",
    "            logger.info(f\"{query_log_prefix}>> Retrieval Result: Found Top-{len(docs_list)} relevant documents. Summary:\")\n",
    "            for i, doc_item_data in enumerate(docs_list): \n",
    "                score = doc_item_data.get('score', 'N/A') \n",
    "                score_str = f\"{score:.4f}\" if isinstance(score, float) else str(score)\n",
    "                text_preview = doc_item_data.get('text', 'No text content')[:70] \n",
    "                if len(doc_item_data.get('text', '')) > 70: text_preview += \"...\" \n",
    "                img_filename_info = \"\"\n",
    "                if doc_item_data.get('image_path'):\n",
    "                    img_filename_info = f\", Associated Image: '{os.path.basename(doc_item_data['image_path'])}'\"\n",
    "                logger.info(f\"{query_log_prefix}  {i+1}. DocID: {doc_item_data.get('id', 'N/A')} (Score: {score_str})\")\n",
    "                logger.info(f\"{query_log_prefix}     Text Preview: '{text_preview}'{img_filename_info}\")\n",
    "            logger.info(f\"{query_log_prefix}{'-'*40}\") \n",
    "\n",
    "        # --- 准备示例查询数据 (减少数量以适应资源限制) ---\n",
    "        text_queries_examples: List[str] = [\n",
    "            \"What is a bandgap voltage reference and its main purpose?\", # 英文查询以配合英文目录和文件名\n",
    "            \"Explain how PTAT current is generated and its role in bandgap circuits.\",\n",
    "            # \"Describe the basic topology of a classic bandgap reference circuit using BJTs.\", # Removed for brevity\n",
    "        ]\n",
    "\n",
    "        image_docs_available_for_queries: List[Dict[str, Any]] = []\n",
    "        if documents_to_index: \n",
    "            for doc_data_item_source in documents_to_index: \n",
    "                img_path_source = doc_data_item_source.get('image_path')\n",
    "                if img_path_source and os.path.exists(img_path_source) and os.path.isfile(img_path_source):\n",
    "                    image_docs_available_for_queries.append({\n",
    "                        'id': doc_data_item_source.get('id'), \n",
    "                        'image_path': img_path_source,\n",
    "                        'text': doc_data_item_source.get('text', '') \n",
    "                    })\n",
    "\n",
    "        image_queries_examples_data: List[Dict[str, Any]] = []\n",
    "        multimodal_queries_examples_data: List[Dict[str, Any]] = []\n",
    "\n",
    "        if image_docs_available_for_queries:\n",
    "            num_image_query_samples = min(1, len(image_docs_available_for_queries)) # Reduced to 1 sample\n",
    "            logger.info(f\"Found {len(image_docs_available_for_queries)} documents with valid images. Will randomly select {num_image_query_samples} for image/multimodal query examples.\")\n",
    "            selected_image_docs_for_queries = random.sample(image_docs_available_for_queries, num_image_query_samples)\n",
    "\n",
    "            for selected_doc_info in selected_image_docs_for_queries:\n",
    "                doc_id_for_query = selected_doc_info['id']\n",
    "                img_path_for_query = selected_doc_info['image_path']\n",
    "                img_filename_for_query = os.path.basename(img_path_for_query) \n",
    "\n",
    "                image_queries_examples_data.append({\n",
    "                    'query_input': {'image_path': img_path_for_query},\n",
    "                    'query_for_generator': f\"This image (filename: {img_filename_for_query}) primarily shows what circuit structure or key concept? Please explain in detail based on the text description in the associated document.\",\n",
    "                    'description': f\"PureImageQuery_About_{img_filename_for_query}\"\n",
    "                })\n",
    "\n",
    "                multimodal_queries_examples_data.append({\n",
    "                    'query_input': {\n",
    "                        'text': f\"Combining the document content and this image (filename: {img_filename_for_query}), please explain the working principle, key features, or design considerations of the circuit shown.\", \n",
    "                        'image_path': img_path_for_query\n",
    "                    },\n",
    "                    'query_for_generator': f\"Combining the document content and this image (filename: {img_filename_for_query}), please explain the working principle, key features, or design considerations of the circuit shown.\",\n",
    "                    'description': f\"MultimodalQuery_Explain_Image_{img_filename_for_query}\"\n",
    "                })\n",
    "        else:\n",
    "             logger.warning(\"WARNING: No valid, existing image files found in the loaded data.\")\n",
    "             logger.warning(\"      Therefore, pure image query and multimodal query examples will be skipped.\")\n",
    "\n",
    "\n",
    "        all_example_queries_groups: List[Tuple[str, List[Any]]] = [ # Adjusted type for List[Any]\n",
    "            (\"Pure_Text_Queries\", text_queries_examples),\n",
    "            (\"Pure_Image_Queries\", image_queries_examples_data),\n",
    "            (\"Multimodal_Queries\", multimodal_queries_examples_data)\n",
    "        ]\n",
    "\n",
    "        overall_query_counter = 0 \n",
    "        for query_group_name, queries_in_group in all_example_queries_groups:\n",
    "            logger.info(f\"\\n{'#'*70}\\n>>> Starting Example Queries for Type: [{query_group_name}] (Total in this group: {len(queries_in_group)}) <<<\\n{'#'*70}\\n\")\n",
    "\n",
    "            if not queries_in_group:\n",
    "                logger.info(f\"    (Skipping [{query_group_name}] type queries as no query data is available.)\")\n",
    "                continue \n",
    "\n",
    "            for query_index_in_group, query_data_item in enumerate(queries_in_group):\n",
    "                overall_query_counter += 1\n",
    "                \n",
    "                query_input_for_retriever: Union[str, Dict[str, str], None] = None \n",
    "                query_text_for_generator: Optional[str] = None          \n",
    "                query_description_for_logging: Optional[str] = None     \n",
    "                query_file_prefix_for_saving: Optional[str] = None     \n",
    "\n",
    "                if query_group_name == \"Pure_Text_Queries\":\n",
    "                    query_input_for_retriever = str(query_data_item) \n",
    "                    query_text_for_generator = str(query_data_item)\n",
    "                    query_description_for_logging = str(query_data_item)\n",
    "                    query_file_prefix_for_saving = sanitize_filename(f\"TextQuery_{query_data_item}\", max_length=60)\n",
    "                else: \n",
    "                    query_input_for_retriever = query_data_item['query_input'] # type: ignore\n",
    "                    query_text_for_generator = query_data_item['query_for_generator'] # type: ignore\n",
    "                    # Use the pre-defined description from the dict, as it's already sanitized for filename use\n",
    "                    query_description_for_logging = query_data_item['description'] # type: ignore\n",
    "                    query_file_prefix_for_saving = sanitize_filename(query_data_item['description'], max_length=60) # type: ignore\n",
    "                \n",
    "                logger.info(f\"\\n--- Processing Query #{overall_query_counter} (Type: {query_group_name} - Index: {query_index_in_group+1}/{len(queries_in_group)}) ---\")\n",
    "                logger.info(f\"Query Description: {str(query_description_for_logging)[:120]}{'...' if len(str(query_description_for_logging))>120 else ''}\")\n",
    "                if isinstance(query_input_for_retriever, dict):\n",
    "                    if 'text' in query_input_for_retriever:\n",
    "                        logger.info(f\"  -> Input text for Retriever: '{str(query_input_for_retriever['text'])[:80]}...'\")\n",
    "                    if 'image_path' in query_input_for_retriever:\n",
    "                        logger.info(f\"  -> Input image for Retriever: '{os.path.basename(str(query_input_for_retriever['image_path']))}'\")\n",
    "                logger.info(f\"  -> Question text for Generator: '{str(query_text_for_generator)[:100]}...'\")\n",
    "                logger.info(\"-\" * 30) \n",
    "                \n",
    "                current_query_specific_output_dir = os.path.join(QUERY_RESULTS_DIR, f\"query_{overall_query_counter:03d}_{query_file_prefix_for_saving}\")\n",
    "                os.makedirs(current_query_specific_output_dir, exist_ok=True)\n",
    "                logger.info(f\"  Detailed results for this query will be saved in: {current_query_specific_output_dir}\")\n",
    "\n",
    "\n",
    "                retrieved_context_docs_list: List[Dict[str, Any]] = [] \n",
    "                final_generated_response_text: str = \"LLM generation step was not executed or failed due to an error.\" \n",
    "                \n",
    "                try:\n",
    "                    query_input_filename = \"input_to_retriever.json\" if isinstance(query_input_for_retriever, dict) else \"input_to_retriever.txt\"\n",
    "                    query_input_save_path = os.path.join(current_query_specific_output_dir, query_input_filename)\n",
    "                    with open(query_input_save_path, 'w', encoding='utf-8') as f_query_in:\n",
    "                        if isinstance(query_input_for_retriever, dict):\n",
    "                            json.dump(query_input_for_retriever, f_query_in, ensure_ascii=False, indent=4)\n",
    "                        else:\n",
    "                            f_query_in.write(str(query_input_for_retriever))\n",
    "                    logger.debug(f\"  Query input saved to: {query_input_save_path}\")\n",
    "\n",
    "                    logger.info(\"  [Retrieval Phase] Calling Retriever.retrieve() method...\")\n",
    "                    # Using k=2 for faster example runs\n",
    "                    retrieved_context_docs_list = retriever_instance.retrieve(query_input_for_retriever, k=2) \n",
    "                    log_retrieved_docs_summary_for_main_process(retrieved_context_docs_list, query_log_prefix=\"    \")\n",
    "                    \n",
    "                    retrieved_context_save_path = os.path.join(current_query_specific_output_dir, \"retrieved_context_documents.json\")\n",
    "                    with open(retrieved_context_save_path, 'w', encoding='utf-8') as f_retrieved_ctx:\n",
    "                        json.dump(retrieved_context_docs_list, f_retrieved_ctx, ensure_ascii=False, indent=4)\n",
    "                    logger.debug(f\"  Full retrieved context documents saved to: {retrieved_context_save_path}\")\n",
    "\n",
    "                    if retrieved_context_docs_list: # Only generate if context is found\n",
    "                        logger.info(\"  [Generation Phase] Calling Generator.generate() method (using retrieved context)...\")\n",
    "                        if query_text_for_generator is not None: \n",
    "                            final_generated_response_text = generator_instance.generate(query_text_for_generator, retrieved_context_docs_list)\n",
    "\n",
    "                            logger.info(f\"\\n  <<< LLM Final Response for Query #{overall_query_counter} >>>\")\n",
    "                            logger.info(\"-\" * 35)\n",
    "                            logger.info(final_generated_response_text) \n",
    "                            logger.info(\"-\" * 35)\n",
    "                        else:\n",
    "                            logger.error(\"  [Generation Phase] ERROR: Query text for Generator is None. Cannot generate response.\")\n",
    "                            final_generated_response_text = \"Error: Query text provided to the generator was empty.\"\n",
    "                    else:\n",
    "                         logger.info(\"  [Generation Phase] Skipped: No relevant context documents were retrieved by the Retriever, so LLM generation is not performed.\")\n",
    "                         final_generated_response_text = \"LLM generation was not performed as no relevant context was found.\"\n",
    "\n",
    "                    llm_response_save_path = os.path.join(current_query_specific_output_dir, \"final_llm_generated_response.txt\")\n",
    "                    with open(llm_response_save_path, 'w', encoding='utf-8') as f_llm_resp:\n",
    "                        f_llm_resp.write(final_generated_response_text)\n",
    "                    logger.debug(f\"  LLM generated response saved to: {llm_response_save_path}\")\n",
    "\n",
    "                except Exception as e_query_processing:\n",
    "                     logger.error(f\"CRITICAL ERROR during processing of query '{query_description_for_logging}' (Query #{overall_query_counter}): {e_query_processing}\", exc_info=True)\n",
    "                     try:\n",
    "                        llm_response_path = os.path.join(current_query_specific_output_dir, \"final_llm_generated_response_ERROR.txt\")\n",
    "                        with open(llm_response_path, 'w', encoding='utf-8') as f_llm_err:\n",
    "                            f_llm_err.write(f\"A critical error occurred while processing this query: {e_query_processing}\\nPlease check the main log file for a detailed stack trace.\")\n",
    "                     except Exception as e_save_err:\n",
    "                        logger.error(f\"Additional error: Failed to save query processing error information to file: {e_save_err}\")\n",
    "\n",
    "                logger.info(f\"--- Query #{overall_query_counter} processing complete ---\")\n",
    "                if query_index_in_group < len(queries_in_group) - 1: \n",
    "                    delay_seconds = 0.5 # Reduced delay for faster testing\n",
    "                    logger.info(f\"\\n...Pausing for {delay_seconds} seconds before next query in this group...\\n\" + \"-\"*70 + \"\\n\")\n",
    "                    time.sleep(delay_seconds)\n",
    "            \n",
    "            logger.info(f\"\\n{'#'*70}\\n>>> All example queries for type [{query_group_name}] have been processed <<<\\n{'#'*70}\\n\")\n",
    "            time.sleep(0.5) \n",
    "\n",
    "    else:\n",
    "        logger.critical(\"\\nCRITICAL SYSTEM ISSUE: RAG query example flow cannot be executed due to failure in initializing one or more core components.\")\n",
    "        if not retriever_instance:\n",
    "            logger.critical(\"  - Reason: Retriever failed to initialize.\")\n",
    "            logger.critical(\"    Please carefully review logs for Step 2 (Indexer initialization) and Step 3 (Retriever initialization) to identify the root cause.\")\n",
    "        if not generator_instance:\n",
    "            logger.critical(\"  - Reason: Generator failed to initialize.\")\n",
    "            logger.critical(\"    Please carefully review logs for Step 4 (Generator initialization), especially checks for ZHIPUAI_API_KEY and ZhipuAI client initialization status.\")\n",
    "        logger.critical(\"Please resolve the initialization issues and try again.\")\n",
    "\n",
    "    logger.info(\"--- [Main Flow] Step 5 (RAG Query Examples) Complete. ---\\n\")\n",
    "\n",
    "    # =============================================================================================\n",
    "    # 步骤 6: 清理和关闭资源\n",
    "    # =============================================================================================\n",
    "    logger.info(\"--- [Main Flow] Step 6: Cleaning up and closing system resources ---\")\n",
    "    if retriever_instance: \n",
    "        retriever_instance.close()\n",
    "    else:\n",
    "        logger.info(\"  Retriever was not initialized or failed, no cleanup needed.\")\n",
    "        \n",
    "    if generator_instance: \n",
    "        generator_instance.close()\n",
    "    else:\n",
    "        logger.info(\"  Generator was not initialized or failed, no cleanup needed.\")\n",
    "        \n",
    "    if indexer_instance:   \n",
    "        indexer_instance.close()\n",
    "    else:\n",
    "        logger.info(\"  Indexer was not initialized or failed, no cleanup (and Faiss indices might not be saved).\")\n",
    "        \n",
    "    logger.info(\"--- [Main Flow] System resource cleanup and shutdown procedures complete. ---\\n\")\n",
    "\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"========= Multimodal RAG System Example Program Execution Finished =========\")\n",
    "    logger.info(f\"All outputs (logs, database, indices, query results) have been saved in the top-level directory:\")\n",
    "    logger.info(f\"  {os.path.abspath(OUTPUT_BASE_DIR)}\")\n",
    "    logger.info(\"Key subdirectories overview:\")\n",
    "    logger.info(f\"  - {os.path.join(OUTPUT_BASE_DIR, 'run_logs/')}\")\n",
    "    logger.info(f\"  - {os.path.join(OUTPUT_BASE_DIR, 'data_storage', 'database/')}\")\n",
    "    logger.info(f\"  - {os.path.join(OUTPUT_BASE_DIR, 'data_storage', 'vector_indices/')}\")\n",
    "    logger.info(f\"  - {os.path.join(OUTPUT_BASE_DIR, 'query_session_results/')}\")\n",
    "    logger.info(f\"    (Under query_session_results/, each 'query_XXX_...' subdirectory contains detailed I/O for a single query)\")\n",
    "    logger.info(\"=\"*80 + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
