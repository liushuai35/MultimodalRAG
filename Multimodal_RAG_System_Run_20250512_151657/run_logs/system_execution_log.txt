2025-05-12 15:16:57,003 - INFO - [873340601.py.setup_logging:77] - 全局日志记录器配置完成。日志将输出到控制台，并写入文件: Multimodal_RAG_System_Run_20250512_151657\run_logs\system_execution_log.txt
2025-05-12 15:16:57,005 - INFO - [873340601.py.<module>:1776] - 
================================================================================
2025-05-12 15:16:57,006 - INFO - [873340601.py.<module>:1777] - ========= Multimodal Retrieval Augmented Generation (RAG) System =========
2025-05-12 15:16:57,007 - INFO - [873340601.py.<module>:1778] - =========                     Main Program Execution Start               =========
2025-05-12 15:16:57,008 - INFO - [873340601.py.<module>:1779] - ================================================================================

2025-05-12 15:16:57,009 - INFO - [873340601.py.<module>:1780] - User Defined Run Identifier (Base): Multimodal_RAG_System_Run
2025-05-12 15:16:57,009 - INFO - [873340601.py.<module>:1781] - Sanitized Run Identifier: Multimodal_RAG_System_Run
2025-05-12 15:16:57,010 - INFO - [873340601.py.<module>:1782] - All output data will be saved in the directory: d:\ALL IN AI\多模态RAG\IDT_RAG\MultimodalRAG\Multimodal_RAG_System_Run_20250512_151657
2025-05-12 15:16:57,011 - INFO - [873340601.py.<module>:1787] - Data Source Config: JSON Metadata File='data.json', Image Directory='images'
2025-05-12 15:16:57,012 - INFO - [873340601.py.<module>:1802] - Database file will be saved to: Multimodal_RAG_System_Run_20250512_151657\data_storage\database\multimodal_document_library.db
2025-05-12 15:16:57,012 - INFO - [873340601.py.<module>:1803] - Faiss index files will be saved to directory: Multimodal_RAG_System_Run_20250512_151657\data_storage\vector_indices
2025-05-12 15:16:57,013 - INFO - [873340601.py.<module>:1804] - Query session results will be saved to directory: Multimodal_RAG_System_Run_20250512_151657\query_session_results
2025-05-12 15:16:57,013 - INFO - [873340601.py.<module>:1813] - Model Configuration: CLIP Model='openai/clip-vit-base-patch32', Large Language Model (LLM)='glm-4-flash'
2025-05-12 15:16:57,014 - INFO - [873340601.py.<module>:1818] - 
--- [Main Flow] Step 1: Loading document data from JSON and associating image files ---
2025-05-12 15:16:57,014 - INFO - [873340601.py.load_data_from_json_and_associate_images:156] - 开始从 JSON 文件 'data.json' 加载数据，并在目录 'images' 中关联图像...
2025-05-12 15:16:57,017 - INFO - [873340601.py.load_data_from_json_and_associate_images:188] - 已成功从 'data.json' 加载 219 条原始记录。
2025-05-12 15:16:57,054 - INFO - [873340601.py.load_data_from_json_and_associate_images:245] - 成功准备了 219 个文档用于后续处理。
2025-05-12 15:16:57,055 - INFO - [873340601.py.load_data_from_json_and_associate_images:248] - 在有效文档中，共有 213 个文档成功关联了图像文件。
2025-05-12 15:16:57,055 - INFO - [873340601.py.load_data_from_json_and_associate_images:255] - --- 数据加载与图像关联流程结束 ---
2025-05-12 15:16:57,056 - INFO - [873340601.py.<module>:1826] - --- [Main Flow] Step 1 Complete: Successfully loaded and prepared 219 documents for indexing. ---

2025-05-12 15:16:57,258 - INFO - [873340601.py.<module>:1832] - --- [Main Flow] Step 2: Initializing Indexer and building indices for loaded documents ---
2025-05-12 15:16:57,258 - INFO - [873340601.py.__init__:547] - 开始初始化 Indexer...
2025-05-12 15:16:57,259 - INFO - [873340601.py.__init__:554] -   数据库路径: Multimodal_RAG_System_Run_20250512_151657\data_storage\database\multimodal_document_library.db
2025-05-12 15:16:57,260 - INFO - [873340601.py.__init__:555] -   文本索引路径: Multimodal_RAG_System_Run_20250512_151657\data_storage\vector_indices\text_vector_index.faiss
2025-05-12 15:16:57,260 - INFO - [873340601.py.__init__:556] -   图像索引路径: Multimodal_RAG_System_Run_20250512_151657\data_storage\vector_indices\image_vector_index.faiss
2025-05-12 15:16:57,260 - INFO - [873340601.py.__init__:557] -   平均向量索引路径: Multimodal_RAG_System_Run_20250512_151657\data_storage\vector_indices\mean_vector_index.faiss
2025-05-12 15:16:57,261 - INFO - [873340601.py.__init__:561] -   - 正在初始化内部 MultimodalEncoder，使用 CLIP 模型: openai/clip-vit-base-patch32...
2025-05-12 15:16:57,261 - INFO - [873340601.py.__init__:296] - 开始初始化 MultimodalEncoder，尝试加载 CLIP 模型: openai/clip-vit-base-patch32
