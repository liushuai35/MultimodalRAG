{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc8c28b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== 选项 1: 端到端多模态 RAG 示例 ==========\n",
      "\n",
      "--- 清理旧文件 ---\n",
      "--- 清理完成 ---\n",
      "\n",
      "--- 步骤 1: 加载数据 ---\n",
      "已加载 219 条记录，成功准备 219 个文档。\n",
      "--- 步骤 1 完成 ---\n",
      "\n",
      "--- 步骤 2: 初始化 Indexer (选项 1) 并索引 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.hf.co/openai/clip-vit-base-patch32/a63082132ba4f97a80bea76823f544493bffa8082296d62d71581a4feff1576f?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1745643762&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTY0Mzc2Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9vcGVuYWkvY2xpcC12aXQtYmFzZS1wYXRjaDMyL2E2MzA4MjEzMmJhNGY5N2E4MGJlYTc2ODIzZjU0NDQ5M2JmZmE4MDgyMjk2ZDYyZDcxNTgxYTRmZWZmMTU3NmY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=WtEzPrpaLcBeKtb5b%7EeJwccvR2UvoMT%7EOXfvLl-Eshtla5DwjXfhlCllW4eAgEQ3MUbT9N9yBlgnK5RuRN67v%7E2y1qKTD%7Ez1y748uLny6g3srLjMapjYGNqZMn66jSc9djX-y7LTTG2Szvvo1GZczLqWjaRTB%7E1Lf8ZeNFmI8cH2REy07yNP8gfnGIL4pmpdUktRgt2RRq8TU1lSkR7OIamy3YMLiXNFfWjaPpIhO06CMUuI8DwxD7Q8Dh3uLi4GlZG2JOQBmsga%7E3BYqVcVzKJcgr4jrctiE1nrfBnA-IygOIQRAN8pR7OGMXF5no7lmgpDQE8%7Eo6IEzYSCQ96xwA__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "d:\\ProgramData\\anaconda3\\envs\\mrag\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\26354\\.cache\\huggingface\\hub\\models--openai--clip-vit-base-patch32. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultimodalEncoder (CLIP) 初始化成功，模型: openai/clip-vit-base-patch32, 维度: 512, 设备: cpu\n",
      "数据库已初始化或连接成功: rag_option1.db\n",
      "未找到 Faiss 索引文件，创建新的空索引。\n",
      "创建了新的 Faiss IndexIDMap2 (内积) 索引 (维度: 512)。\n",
      "开始处理 219 个文档进行多模态索引...\n",
      "  已处理 50/219 个原始文档...\n",
      "  已处理 100/219 个原始文档...\n",
      "  已处理 150/219 个原始文档...\n",
      "  已处理 200/219 个原始文档...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.hf.co/openai/clip-vit-base-patch32/99d28a652e6ec46629ab7047a0ac82c69b1fe11e0ce672c43af65d3a9a3fc05d?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1745642738&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTY0MjczOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9vcGVuYWkvY2xpcC12aXQtYmFzZS1wYXRjaDMyLzk5ZDI4YTY1MmU2ZWM0NjYyOWFiNzA0N2EwYWM4MmM2OWIxZmUxMWUwY2U2NzJjNDNhZjY1ZDNhOWEzZmMwNWQ%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=DzlFrL5T0qg3SQq3APsz4g56YwU6JbAEugSjSJ3Cy4TJMEUqPro97HjAeFWVaIDSJRc-W12OICCINDJ7mjF6VlxY47yDHL9xiGdf2WlYbsoJ0y7HnuW1vr0AsM9COjQPf5mzBGsXa48DkTlEUWPm5BaBqib83byjvm3RC9PjiyTkt2UZaoX8p3W8xDtH%7EQjV8V3Lq58Ck38PefMi%7EbubT6O8E3C2uzLV5ckXDEZNYrTRFTjRrNoqszXM7pcjz%7EGywDZwre7cNaOCg%7EZioUlpt1SSF5y9u97H%7ENgtPXz2U82zoEujBBiNZeemaNXKkt%7EZ7yx69z54fp61rksAO0mWKw__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功向 Faiss 添加 438 个新向量。当前总数: 438\n",
      "成功向数据库存储 438 条新记录。\n",
      "索引过程完成。总处理文档: 219, 跳过重复: 0, 跳过编码错误: 0\n",
      "索引完成。向量总数: 438, 数据库条目数: 438\n",
      "--- 步骤 2 完成 ---\n",
      "\n",
      "--- 步骤 3: 初始化 Retriever (选项 1) ---\n",
      "Retriever 初始化成功。\n",
      "--- 步骤 3 完成 ---\n",
      "\n",
      "--- 步骤 4: 初始化 Generator (选项 1 - MLLM 占位符) ---\n",
      "Generator (选项 1 - MLLM 占位符) 初始化成功。目标模型: glm-4v, 备用: glm-4-flash\n",
      "Generator 初始化成功。\n",
      "--- 步骤 4 完成 ---\n",
      "\n",
      "--- 步骤 5: 执行查询示例 ---\n",
      "\n",
      "--- 查询 1/3 ---\n",
      "查询 (文本): 带隙基准电路的核心原理是什么？\n",
      "  - 正在 Faiss 索引中搜索 Top 5...\n",
      "  - Faiss 搜索完成，找到 5 个结果。\n",
      "  - 正在从数据库获取原始条目信息...\n",
      "  - 成功获取 5 个条目的数据。\n",
      "  检索到 5 个条目:\n",
      "    1. [类型: text] ID: Comparator58, 得分: 0.8904\n",
      "       文本: \n",
      "\n",
      "    ---------------\n",
      "    2. [类型: text] ID: Bandgap32, 得分: 0.7764\n",
      "       文本: conclusion\": \": 1. **Evidence 1: PTAT Current Generator**\\n   - \\\\( Q1 \\\\) and \\\\( Q2 \\\\): Unequal e...\n",
      "    ---------------\n",
      "    3. [类型: text] ID: Bandgap52, 得分: 0.7682\n",
      "       文本: conclusion\": \"**\\n\\nBased on the provided circuit diagram:\\n\\n1. **Evidence for Bandgap Reference Id...\n",
      "    ---------------\n",
      "    4. [类型: text] ID: Bandgap86, 得分: 0.7677\n",
      "       文本: conclusion\": \"1. **Evidence 1:** Q1 and Q2 form a BJT pair with unequal emitter areas, producing a P...\n",
      "    ---------------\n",
      "    5. [类型: text] ID: Bandgap65, 得分: 0.7624\n",
      "       文本: conclusion\": \"1. **PTAT Generation:** Q1, Q2 and R1 generate a voltage proportional to temperature (...\n",
      "    ---------------\n",
      "\n",
      "  生成响应 (使用 MLLM 或占位符):\n",
      "正在使用 5 个检索到的条目 (含图文) 为查询生成响应...\n",
      "  - [占位符] MLLM Prompt 构建完成 (需要适配实际 MLLM API 格式)。\n",
      "  - [占位符] 正在尝试调用目标 MLLM 'glm-4v'...\n",
      "  - [占位符] 无法直接调用 MLLM，将使用备用文本模型 'glm-4-flash' 处理纯文本部分...\n",
      "  - [占位符] 使用备用文本模型调用成功。\n",
      "  - 响应生成和后处理完成。\n",
      "带隙基准电路的核心原理基于以下步骤：\n",
      "\n",
      "1. **PTAT（正温度系数）电压生成**：使用晶体管Q1和Q2，它们的发射极面积不等，这会导致它们的基射电压差（ΔV_BE）随温度变化而变化，形成与温度成正比的PTAT电压。\n",
      "\n",
      "2. **CTAT（负温度系数）电压生成**：晶体管Q3通过其基射结提供与温度成反比的CTAT电压。\n",
      "\n",
      "3. **电阻网络组合**：电阻网络，例如R1、R2和R3，将PTAT和CTAT组件结合起来，以达到温度不变性。\n",
      "\n",
      "4. **输出电压稳定性**：通过反馈和电流镜结构，稳定输出电压V_REF，确保其与温度和供电变化无关。\n",
      "\n",
      "这种电路能够产生一个几乎不随温度变化的稳定参考电压，通常约为1.2V。这是通过以下证据来确认的：\n",
      "\n",
      "- **PTAT和CTAT元件的存在**：如PTAT生成器（Q1 & Q2）和CTAT源（Q3）。\n",
      "- **温度系数平衡的电阻网络**：如R1-R2。\n",
      "- **稳定的输出电压**：在V_REF处输出电压稳定。\n",
      "- **反馈和电流镜结构**：确保电压稳定性。\n",
      "\n",
      "通过这些机制，带隙基准电路能够提供高精度的电压参考，这对于各种电子设备中的模拟电路设计至关重要。\n",
      "\n",
      "--- 查询 2/3 ---\n",
      "查询 (图像): Comparator31.png\n",
      "  - 正在 Faiss 索引中搜索 Top 5...\n",
      "  - Faiss 搜索完成，找到 5 个结果。\n",
      "  - 正在从数据库获取原始条目信息...\n",
      "  - 成功获取 5 个条目的数据。\n",
      "  检索到 5 个条目:\n",
      "    1. [类型: image] ID: Comparator31, 得分: 1.0000\n",
      "       图像文件: Comparator31.png\n",
      "    ---------------\n",
      "    2. [类型: image] ID: Comparator30, 得分: 0.9481\n",
      "       图像文件: Comparator30.png\n",
      "    ---------------\n",
      "    3. [类型: image] ID: Comparator26, 得分: 0.9422\n",
      "       图像文件: Comparator26.png\n",
      "    ---------------\n",
      "    4. [类型: image] ID: Comparator27, 得分: 0.9375\n",
      "       图像文件: Comparator27.png\n",
      "    ---------------\n",
      "    5. [类型: image] ID: Comparator41, 得分: 0.9350\n",
      "       图像文件: Comparator41.png\n",
      "    ---------------\n",
      "\n",
      "  生成响应 (使用 MLLM 或占位符):\n",
      "正在使用 5 个检索到的条目 (含图文) 为查询生成响应...\n",
      "  - [占位符] MLLM Prompt 构建完成 (需要适配实际 MLLM API 格式)。\n",
      "  - [占位符] 正在尝试调用目标 MLLM 'glm-4v'...\n",
      "  - [占位符] 无法直接调用 MLLM，将使用备用文本模型 'glm-4-flash' 处理纯文本部分...\n",
      "  - [占位符] 使用备用文本模型调用成功。\n",
      "  - 响应生成和后处理完成。\n",
      "很抱歉，当前没有提供具体的图片或文本描述，因此我无法描述看到的内容。请提供相关的图片或描述，以便我能够作出相应的回答。\n",
      "\n",
      "--- 查询 3/3 ---\n",
      "查询 (多模态): 文本='请结合这张图片解释电路如何工作', 图像='Comparator88.png'\n",
      "  - 正在 Faiss 索引中搜索 Top 5...\n",
      "  - Faiss 搜索完成，找到 5 个结果。\n",
      "  - 正在从数据库获取原始条目信息...\n",
      "  - 成功获取 5 个条目的数据。\n",
      "  检索到 5 个条目:\n",
      "    1. [类型: image] ID: Comparator88, 得分: 0.7764\n",
      "       图像文件: Comparator88.png\n",
      "    ---------------\n",
      "    2. [类型: image] ID: Comparator74, 得分: 0.7764\n",
      "       图像文件: Comparator74.png\n",
      "    ---------------\n",
      "    3. [类型: image] ID: Comparator87, 得分: 0.7579\n",
      "       图像文件: Comparator87.png\n",
      "    ---------------\n",
      "    4. [类型: image] ID: Comparator73, 得分: 0.7579\n",
      "       图像文件: Comparator73.png\n",
      "    ---------------\n",
      "    5. [类型: image] ID: Comparator2, 得分: 0.7478\n",
      "       图像文件: Comparator2.png\n",
      "    ---------------\n",
      "\n",
      "  生成响应 (使用 MLLM 或占位符):\n",
      "正在使用 5 个检索到的条目 (含图文) 为查询生成响应...\n",
      "  - [占位符] MLLM Prompt 构建完成 (需要适配实际 MLLM API 格式)。\n",
      "  - [占位符] 正在尝试调用目标 MLLM 'glm-4v'...\n",
      "  - [占位符] 无法直接调用 MLLM，将使用备用文本模型 'glm-4-flash' 处理纯文本部分...\n",
      "  - [占位符] 使用备用文本模型调用成功。\n",
      "  - 响应生成和后处理完成。\n",
      "很抱歉，由于我无法直接查看图片，因此无法根据图片内容解释电路如何工作。如果您能提供图片的描述或者具体的工作原理，我将能够根据这些信息来解释电路的工作方式。请提供更多细节以便我能够帮助您。\n",
      "--- 步骤 5 完成 ---\n",
      "\n",
      "--- 步骤 6: 清理资源 ---\n",
      "Faiss 索引已保存到: rag_option1.faiss\n",
      "--- 清理完成 ---\n",
      "\n",
      "========== 选项 1 示例结束 ==========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# 选项 1: 端到端多模态处理 RAG 实现示例\n",
    "# 使用 CLIP 进行图文统一嵌入，使用 MLLM (占位符) 进行生成\n",
    "\n",
    "import sqlite3\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import List, Dict, Union, Optional, Tuple\n",
    "import faiss  # 确保已安装 faiss-cpu 或 faiss-gpu\n",
    "from transformers import CLIPProcessor, CLIPModel # 确保已安装 transformers 和 pillow\n",
    "from PIL import Image # 确保已安装 pillow\n",
    "import torch # transformers 依赖 torch\n",
    "import zhipuai # 导入 ZhipuAI 客户端 (用于占位符 Generator)\n",
    "import json # 导入 json 库用于读取数据文件\n",
    "import time # 导入 time 库用于增加延迟\n",
    "import random # 导入 random 库用于随机选择图片\n",
    "\n",
    "# --- 数据加载与图片关联函数 (与原示例相同) ---\n",
    "def load_data_from_json_and_associate_images(json_path: str, image_dir: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    # 从 JSON 文件加载文档数据，并尝试在指定的图像目录中关联对应的图片文件。\n",
    "    # (与原示例代码相同，此处省略详细注释)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(json_path):\n",
    "        print(f\"错误: 未找到 JSON 文件 '{json_path}'。\")\n",
    "        return []\n",
    "    documents = []\n",
    "    image_extensions = ['.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff']\n",
    "    try:\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            json_data = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"错误: 读取或解析 JSON 文件 '{json_path}' 失败: {e}\")\n",
    "        return []\n",
    "    for item in json_data:\n",
    "        doc_id = item.get('name')\n",
    "        text_content = item.get('description')\n",
    "        if not doc_id or not text_content:\n",
    "            continue\n",
    "        image_path = None\n",
    "        if image_dir and os.path.exists(image_dir):\n",
    "             for ext in image_extensions:\n",
    "                 potential_image_path = os.path.join(image_dir, str(doc_id) + ext)\n",
    "                 if os.path.exists(potential_image_path):\n",
    "                     image_path = potential_image_path\n",
    "                     break\n",
    "        documents.append({\n",
    "            'id': str(doc_id),\n",
    "            'text': str(text_content) if text_content is not None else None,\n",
    "            'image_path': image_path\n",
    "        })\n",
    "    print(f\"已加载 {len(json_data)} 条记录，成功准备 {len(documents)} 个文档。\")\n",
    "    return documents\n",
    "\n",
    "# --- 1. 多模态编码器 (MultimodalEncoder - CLIP) ---\n",
    "# 使用 CLIP 模型将文本和图像编码到 *同一个* 向量空间\n",
    "class MultimodalEncoder:\n",
    "    \"\"\"\n",
    "    # 使用 Hugging Face Transformers 的 CLIP 模型进行多模态编码。\n",
    "    # 负责将文本和图像分别转换为向量，这些向量在同一个语义空间中可比较。\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name: str = \"openai/clip-vit-base-patch32\", device: Optional[str] = None):\n",
    "        try:\n",
    "            self.processor = CLIPProcessor.from_pretrained(model_name)\n",
    "            self.model = CLIPModel.from_pretrained(model_name)\n",
    "            self.vector_dimension = self.model.text_model.config.hidden_size\n",
    "\n",
    "            if device:\n",
    "                self.device = torch.device(device)\n",
    "            elif torch.cuda.is_available():\n",
    "                self.device = torch.device(\"cuda\")\n",
    "            else:\n",
    "                self.device = torch.device(\"cpu\")\n",
    "\n",
    "            self.model.to(self.device)\n",
    "            self.model.eval()\n",
    "            print(f\"MultimodalEncoder (CLIP) 初始化成功，模型: {model_name}, 维度: {self.vector_dimension}, 设备: {self.device}\")\n",
    "\n",
    "        except Exception as e:\n",
    "             print(f\"加载 CLIP 模型 {model_name} 失败: {e}\")\n",
    "             raise e\n",
    "\n",
    "    def encode_text(self, text: str) -> Optional[np.ndarray]:\n",
    "        \"\"\"编码单个文本字符串\"\"\"\n",
    "        if not text: return None\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                inputs = self.processor(text=text, return_tensors=\"pt\", padding=True, truncation=True).to(self.device)\n",
    "                text_features = self.model.get_text_features(**inputs)\n",
    "                vector = text_features.squeeze().cpu().numpy().astype('float32')\n",
    "                norm = np.linalg.norm(vector)\n",
    "                return vector / norm if norm > 1e-6 else np.zeros_like(vector)\n",
    "        except Exception as e:\n",
    "            print(f\"编码文本 '{text[:30]}...' 出错: {e}\")\n",
    "            return None\n",
    "\n",
    "    def encode_image(self, image_path: str) -> Optional[np.ndarray]:\n",
    "        \"\"\"编码单个图像文件\"\"\"\n",
    "        if not image_path or not os.path.exists(image_path):\n",
    "            if image_path: print(f\"警告: 未找到图像文件 {image_path}。\")\n",
    "            return None\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                image = Image.open(image_path).convert(\"RGB\")\n",
    "                inputs = self.processor(images=image, return_tensors=\"pt\").to(self.device)\n",
    "                image_features = self.model.get_image_features(**inputs)\n",
    "                vector = image_features.squeeze().cpu().numpy().astype('float32')\n",
    "                norm = np.linalg.norm(vector)\n",
    "                return vector / norm if norm > 1e-6 else np.zeros_like(vector)\n",
    "        except Exception as e:\n",
    "            print(f\"编码图像 {image_path} 出错: {e}\")\n",
    "            return None\n",
    "\n",
    "    def encode_query(self, text: Optional[str] = None, image_path: Optional[str] = None) -> Optional[np.ndarray]:\n",
    "        \"\"\"\n",
    "        # 对查询进行编码。如果同时提供文本和图像，简单地平均它们的向量。\n",
    "        # 注意：更高级的融合策略可能效果更好。\n",
    "        \"\"\"\n",
    "        text_vec = self.encode_text(text) if text else None\n",
    "        image_vec = self.encode_image(image_path) if image_path else None\n",
    "\n",
    "        if text_vec is None and image_vec is None:\n",
    "            print(\"错误: 查询必须至少包含文本或有效图像路径。\")\n",
    "            return None\n",
    "        elif text_vec is not None and image_vec is not None:\n",
    "            # 对文本和图像向量取平均作为融合表示\n",
    "            combined_vector = np.mean([text_vec, image_vec], axis=0).astype('float32')\n",
    "            norm = np.linalg.norm(combined_vector)\n",
    "            return combined_vector / norm if norm > 1e-6 else np.zeros_like(combined_vector)\n",
    "        elif text_vec is not None:\n",
    "            return text_vec\n",
    "        else: # image_vec is not None\n",
    "            return image_vec\n",
    "\n",
    "\n",
    "# --- 2. 索引器 (Indexer) - 选项 1 ---\n",
    "# 编码文本和图像，将 *两种* 向量存入 Faiss，原始数据存入 SQLite\n",
    "class Indexer_Option1:\n",
    "    \"\"\"\n",
    "    # 索引器 (选项1):\n",
    "    # - 使用 MultimodalEncoder (CLIP) 分别编码文本块和图像。\n",
    "    # - 将文本向量和图像向量都存储到 Faiss 索引中。\n",
    "    # - 将原始文本和图像路径存储到 SQLite 数据库中。\n",
    "    # - 使用唯一的 vector_index_id 关联 Faiss 中的向量和 SQLite 中的原始数据。\n",
    "    \"\"\"\n",
    "    def __init__(self, db_path: str, faiss_index_path: str, clip_model_name: str):\n",
    "        self.db_path = db_path\n",
    "        self.faiss_index_path = faiss_index_path\n",
    "        self.encoder = MultimodalEncoder(clip_model_name)\n",
    "        self.vector_dimension = self.encoder.vector_dimension\n",
    "\n",
    "        self._init_db()\n",
    "        self._load_or_create_faiss_index()\n",
    "\n",
    "    def _init_db(self):\n",
    "        \"\"\"初始化 SQLite 数据库和表\"\"\"\n",
    "        try:\n",
    "            with sqlite3.connect(self.db_path) as conn:\n",
    "                cursor = conn.cursor()\n",
    "                # vector_index_id: Faiss 中的唯一 ID，也是 DB 主键\n",
    "                # doc_id: 原始文档标识符 (来自 JSON 'name')\n",
    "                # content_type: 'text' 或 'image'\n",
    "                # text_content: 存储原始文本 (如果是文本类型)\n",
    "                # image_path: 存储图像路径 (如果是图像类型)\n",
    "                cursor.execute('''\n",
    "                    CREATE TABLE IF NOT EXISTS multimodal_items (\n",
    "                        vector_index_id INTEGER PRIMARY KEY,\n",
    "                        doc_id TEXT NOT NULL,\n",
    "                        content_type TEXT NOT NULL CHECK(content_type IN ('text', 'image')),\n",
    "                        text_content TEXT,\n",
    "                        image_path TEXT\n",
    "                    )\n",
    "                ''')\n",
    "                # 添加索引以加速 doc_id 查找 (用于去重)\n",
    "                cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_doc_id_type ON multimodal_items (doc_id, content_type)\")\n",
    "                conn.commit()\n",
    "                print(f\"数据库已初始化或连接成功: {self.db_path}\")\n",
    "        except Exception as e:\n",
    "             print(f\"初始化数据库失败: {e}\")\n",
    "             raise e\n",
    "\n",
    "    def _load_or_create_faiss_index(self):\n",
    "        \"\"\"加载或创建 Faiss 向量索引 (IndexIDMap2 + 内积)\"\"\"\n",
    "        try:\n",
    "            if os.path.exists(self.faiss_index_path):\n",
    "                self.index = faiss.read_index(self.faiss_index_path)\n",
    "                print(f\"成功加载 Faiss 索引: {self.faiss_index_path}, 包含 {self.index.ntotal} 个向量。\")\n",
    "            else:\n",
    "                print(\"未找到 Faiss 索引文件，创建新的空索引。\")\n",
    "                quantizer = faiss.IndexFlatIP(self.vector_dimension) # 内积 (余弦相似度)\n",
    "                self.index = faiss.IndexIDMap2(quantizer)\n",
    "                print(f\"创建了新的 Faiss IndexIDMap2 (内积) 索引 (维度: {self.vector_dimension})。\")\n",
    "        except Exception as e:\n",
    "            print(f\"加载或创建 Faiss 索引失败: {e}。将创建一个新的空索引。\")\n",
    "            quantizer = faiss.IndexFlatIP(self.vector_dimension)\n",
    "            self.index = faiss.IndexIDMap2(quantizer)\n",
    "\n",
    "    def index_documents(self, documents: List[Dict]):\n",
    "        \"\"\"\n",
    "        # 对文档列表进行索引。\n",
    "        # 对每个文档，分别索引其文本内容和关联的图像（如果存在）。\n",
    "        \"\"\"\n",
    "        if not documents: return\n",
    "        print(f\"开始处理 {len(documents)} 个文档进行多模态索引...\")\n",
    "\n",
    "        vectors_to_add = []\n",
    "        vector_ids_for_batch = [] # Faiss 需要的 int64 ID\n",
    "        data_to_store = [] # (vector_id, doc_id, content_type, text, image_path)\n",
    "\n",
    "        start_vector_index_id = self.index.ntotal\n",
    "        next_vector_index_id = start_vector_index_id\n",
    "\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        processed_count = 0\n",
    "        skipped_duplicates = 0\n",
    "        skipped_encoding_errors = 0\n",
    "\n",
    "        for doc in documents:\n",
    "            doc_id = doc.get('id')\n",
    "            text = doc.get('text')\n",
    "            image_path = doc.get('image_path')\n",
    "\n",
    "            if not doc_id: continue\n",
    "\n",
    "            # --- 索引文本部分 ---\n",
    "            if text:\n",
    "                # 检查文本是否已索引\n",
    "                cursor.execute(\"SELECT 1 FROM multimodal_items WHERE doc_id = ? AND content_type = 'text'\", (doc_id,))\n",
    "                if cursor.fetchone():\n",
    "                    skipped_duplicates += 1\n",
    "                    # print(f\"  文本部分 (ID: {doc_id}) 已存在，跳过。\")\n",
    "                    pass # 避免重复打印\n",
    "                else:\n",
    "                    text_vector = self.encoder.encode_text(text)\n",
    "                    if text_vector is not None:\n",
    "                        vectors_to_add.append(text_vector)\n",
    "                        vector_ids_for_batch.append(next_vector_index_id)\n",
    "                        data_to_store.append((next_vector_index_id, doc_id, 'text', text, None))\n",
    "                        next_vector_index_id += 1\n",
    "                    else:\n",
    "                        skipped_encoding_errors += 1\n",
    "                        # print(f\"  文本部分 (ID: {doc_id}) 编码失败，跳过。\")\n",
    "\n",
    "            # --- 索引图像部分 ---\n",
    "            if image_path and os.path.exists(image_path):\n",
    "                 # 检查图像是否已索引\n",
    "                 cursor.execute(\"SELECT 1 FROM multimodal_items WHERE doc_id = ? AND content_type = 'image'\", (doc_id,))\n",
    "                 if cursor.fetchone():\n",
    "                     skipped_duplicates += 1\n",
    "                     # print(f\"  图像部分 (ID: {doc_id}) 已存在，跳过。\")\n",
    "                     pass\n",
    "                 else:\n",
    "                    image_vector = self.encoder.encode_image(image_path)\n",
    "                    if image_vector is not None:\n",
    "                        vectors_to_add.append(image_vector)\n",
    "                        vector_ids_for_batch.append(next_vector_index_id)\n",
    "                        data_to_store.append((next_vector_index_id, doc_id, 'image', None, image_path))\n",
    "                        next_vector_index_id += 1\n",
    "                    else:\n",
    "                         skipped_encoding_errors += 1\n",
    "                         # print(f\"  图像部分 (ID: {doc_id}, Path: {image_path}) 编码失败，跳过。\")\n",
    "            elif image_path:\n",
    "                 # print(f\"  警告: 图像文件不存在，无法索引图像部分 (ID: {doc_id}, Path: {image_path})\")\n",
    "                 pass\n",
    "\n",
    "            processed_count += 1\n",
    "            if processed_count % 50 == 0: # 每处理50个文档打印一次进度\n",
    "                 print(f\"  已处理 {processed_count}/{len(documents)} 个原始文档...\")\n",
    "\n",
    "\n",
    "        # --- 批量添加到 Faiss 和 SQLite ---\n",
    "        if vectors_to_add:\n",
    "            try:\n",
    "                vectors_np = np.array(vectors_to_add, dtype='float32')\n",
    "                ids_np = np.array(vector_ids_for_batch, dtype='int64')\n",
    "                self.index.add_with_ids(vectors_np, ids_np)\n",
    "                print(f\"成功向 Faiss 添加 {len(vectors_np)} 个新向量。当前总数: {self.index.ntotal}\")\n",
    "\n",
    "                cursor.executemany(\n",
    "                    \"INSERT INTO multimodal_items (vector_index_id, doc_id, content_type, text_content, image_path) VALUES (?, ?, ?, ?, ?)\",\n",
    "                    data_to_store\n",
    "                )\n",
    "                conn.commit()\n",
    "                print(f\"成功向数据库存储 {len(data_to_store)} 条新记录。\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"批量添加向量或存储数据时出错: {e}\")\n",
    "                conn.rollback()\n",
    "        else:\n",
    "            print(\"没有新的有效向量或数据需要添加到索引或数据库。\")\n",
    "\n",
    "        conn.close()\n",
    "        print(f\"索引过程完成。总处理文档: {processed_count}, 跳过重复: {skipped_duplicates}, 跳过编码错误: {skipped_encoding_errors}\")\n",
    "\n",
    "    def get_item_by_vector_index_id(self, vector_index_id: int) -> Optional[Dict]:\n",
    "        \"\"\"根据 Faiss 返回的 vector_index_id 从数据库获取原始条目信息\"\"\"\n",
    "        try:\n",
    "            with sqlite3.connect(self.db_path) as conn:\n",
    "                cursor = conn.cursor()\n",
    "                cursor.execute(\n",
    "                    \"SELECT doc_id, content_type, text_content, image_path FROM multimodal_items WHERE vector_index_id = ?\",\n",
    "                    (vector_index_id,)\n",
    "                )\n",
    "                row = cursor.fetchone()\n",
    "                if row:\n",
    "                    doc_id, content_type, text_content, image_path = row\n",
    "                    return {\n",
    "                        'vector_index_id': vector_index_id,\n",
    "                        'doc_id': doc_id,\n",
    "                        'content_type': content_type,\n",
    "                        'text': text_content,\n",
    "                        'image_path': image_path\n",
    "                    }\n",
    "                return None\n",
    "        except Exception as e:\n",
    "             print(f\"从数据库根据 vector_index_id {vector_index_id} 获取条目出错: {e}\")\n",
    "             return None\n",
    "\n",
    "    def get_index_count(self) -> int:\n",
    "         return self.index.ntotal if hasattr(self, 'index') else 0\n",
    "\n",
    "    def get_db_item_count(self) -> int:\n",
    "         try:\n",
    "             with sqlite3.connect(self.db_path) as conn:\n",
    "                 cursor = conn.cursor()\n",
    "                 cursor.execute(\"SELECT COUNT(*) FROM multimodal_items\")\n",
    "                 return cursor.fetchone()[0]\n",
    "         except Exception: return 0\n",
    "\n",
    "    def save_index(self):\n",
    "        if hasattr(self, 'index') and self.index.ntotal > 0:\n",
    "            try:\n",
    "                faiss.write_index(self.index, self.faiss_index_path)\n",
    "                print(f\"Faiss 索引已保存到: {self.faiss_index_path}\")\n",
    "            except Exception as e: print(f\"保存 Faiss 索引失败: {e}\")\n",
    "        elif hasattr(self, 'index'): print(\"Faiss 索引为空，跳过保存。\")\n",
    "        else: print(\"Faiss 索引未初始化，跳过保存。\")\n",
    "\n",
    "    def close(self):\n",
    "        self.save_index()\n",
    "\n",
    "# --- 3. 检索器 (Retriever) - 选项 1 ---\n",
    "# 使用与 Indexer 相同的 Encoder 对查询编码，在 Faiss 中搜索，获取原始数据\n",
    "class Retriever_Option1:\n",
    "    \"\"\"\n",
    "    # 检索器 (选项1):\n",
    "    # - 使用 Indexer 的 MultimodalEncoder 对用户查询（文本、图像、图文）进行编码。\n",
    "    # - 在 Faiss 索引（包含文本和图像向量）中搜索最相似的向量。\n",
    "    # - 根据返回的 vector_index_id 从数据库获取对应的原始文本或图像信息。\n",
    "    \"\"\"\n",
    "    def __init__(self, indexer: Indexer_Option1):\n",
    "        if not isinstance(indexer, Indexer_Option1):\n",
    "             raise ValueError(\"必须提供有效的 Indexer_Option1 实例。\")\n",
    "        self.indexer = indexer\n",
    "        self.encoder = indexer.encoder\n",
    "        self.index = indexer.index\n",
    "        if self.index is None or self.index.ntotal == 0:\n",
    "            print(\"警告: 检索器初始化时发现索引为空。\")\n",
    "\n",
    "    def retrieve(self, query: Union[str, Dict], k: int = 5) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        # 执行检索流程。\n",
    "\n",
    "        Args:\n",
    "            query: 用户查询 (str for text, dict for image {'image_path': ...}, or dict for multimodal {'text': ..., 'image_path': ...})。\n",
    "            k: 检索数量。\n",
    "\n",
    "        Returns:\n",
    "            包含原始数据（文本或图像路径）和得分的字典列表。\n",
    "            [{'doc_id': ..., 'content_type': ..., 'text': ..., 'image_path': ..., 'score': ...}, ...]\n",
    "        \"\"\"\n",
    "        if self.index is None or self.index.ntotal == 0:\n",
    "            print(\"错误: 向量索引不可用或为空。\")\n",
    "            return []\n",
    "\n",
    "        # 1. 查询编码\n",
    "        query_vector = None\n",
    "        if isinstance(query, str):\n",
    "            query_vector = self.encoder.encode_query(text=query)\n",
    "        elif isinstance(query, dict):\n",
    "            query_vector = self.encoder.encode_query(text=query.get('text'), image_path=query.get('image_path'))\n",
    "        else:\n",
    "            print(f\"错误: 不支持的查询类型 {type(query)}\")\n",
    "            return []\n",
    "\n",
    "        if query_vector is None:\n",
    "            print(\"错误: 查询编码失败。\")\n",
    "            return []\n",
    "\n",
    "        query_vector = query_vector.reshape(1, self.indexer.vector_dimension)\n",
    "\n",
    "        # 2. Faiss 搜索\n",
    "        try:\n",
    "            print(f\"  - 正在 Faiss 索引中搜索 Top {k}...\")\n",
    "            scores, vector_index_ids = self.index.search(query_vector, k)\n",
    "            print(f\"  - Faiss 搜索完成，找到 {len(vector_index_ids[0])} 个结果。\")\n",
    "        except Exception as e:\n",
    "            print(f\"  - Faiss 搜索失败: {e}\")\n",
    "            return []\n",
    "\n",
    "        # 3. 获取原始数据\n",
    "        retrieved_items = []\n",
    "        print(\"  - 正在从数据库获取原始条目信息...\")\n",
    "        for i, vec_id in enumerate(vector_index_ids[0]):\n",
    "            if vec_id == -1: continue # Faiss 可能返回 -1\n",
    "            item_data = self.indexer.get_item_by_vector_index_id(int(vec_id))\n",
    "            if item_data:\n",
    "                item_data['score'] = float(scores[0][i]) # 添加相似度得分 (内积)\n",
    "                retrieved_items.append(item_data)\n",
    "            else:\n",
    "                print(f\"  - 警告: 未找到 vector_index_id {vec_id} 对应的数据库记录。\")\n",
    "        print(f\"  - 成功获取 {len(retrieved_items)} 个条目的数据。\")\n",
    "        return retrieved_items\n",
    "\n",
    "    def close(self): pass # 无需特殊操作\n",
    "\n",
    "# --- 4. 生成器 (Generator) - 选项 1 (使用 MLLM - 占位符) ---\n",
    "class Generator_Option1:\n",
    "    \"\"\"\n",
    "    # 生成器 (选项1):\n",
    "    # - **需要使用真正的多模态大语言模型 (MLLM)，如 GPT-4V, GLM-4V, LLaVA 等。**\n",
    "    # - 接收检索到的原始文本和图像。\n",
    "    # - 构建能够被 MLLM API 接受的 Prompt (包含文本和图像引用/数据)。\n",
    "    # - 调用 MLLM API 生成答案。\n",
    "    #\n",
    "    # !!! 注意: 下面的实现使用 ZhipuAI 文本模型作为占位符 !!!\n",
    "    # !!! 实际应用中需要替换为与所选 MLLM 匹配的 API 调用和 Prompt 构建逻辑 !!!\n",
    "    \"\"\"\n",
    "    def __init__(self, api_key: Optional[str] = None, model_name: str = \"glm-4v\", # 默认指向多模态模型\n",
    "                 fallback_text_model: str = \"glm-4-flash\"):\n",
    "        # 优先使用传入的 api_key，否则从环境变量 ZHIPUAI_API_KEY 获取\n",
    "        final_api_key = api_key if api_key else os.getenv(\"ZHIPUAI_API_KEY\")\n",
    "        if not final_api_key:\n",
    "            raise ValueError(\"未提供 ZHIPUAI_API_KEY。\")\n",
    "\n",
    "        try:\n",
    "            self.client = zhipuai.ZhipuAI(api_key=final_api_key)\n",
    "            self.model_name = model_name # 目标 MLLM 模型\n",
    "            self.fallback_model = fallback_text_model # 备用文本模型\n",
    "            print(f\"Generator (选项 1 - MLLM 占位符) 初始化成功。目标模型: {self.model_name}, 备用: {self.fallback_model}\")\n",
    "            # 在这里可以添加检查 API Key 是否支持目标 MLLM 的逻辑 (如果 Zhipu SDK 支持)\n",
    "        except Exception as e:\n",
    "             print(f\"初始化智谱 AI 客户端失败: {e}\")\n",
    "             raise e\n",
    "\n",
    "    def generate(self, query: Union[str, Dict], context: List[Dict]) -> str:\n",
    "        \"\"\"\n",
    "        # 接收查询和包含原始文本/图像的上下文，生成答案。\n",
    "\n",
    "        Args:\n",
    "            query: 原始用户查询 (文本或字典)。\n",
    "            context: 从 Retriever_Option1 获取的列表，每个元素包含原始数据。\n",
    "                     [{'doc_id': ..., 'content_type': 'text'/'image', 'text': ..., 'image_path': ..., 'score': ...}, ...]\n",
    "\n",
    "        Returns:\n",
    "            MLLM (或占位符 LLM) 生成的文本响应。\n",
    "        \"\"\"\n",
    "        print(f\"正在使用 {len(context)} 个检索到的条目 (含图文) 为查询生成响应...\")\n",
    "\n",
    "        # --- !!! MLLM Prompt 构建逻辑 (需要根据实际 MLLM API 调整) !!! ---\n",
    "        # 1. 提取查询中的文本部分\n",
    "        query_text = query if isinstance(query, str) else query.get('text', \"请描述您看到的内容。\") # 如果查询是图片，提供默认文本\n",
    "\n",
    "        # 2. 分离上下文中的文本和图像\n",
    "        context_texts = []\n",
    "        context_images = [] # 存储图像路径或 base64 编码等 MLLM 需要的信息\n",
    "        for item in context:\n",
    "            if item['content_type'] == 'text' and item['text']:\n",
    "                # 限制文本长度\n",
    "                truncated_text = item['text'][:500] + ('...' if len(item['text']) > 500 else '')\n",
    "                context_texts.append(f\"- [来源 Doc ID: {item['doc_id']}, 得分: {item['score']:.4f}] {truncated_text}\")\n",
    "            elif item['content_type'] == 'image' and item['image_path']:\n",
    "                # MLLM 通常需要图像的 URL 或 Base64 编码\n",
    "                # 这里仅作为示例，存储路径和元信息\n",
    "                context_images.append({\n",
    "                    \"path\": item['image_path'],\n",
    "                    \"doc_id\": item['doc_id'],\n",
    "                    \"score\": item['score']\n",
    "                })\n",
    "                # !! 实际操作: 需要将 image_path 转换为 MLLM API 接受的格式 !!\n",
    "                # 例如: 读取图片 -> base64 编码，或者如果图片有公共 URL 则使用 URL\n",
    "\n",
    "        # 3. 构建 MLLM 需要的 messages 结构 (示例，具体格式依赖于 MLLM API)\n",
    "        #    - 对于 GLM-4V, content 可以是包含 text 和 image_url 的列表\n",
    "        #    - 对于 GPT-4V, content 可以是包含 text 和 image_url (含 base64) 的列表\n",
    "        #    - 对于 LLaVA, 可能需要特定的格式或库来处理\n",
    "\n",
    "        messages = []\n",
    "        system_prompt = f\"\"\"\n",
    "        你是一个多模态助手，擅长结合文本和图像信息回答问题。请根据用户查询和下面提供的文本及图像信息进行回答。\n",
    "        严格根据提供的信息作答，如果信息不足请说明。\n",
    "        参考文本信息:\n",
    "        {chr(10).join(context_texts) if context_texts else '无相关文本信息。'}\n",
    "        \"\"\".strip()\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "\n",
    "        # 构建 user message (包含文本查询和图像引用)\n",
    "        user_content_parts = [{\"type\": \"text\", \"text\": query_text}]\n",
    "        if context_images:\n",
    "            user_content_parts.append({\"type\": \"text\", \"text\": \"\\n请参考以下图像:\"})\n",
    "            image_count = 0\n",
    "            for img_info in context_images:\n",
    "                # --- !!! 此处需要将图像转换为 MLLM API 格式 !!! ---\n",
    "                # 假设 MLLM API 支持 \"image_url\" 包含本地路径 (很多 API 不支持) 或 base64\n",
    "                # 这是一个 *占位符* 结构，需要替换\n",
    "                try:\n",
    "                    # 尝试读取并 base64 编码 (如果需要)\n",
    "                    # img_base64 = image_to_base64(img_info['path']) # 需要实现 image_to_base64\n",
    "                    # user_content_parts.append({\n",
    "                    #     \"type\": \"image_url\",\n",
    "                    #     \"image_url\": {\"url\": f\"data:image/jpeg;base64,{img_base64}\"} # 示例 base64 格式\n",
    "                    # })\n",
    "                    # 或者如果 API 支持直接引用，可能更简单，但通常不安全或不可行\n",
    "                    # 为了代码能运行，暂时只添加文本描述\n",
    "                    user_content_parts.append({\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": f\"\\n- 图像 {image_count+1} (来源 Doc ID: {img_info['doc_id']}, 路径: {img_info['path']}, 得分: {img_info['score']:.4f}) [图像内容需由 MLLM 查看]\"\n",
    "                    })\n",
    "                    image_count += 1\n",
    "                except Exception as img_err:\n",
    "                    print(f\"处理图像 {img_info['path']} 时出错: {img_err}\")\n",
    "                    user_content_parts.append({\"type\": \"text\", \"text\": f\"\\n- 图像 (来源 Doc ID: {img_info['doc_id']}) 加载失败.\"})\n",
    "\n",
    "\n",
    "        messages.append({\"role\": \"user\", \"content\": user_content_parts}) # user content 是一个列表\n",
    "\n",
    "        print(\"  - [占位符] MLLM Prompt 构建完成 (需要适配实际 MLLM API 格式)。\")\n",
    "        # print(\"  - [占位符] Prompt 预览 (结构):\", messages) # 打印复杂结构\n",
    "\n",
    "        # --- !!! 调用 MLLM API (占位符逻辑) !!! ---\n",
    "        # 实际应调用目标 MLLM 的 API，如 self.client.chat.completions.create(model=self.model_name, messages=messages, ...)\n",
    "        # 由于没有通用的本地 MLLM 调用方式或统一 API，这里使用 ZhipuAI 文本模型作为回退演示\n",
    "        print(f\"  - [占位符] 正在尝试调用目标 MLLM '{self.model_name}'...\")\n",
    "        try:\n",
    "            # --- !!! 此处应为实际 MLLM API 调用 !!! ---\n",
    "            # response = self.client.chat.completions.create(model=self.model_name, messages=messages, ...)\n",
    "\n",
    "            # --- 回退到文本模型进行演示 ---\n",
    "            print(f\"  - [占位符] 无法直接调用 MLLM，将使用备用文本模型 '{self.fallback_model}' 处理纯文本部分...\")\n",
    "            text_only_messages = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt}, # 复用 system prompt\n",
    "                {\"role\": \"user\", \"content\": query_text + \"\\n\\n(注意: 我无法直接看到图片，请根据提供的文本描述回答。)\"} # 提醒文本模型\n",
    "            ]\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.fallback_model, # 使用备用文本模型\n",
    "                messages=text_only_messages,\n",
    "                temperature=0.7,\n",
    "                max_tokens=1024\n",
    "            )\n",
    "            llm_response = response.choices[0].message.content\n",
    "            print(f\"  - [占位符] 使用备用文本模型调用成功。\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  - 调用 MLLM (或备用模型) 时出错: {e}\")\n",
    "            return f\"调用 LLM 出错: {e}\"\n",
    "\n",
    "        # 后处理\n",
    "        processed_response = llm_response.strip()\n",
    "        print(\"  - 响应生成和后处理完成。\")\n",
    "        return processed_response\n",
    "\n",
    "# --- 选项 1 示例使用流程 ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*10 + \" 选项 1: 端到端多模态 RAG 示例 \" + \"=\"*10 + \"\\n\")\n",
    "\n",
    "    # --- 配置 ---\n",
    "    json_data_path = 'data.json'\n",
    "    image_directory_path = 'images'\n",
    "    db_file_opt1 = 'rag_option1.db'\n",
    "    faiss_index_file_opt1 = 'rag_option1.faiss'\n",
    "    CLIP_MODEL_OPT1 = \"openai/clip-vit-base-patch32\"\n",
    "    # !! 选择你的目标 MLLM 模型名称 (如果可用), 否则用文本模型作为占位符 !!\n",
    "    TARGET_MLLM = \"glm-4v\" # 假设的目标 MLLM\n",
    "    FALLBACK_TEXT_LLM = \"glm-4-flash\" # 备用文本模型\n",
    "\n",
    "    # --- 清理 ---\n",
    "    print(\"--- 清理旧文件 ---\")\n",
    "    if os.path.exists(db_file_opt1): os.remove(db_file_opt1)\n",
    "    if os.path.exists(faiss_index_file_opt1): os.remove(faiss_index_file_opt1)\n",
    "    print(\"--- 清理完成 ---\")\n",
    "\n",
    "    # --- 1. 加载数据 ---\n",
    "    print(\"\\n--- 步骤 1: 加载数据 ---\")\n",
    "    documents = load_data_from_json_and_associate_images(json_data_path, image_directory_path)\n",
    "    if not documents: exit(\"错误: 未加载到文档。\")\n",
    "    print(\"--- 步骤 1 完成 ---\")\n",
    "\n",
    "    # --- 2. 初始化 Indexer 并索引 ---\n",
    "    print(\"\\n--- 步骤 2: 初始化 Indexer (选项 1) 并索引 ---\")\n",
    "    indexer_opt1 = None\n",
    "    try:\n",
    "        indexer_opt1 = Indexer_Option1(db_path=db_file_opt1, faiss_index_path=faiss_index_file_opt1, clip_model_name=CLIP_MODEL_OPT1)\n",
    "        indexer_opt1.index_documents(documents)\n",
    "        print(f\"索引完成。向量总数: {indexer_opt1.get_index_count()}, 数据库条目数: {indexer_opt1.get_db_item_count()}\")\n",
    "        if indexer_opt1.get_index_count() == 0:\n",
    "             print(\"错误: 索引为空！\")\n",
    "             indexer_opt1 = None\n",
    "    except Exception as e:\n",
    "        print(f\"Indexer 初始化或索引失败: {e}\")\n",
    "        indexer_opt1 = None\n",
    "    print(\"--- 步骤 2 完成 ---\")\n",
    "\n",
    "    # --- 3. 初始化 Retriever ---\n",
    "    print(\"\\n--- 步骤 3: 初始化 Retriever (选项 1) ---\")\n",
    "    retriever_opt1 = None\n",
    "    if indexer_opt1:\n",
    "        try:\n",
    "            retriever_opt1 = Retriever_Option1(indexer=indexer_opt1)\n",
    "            print(\"Retriever 初始化成功。\")\n",
    "        except Exception as e:\n",
    "            print(f\"Retriever 初始化失败: {e}\")\n",
    "    else:\n",
    "        print(\"Indexer 不可用，跳过 Retriever 初始化。\")\n",
    "    print(\"--- 步骤 3 完成 ---\")\n",
    "\n",
    "    # --- 4. 初始化 Generator ---\n",
    "    print(\"\\n--- 步骤 4: 初始化 Generator (选项 1 - MLLM 占位符) ---\")\n",
    "    generator_opt1 = None\n",
    "    if os.getenv(\"ZHIPUAI_API_KEY\"):\n",
    "        try:\n",
    "            generator_opt1 = Generator_Option1(model_name=TARGET_MLLM, fallback_text_model=FALLBACK_TEXT_LLM)\n",
    "            print(\"Generator 初始化成功。\")\n",
    "        except Exception as e:\n",
    "            print(f\"Generator 初始化失败: {e}\")\n",
    "    else:\n",
    "        print(\"ZHIPUAI_API_KEY 未设置，跳过 Generator 初始化。\")\n",
    "    print(\"--- 步骤 4 完成 ---\")\n",
    "\n",
    "    # --- 5. 执行查询 ---\n",
    "    print(\"\\n--- 步骤 5: 执行查询示例 ---\")\n",
    "    if retriever_opt1 and generator_opt1:\n",
    "        # 辅助函数打印结果\n",
    "        def print_retrieved_items_opt1(items: List[Dict]):\n",
    "            if not items: print(\"    (未检索到条目)\")\n",
    "            for i, item in enumerate(items):\n",
    "                score_str = f\"得分: {item.get('score', 'N/A'):.4f}\"\n",
    "                print(f\"    {i+1}. [类型: {item['content_type']}] ID: {item['doc_id']}, {score_str}\")\n",
    "                if item['content_type'] == 'text':\n",
    "                    text_preview = item['text'][:100] + ('...' if len(item['text']) > 100 else '')\n",
    "                    print(f\"       文本: {text_preview}\")\n",
    "                elif item['content_type'] == 'image':\n",
    "                    print(f\"       图像文件: {os.path.basename(item['image_path'])}\")\n",
    "                print(\"    \" + \"-\" * 15)\n",
    "\n",
    "        # 查询示例\n",
    "        queries_opt1 = [\n",
    "            \"带隙基准电路的核心原理是什么？\", # 文本查询\n",
    "            {'image_path': random.choice([d['image_path'] for d in documents if d['image_path']]) if any(d['image_path'] for d in documents) else None}, # 图像查询 (随机选一张)\n",
    "            {'text': '请结合这张图片解释电路如何工作', 'image_path': random.choice([d['image_path'] for d in documents if d['image_path']]) if any(d['image_path'] for d in documents) else None} # 多模态查询\n",
    "        ]\n",
    "        # 过滤掉无效查询\n",
    "        queries_opt1 = [q for q in queries_opt1 if q and (not isinstance(q, dict) or q.get('image_path'))]\n",
    "\n",
    "        for i, query in enumerate(queries_opt1):\n",
    "            print(f\"\\n--- 查询 {i+1}/{len(queries_opt1)} ---\")\n",
    "            if isinstance(query, str): print(f\"查询 (文本): {query}\")\n",
    "            elif 'text' not in query: print(f\"查询 (图像): {os.path.basename(query['image_path'])}\")\n",
    "            else: print(f\"查询 (多模态): 文本='{query['text']}', 图像='{os.path.basename(query['image_path'])}'\")\n",
    "\n",
    "            try:\n",
    "                retrieved_context = retriever_opt1.retrieve(query, k=5)\n",
    "                print(f\"  检索到 {len(retrieved_context)} 个条目:\")\n",
    "                print_retrieved_items_opt1(retrieved_context)\n",
    "\n",
    "                if retrieved_context:\n",
    "                    print(\"\\n  生成响应 (使用 MLLM 或占位符):\")\n",
    "                    response = generator_opt1.generate(query, retrieved_context)\n",
    "                    print(response)\n",
    "                else:\n",
    "                    print(\"\\n  未检索到上下文，无法生成响应。\")\n",
    "            except Exception as e:\n",
    "                print(f\"\\n  执行查询或生成时出错: {e}\")\n",
    "            time.sleep(1)\n",
    "\n",
    "    else:\n",
    "        print(\"Retriever 或 Generator 未初始化，跳过查询执行。\")\n",
    "    print(\"--- 步骤 5 完成 ---\")\n",
    "\n",
    "    # --- 6. 清理 ---\n",
    "    print(\"\\n--- 步骤 6: 清理资源 ---\")\n",
    "    if indexer_opt1: indexer_opt1.close()\n",
    "    if retriever_opt1: retriever_opt1.close()\n",
    "    # Generator 无需关闭\n",
    "    print(\"--- 清理完成 ---\")\n",
    "    print(\"\\n\" + \"=\"*10 + \" 选项 1 示例结束 \" + \"=\"*10 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
